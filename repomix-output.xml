This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    build-and-push.yml
    go-test.yml
    mkdocs.yml
    README.md
changelog.d/
  README.md
  template.md.j2
cmd/
  edge-video/
    main.go
  validate-config/
    main.go
docs/
  about/
    credits.md
  api/
    camera.md
    config.md
    mq.md
    storage.md
  architecture/
    components.md
    data-flow.md
    overview.md
  development/
    cicd.md
    contributing.md
    precommit-towncrier.md
    testing.md
  features/
    camera-capture.md
    message-queue.md
    metadata.md
    redis-storage.md
  getting-started/
    configuration.md
    installation.md
    quickstart.md
  guides/
    advanced-config.md
    docker.md
    frame-drop-analysis.md
    implementation-summary.md
    monitoring.md
    performance-analysis.md
    performance-summary.md
    troubleshooting.md
    worker-pool-implementation.md
  javascripts/
    extra.js
    mathjax.js
  stylesheets/
    extra.css
  changelog.md
  CONTRIBUTING.md
  index.md
  MKDOCS_GUIDE.md
  PRECOMMIT_TOWNCRIER_GUIDE.md
  QUICK_REFERENCE.md
  TOWNCRIER_SETUP.md
internal/
  metadata/
    publisher.go
  storage/
    redis_store.go
pkg/
  buffer/
    frame_buffer_test.go
    frame_buffer.go
  camera/
    camera.go
    persistent_capture.go
  circuit/
    breaker_test.go
    breaker.go
  config/
    config_formats_test.go
    config_test.go
    config.go
  logger/
    logger.go
  metrics/
    collector.go
  mq/
    amqp.go
    mqtt.go
    publisher_mock.go
    publisher.go
  util/
    compress.go
  worker/
    pool_test.go
    pool.go
scripts/
  build-changelog.sh
  new-changelog.sh
.dockerignore
.env.example
.gitignore
.golangci.yml
.pre-commit-config.yaml
.python-version
.secrets.baseline
CHANGELOG.md
config.test.toml
config.toml
CONTRIBUTING.md
docker-compose.yml
Dockerfile
go.mod
LICENSE
mkdocs.yml
pyproject.toml
requirements-docs.txt
run-docker.sh
test_camera_redis_amqp.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".github/workflows/go-test.yml">
name: Go Tests CI

on:
  push:
    branches:
      - '**'  # Executa em qualquer branch
  pull_request:
    branches:
      - '**'  # Executa em qualquer PR

jobs:
  test:
    name: Testes Unit√°rios Go
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        go-version: ['1.24']
    
    steps:
      - name: Checkout do c√≥digo
        uses: actions/checkout@v4

      - name: Configurar Go ${{ matrix.go-version }}
        uses: actions/setup-go@v5
        with:
          go-version: ${{ matrix.go-version }}
          cache: true

      - name: Verificar depend√™ncias
        run: |
          go mod download
          go mod verify

      - name: Executar go vet
        run: go vet ./...

      - name: Executar testes unit√°rios
        run: go test -v -race -coverprofile=coverage.out ./...

      - name: Gerar relat√≥rio de cobertura
        run: go tool cover -func=coverage.out

      - name: Upload do relat√≥rio de cobertura
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: coverage.out
          retention-days: 30

      - name: Verificar cobertura m√≠nima (opcional)
        run: |
          COVERAGE=$(go tool cover -func=coverage.out | grep total | awk '{print $3}' | sed 's/%//')
          echo "üìä Cobertura total: ${COVERAGE}%"
          
          # Definir cobertura m√≠nima aceit√°vel (ajuste conforme necess√°rio)
          MIN_COVERAGE=0
          
          if (( $(echo "$COVERAGE < $MIN_COVERAGE" | bc -l) )); then
            echo "‚ùå Cobertura abaixo do m√≠nimo de ${MIN_COVERAGE}%"
            exit 1
          else
            echo "‚úÖ Cobertura acima do m√≠nimo de ${MIN_COVERAGE}%"
          fi

  lint:
    name: Lint e Formata√ß√£o
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout do c√≥digo
        uses: actions/checkout@v4

      - name: Configurar Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.24'
          cache: true

      - name: Verificar formata√ß√£o do c√≥digo
        run: |
          if [ "$(gofmt -s -l . | wc -l)" -gt 0 ]; then
            echo "‚ùå C√≥digo n√£o est√° formatado corretamente. Execute 'gofmt -s -w .'"
            gofmt -s -l .
            exit 1
          else
            echo "‚úÖ C√≥digo formatado corretamente"
          fi

      - name: Executar golangci-lint
        uses: golangci/golangci-lint-action@v4
        with:
          version: latest
          args: --timeout=5m

  build:
    name: Verificar Build
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout do c√≥digo
        uses: actions/checkout@v4

      - name: Configurar Go
        uses: actions/setup-go@v5
        with:
          go-version: '1.24'
          cache: true

      - name: Build do projeto
        run: |
          go build -v ./cmd/edge-video
          echo "‚úÖ Build executado com sucesso"

  summary:
    name: Resumo dos Testes
    runs-on: ubuntu-latest
    needs: [test, lint, build]
    if: always()
    
    steps:
      - name: Verificar status dos jobs
        run: |
          echo "üìä Resumo da execu√ß√£o:"
          echo ""
          echo "Testes: ${{ needs.test.result }}"
          echo "Lint: ${{ needs.lint.result }}"
          echo "Build: ${{ needs.build.result }}"
          echo ""
          
          if [ "${{ needs.test.result }}" == "success" ] && \
             [ "${{ needs.lint.result }}" == "success" ] && \
             [ "${{ needs.build.result }}" == "success" ]; then
            echo "‚úÖ Todos os checks passaram com sucesso!"
            exit 0
          else
            echo "‚ùå Alguns checks falharam. Verifique os logs acima."
            exit 1
          fi
</file>

<file path=".github/workflows/mkdocs.yml">
name: Build and Deploy MkDocs

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
  workflow_dispatch:

# Define permiss√µes para GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Permite apenas um deploy por vez
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    name: Build MkDocs Documentation
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout do c√≥digo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Necess√°rio para git-revision-date-localized

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'

      - name: Instalar depend√™ncias do MkDocs
        run: |
          pip install --upgrade pip
          pip install mkdocs-material
          pip install mkdocs-git-revision-date-localized-plugin
          pip install mkdocs-minify-plugin
          pip install mkdocs-redirects
          pip install mkdocstrings[python]
          pip install pymdown-extensions
          pip install mkdocs-awesome-pages-plugin

      - name: Verificar arquivos de documenta√ß√£o
        run: |
          echo "üìö Estrutura de documenta√ß√£o:"
          ls -la docs/ || echo "‚ö†Ô∏è Diret√≥rio docs/ n√£o encontrado"
          echo ""
          echo "üìÑ Arquivo mkdocs.yml:"
          cat mkdocs.yml || echo "‚ö†Ô∏è Arquivo mkdocs.yml n√£o encontrado"

      - name: Build da documenta√ß√£o
        run: |
          mkdocs build --strict --verbose
          echo "‚úÖ Documenta√ß√£o constru√≠da com sucesso!"

      - name: Verificar site gerado
        run: |
          echo "üì¶ Arquivos gerados em site/:"
          ls -la site/
          echo ""
          echo "üìä Tamanho total:"
          du -sh site/

      - name: Upload artifact para GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: site/

  deploy:
    name: Deploy to GitHub Pages
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Deploy bem-sucedido
        run: |
          echo "‚úÖ Documenta√ß√£o publicada com sucesso!"
          echo "üåê URL: ${{ steps.deployment.outputs.page_url }}"
</file>

<file path=".github/workflows/README.md">
# GitHub Actions Workflows

Este diret√≥rio cont√©m os workflows de CI/CD do projeto Edge Video.

## üìã Workflows Dispon√≠veis

### 1. `go-test.yml` - Testes e Qualidade de C√≥digo
**Trigger:** Push ou Pull Request em qualquer branch

**Jobs:**
- **test**: Executa testes unit√°rios com cobertura
- **lint**: Verifica formata√ß√£o e executa golangci-lint
- **build**: Verifica se o projeto compila
- **summary**: Resumo geral de todos os checks

**Badges sugeridos para README.md:**
```markdown
![Go Tests](https://github.com/T3-Labs/edge-video/actions/workflows/go-test.yml/badge.svg)
```

### 2. `build-and-push.yml` - Build e Deploy Docker
**Trigger:** 
- Cria√ß√£o de Release (tag)
- Manual via workflow_dispatch

**A√ß√µes:**
- Faz build da imagem Docker
- Push para GitHub Container Registry (ghcr.io)
- Cria tags: `vers√£o` + `latest`

**Exemplo de uso:**
```bash
# Criar e publicar release
git tag -a v1.0.0 -m "Release v1.0.0"
git push origin v1.0.0

# Usar a imagem
docker pull ghcr.io/t3-labs/edge-video:latest
docker pull ghcr.io/t3-labs/edge-video:1.0.0
```

## üîß Configura√ß√£o Local

### Executar testes localmente:
```bash
# Testes unit√°rios
go test -v -race -coverprofile=coverage.out ./...

# Ver cobertura
go tool cover -func=coverage.out
go tool cover -html=coverage.out

# Lint
golangci-lint run

# Formata√ß√£o
gofmt -s -w .
```

### Instalar golangci-lint:
```bash
# Linux/macOS
curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin

# Ou via Go
go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest
```

## üìä Cobertura de Testes

A cobertura m√≠nima est√° configurada em **0%** (ajust√°vel no workflow).

Para aumentar a cobertura m√≠nima exigida, edite `go-test.yml`:
```yaml
MIN_COVERAGE=70  # 70% de cobertura m√≠nima
```

## üöÄ Boas Pr√°ticas

1. **Sempre execute os testes localmente** antes de fazer push
2. **PRs devem passar em todos os checks** antes de merge
3. **Mantenha a cobertura de testes alta**
4. **Use commits sem√¢nticos** para facilitar changelogs autom√°ticos
5. **Crie releases versionadas** seguindo Semantic Versioning (semver.org)

## üîí Secrets Necess√°rios

### Para `build-and-push.yml`:
- `GITHUB_TOKEN` - Fornecido automaticamente pelo GitHub Actions

### Para deploy em produ√ß√£o (futuro):
Adicione em **Settings ‚Üí Secrets and variables ‚Üí Actions**:
- Credenciais de cloud providers
- Tokens de acesso a registries privados
- Vari√°veis de ambiente sens√≠veis

## üìö Recursos

- [GitHub Actions Documentation](https://docs.github.com/actions)
- [golangci-lint Configuration](https://golangci-lint.run/usage/configuration/)
- [Docker Build Push Action](https://github.com/docker/build-push-action)
</file>

<file path="changelog.d/README.md">
This directory contains changelog fragments for Towncrier.

## Como Usar

### 1. Criar um Fragment de Changelog

Quando voc√™ faz uma mudan√ßa, crie um arquivo neste diret√≥rio com o formato:

```
<n√∫mero-da-issue>.<tipo>.md
```

**Exemplo:**
```bash
# Para issue #123, feature nova
echo "Adiciona armazenamento Redis para frames" > changelog.d/123.feature.md

# Para issue #456, bugfix
echo "Corrige erro de conex√£o com RabbitMQ" > changelog.d/456.bugfix.md

# Sem issue number, use um identificador √∫nico
echo "Atualiza documenta√ß√£o do README" > changelog.d/$(date +%s).docs.md
```

### 2. Tipos de Fragments Dispon√≠veis

- **feature** - ‚ú® Nova funcionalidade
- **bugfix** - üêõ Corre√ß√£o de bug
- **docs** - üìö Mudan√ßas na documenta√ß√£o
- **removal** - üóëÔ∏è Remo√ß√µes e deprecia√ß√µes
- **security** - üîí Corre√ß√µes de seguran√ßa
- **performance** - ‚ö° Melhorias de performance
- **refactor** - ‚ôªÔ∏è Refatora√ß√£o de c√≥digo
- **misc** - üîß Outras mudan√ßas

### 3. Gerar o CHANGELOG

```bash
# Gerar changelog para uma nova vers√£o
towncrier build --version 1.0.0

# Preview sem modificar arquivos
towncrier build --version 1.0.0 --draft

# Gerar e fazer commit automaticamente
towncrier build --version 1.0.0 --yes
```

### 4. Exemplo de Fragment

**changelog.d/123.feature.md:**
```markdown
Adiciona suporte a autentica√ß√£o Redis com senha configur√°vel via config.toml
```

**changelog.d/456.bugfix.md:**
```markdown
Corrige race condition na captura de frames de m√∫ltiplas c√¢meras
```

### 5. Ignorar o Hook do Pre-commit

Se precisar fazer um commit sem fragment (ex: commits em main):

```bash
git commit --no-verify -m "chore: atualiza depend√™ncias"
```

## Estrutura de Arquivo Fragment

Cada fragment √© um arquivo simples de texto markdown contendo:
- Uma linha descrevendo a mudan√ßa
- Opcionalmente, mais detalhes em par√°grafos adicionais

## Integra√ß√£o com CI/CD

O pre-commit hook `towncrier-check` valida que:
- ‚úÖ Branches de feature t√™m pelo menos um fragment
- ‚úÖ Os fragments seguem o formato correto
- ‚úÖ N√£o h√° fragments duplicados

## Comandos √öteis

```bash
# Instalar towncrier
pip install towncrier

# Verificar configura√ß√£o
towncrier --help

# Listar fragments pendentes
ls -la changelog.d/*.md

# Limpar fragments ap√≥s build
# (towncrier faz isso automaticamente com --yes)
```

## Recursos

- [Towncrier Docs](https://towncrier.readthedocs.io/)
- [Keep a Changelog](https://keepachangelog.com/)
- [Semantic Versioning](https://semver.org/)
</file>

<file path="changelog.d/template.md.j2">
{% if sections %}
{% for section, _ in sections.items() %}
{% set underline = underlines[0] %}{% if section %}{{section}}
{{ underline * section|length }}{% set underline = underlines[1] %}

{% endif %}
{% if sections[section] %}
{% for category, val in definitions.items() if category in sections[section]%}
### {{ definitions[category]['name'] }}

{% for text, values in sections[section][category].items() %}
- {{ text }}{% if values %} ({% for issue in values %}[#{{ issue }}](https://github.com/T3-Labs/edge-video/issues/{{ issue }}){% if not loop.last %}, {% endif %}{% endfor %}){% endif %}

{% endfor %}

{% endfor %}
{% else %}
No significant changes.

{% endif %}
{% endfor %}
{% else %}
No significant changes.
{% endif %}
</file>

<file path="docs/about/credits.md">
# Cr√©ditos\n\nDesenvolvido por T3 Labs.
</file>

<file path="docs/api/camera.md">
# API: Camera\n\nEm desenvolvimento.
</file>

<file path="docs/api/config.md">
# API: Config\n\nEm desenvolvimento.
</file>

<file path="docs/api/mq.md">
# API: Message Queue\n\nEm desenvolvimento.
</file>

<file path="docs/api/storage.md">
# API: Storage\n\nEm desenvolvimento.
</file>

<file path="docs/architecture/components.md">
# Componentes\n\nEm desenvolvimento.
</file>

<file path="docs/architecture/data-flow.md">
# Fluxo de Dados\n\nEm desenvolvimento.
</file>

<file path="docs/architecture/overview.md">
# Vis√£o Geral da Arquitetura\n\nEm desenvolvimento.
</file>

<file path="docs/development/cicd.md">
# CI/CD\n\nEm desenvolvimento.
</file>

<file path="docs/development/precommit-towncrier.md">
# Pre-commit & Towncrier\n\nVeja [guia completo](../PRECOMMIT_TOWNCRIER_GUIDE.md).
</file>

<file path="docs/development/testing.md">
# Testes\n\nEm desenvolvimento.
</file>

<file path="docs/features/camera-capture.md">
# Captura de C√¢meras\n\nEm desenvolvimento.
</file>

<file path="docs/features/message-queue.md">
# Message Queue\n\nEm desenvolvimento.
</file>

<file path="docs/features/metadata.md">
# Metadata Publisher\n\nEm desenvolvimento.
</file>

<file path="docs/features/redis-storage.md">
# Redis Storage\n\nEm desenvolvimento.
</file>

<file path="docs/getting-started/configuration.md">
# Configura√ß√£o

Guia completo de configura√ß√£o do Edge Video.

## Arquivo de Configura√ß√£o

O Edge Video usa TOML como formato de configura√ß√£o. O arquivo padr√£o √© `config.toml`.

## Estrutura Completa

```toml
# FPS desejado para captura
target_fps = 30

# Protocolo: "amqp" ou "mqtt"
protocol = "amqp"

# Configura√ß√£o AMQP (RabbitMQ)
[amqp]
amqp_url = "amqp://user:password@rabbitmq:5672/supermercado_vhost"
exchange = "supermercado_exchange"
routing_key_prefix = "camera."

# Configura√ß√£o MQTT
[mqtt]
broker = "tcp://localhost:1883"
topic_prefix = "camera/"

# Configura√ß√£o Redis
[redis]
enabled = true
address = "redis:6379"
password = "your_redis_password"
ttl_seconds = 300
prefix = "frames"

# Configura√ß√£o de Metadados
[metadata]
enabled = true
exchange = "camera.metadata"
routing_key = "camera.metadata.event"

# C√¢meras RTSP
[[cameras]]
id = "cam1"
url = "rtsp://user:pass@ip:port/stream"

[[cameras]]
id = "cam2"
url = "rtsp://user:pass@ip:port/stream"
```

## Par√¢metros Detalhados

Veja a documenta√ß√£o completa em desenvolvimento.

[‚Üê Instala√ß√£o](installation.md){ .md-button }
[Quick Start ‚Üí](quickstart.md){ .md-button .md-button--primary }
</file>

<file path="docs/getting-started/installation.md">
# Instala√ß√£o

Este guia mostra como instalar e configurar o Edge Video em diferentes ambientes.

## Pr√©-requisitos

### Requisitos M√≠nimos

- **CPU**: 2 cores
- **RAM**: 2 GB
- **Disco**: 10 GB
- **OS**: Linux, macOS ou Windows (com Docker)

### Software Necess√°rio

=== "Docker (Recomendado)"

    - [Docker](https://docs.docker.com/get-docker/) 20.10+
    - [Docker Compose](https://docs.docker.com/compose/install/) 2.0+

=== "Build Local"

    - [Go](https://go.dev/dl/) 1.24+
    - [FFmpeg](https://ffmpeg.org/download.html)
    - [RabbitMQ](https://www.rabbitmq.com/download.html) 3.13+
    - [Redis](https://redis.io/download) 7+

## Instala√ß√£o via Docker Compose

!!! success "M√©todo Recomendado"
    Esta √© a forma mais r√°pida e f√°cil de come√ßar!

### 1. Clone o Reposit√≥rio

```bash
git clone https://github.com/T3-Labs/edge-video.git
cd edge-video
```

### 2. Configure as C√¢meras

Edite o arquivo `config.toml`:

```toml
[[cameras]]
id = "cam1"
url = "rtsp://user:pass@192.168.1.100:554/stream"

[[cameras]]
id = "cam2"
url = "rtsp://user:pass@192.168.1.101:554/stream"
```

### 3. Inicie os Servi√ßos

```bash
docker-compose up -d
```

### 4. Verifique os Logs

```bash
# Logs do collector
docker logs -f camera-collector

# Logs do RabbitMQ
docker logs -f rabbitmq

# Logs do Redis
docker logs -f redis
```

### 5. Acesse as Interfaces

| Servi√ßo | URL | Credenciais |
|---------|-----|-------------|
| RabbitMQ Management | http://localhost:15672 | user / password |
| RedisInsight | http://localhost:5540 | - |

## Instala√ß√£o via Docker Pull

### 1. Pull da Imagem

```bash
docker pull ghcr.io/t3-labs/edge-video:latest
```

### 2. Execute o Container

```bash
docker run -d \
  --name edge-video \
  -v $(pwd)/config.toml:/app/config.toml \
  --network edge-video-network \
  ghcr.io/t3-labs/edge-video:latest
```

## Build e Instala√ß√£o Local

### 1. Instalar Depend√™ncias

=== "Ubuntu/Debian"

    ```bash
    # Go
    wget https://go.dev/dl/go1.24.linux-amd64.tar.gz
    sudo tar -C /usr/local -xzf go1.24.linux-amd64.tar.gz
    export PATH=$PATH:/usr/local/go/bin

    # FFmpeg
    sudo apt update
    sudo apt install -y ffmpeg

    # RabbitMQ
    sudo apt install -y rabbitmq-server
    sudo systemctl start rabbitmq-server

    # Redis
    sudo apt install -y redis-server
    sudo systemctl start redis-server
    ```

=== "macOS"

    ```bash
    # Homebrew
    brew install go
    brew install ffmpeg
    brew install rabbitmq
    brew install redis

    # Iniciar servi√ßos
    brew services start rabbitmq
    brew services start redis
    ```

=== "Windows"

    ```powershell
    # Chocolatey
    choco install golang
    choco install ffmpeg
    
    # RabbitMQ e Redis via Docker
    docker run -d -p 5672:5672 -p 15672:15672 rabbitmq:3.13-management
    docker run -d -p 6379:6379 redis:7-alpine
    ```

### 2. Clone e Build

```bash
# Clone
git clone https://github.com/T3-Labs/edge-video.git
cd edge-video

# Download depend√™ncias
go mod download

# Build
go build -o edge-video ./cmd/edge-video

# Executar
./edge-video
```

## Verifica√ß√£o da Instala√ß√£o

### 1. Verificar Status dos Servi√ßos

```bash
# Docker
docker ps

# Deve mostrar:
# - camera-collector
# - rabbitmq
# - redis
# - redisinsight
```

### 2. Verificar Conectividade

```bash
# RabbitMQ
curl -u user:password http://localhost:15672/api/overview

# Redis
redis-cli -h localhost -p 6379 ping
# Resposta esperada: PONG
```

### 3. Verificar Captura de Frames

```bash
# Ver logs do collector
docker logs camera-collector | grep "frame captured"

# Verificar frames no Redis
redis-cli -h localhost -p 6379 KEYS "frames:*"
```

## Pr√≥ximos Passos

- [Configura√ß√£o Detalhada](configuration.md)
- [Quick Start](quickstart.md)
- [Troubleshooting](../guides/troubleshooting.md)

## Desinstala√ß√£o

### Docker Compose

```bash
# Parar e remover containers
docker-compose down

# Remover volumes (opcional)
docker-compose down -v

# Remover imagens (opcional)
docker rmi edge-video_camera-collector
```

### Local

```bash
# Parar servi√ßos
sudo systemctl stop rabbitmq-server
sudo systemctl stop redis-server

# Remover bin√°rio
rm -f edge-video

# Remover depend√™ncias (opcional)
sudo apt remove --purge rabbitmq-server redis-server
```
</file>

<file path="docs/getting-started/quickstart.md">
# Quick Start\n\nEm desenvolvimento.
</file>

<file path="docs/guides/advanced-config.md">
# Configura√ß√£o Avan√ßada\n\nEm desenvolvimento.
</file>

<file path="docs/guides/docker.md">
# Docker Deployment\n\nEm desenvolvimento.
</file>

<file path="docs/guides/frame-drop-analysis.md">
# An√°lise de Perda de Frames - Edge Video

## üîç Causas Identificadas de Perda de Frames

Ap√≥s an√°lise do c√≥digo, identifiquei **6 causas principais** de perda de frames, sendo **apenas 1 relacionada √† rede**:

---

## ‚ùå PROBLEMAS ENCONTRADOS (5 causas internas)

### 1. üö® **CR√çTICO: Ticker Fixo vs Processamento Vari√°vel**

**Arquivo**: `pkg/camera/camera.go` (linhas 100, 142)

**Problema**:
```go
ticker := time.NewTicker(c.interval)  // Ex: 33ms para 30 FPS
defer ticker.Stop()

for {
    case <-ticker.C:
        c.captureAndPublish()  // Pode levar 100-500ms!
}
```

**Impacto**:
- Se `captureAndPublish()` leva 200ms, voc√™ perde 6 ticks (200ms / 33ms)
- **Estimativa de perda**: 15-30% dos frames em modo cl√°ssico
- Em 30 FPS, captura real pode ser apenas 10-15 FPS

**Por que acontece**:
- FFmpeg leva 100-300ms para capturar cada frame
- Publishing para RabbitMQ pode levar 10-50ms
- Redis save pode levar 5-20ms
- Enquanto processa 1 frame, perde 3-6 ticks do ticker

**Solu√ß√£o**:
```go
// Op√ß√£o 1: Ticker adaptativo
go func() {
    for {
        start := time.Now()
        c.captureAndPublish()
        
        elapsed := time.Since(start)
        nextInterval := c.interval - elapsed
        if nextInterval < 0 {
            nextInterval = 0
        }
        time.Sleep(nextInterval)
    }
}()

// Op√ß√£o 2: Captura ass√≠ncrona (j√° implementado no persistent)
```

---

### 2. ‚ö†Ô∏è **Worker Pool Cheio**

**Arquivo**: `pkg/camera/camera.go` (linhas 128, 235)

**Problema**:
```go
err := c.workerPool.Submit(job)
if err != nil {
    metrics.FramesDropped.WithLabelValues(c.config.ID, "worker_pool_full").Inc()
    logger.Log.Warnw("Worker pool cheio, frame descartado")
    // Frame √© descartado permanentemente no modo persistente!
}
```

**Impacto**:
- Com 10 workers e 100 buffer: 110 jobs m√°ximo
- Se 5 c√¢meras @ 30 FPS = 150 jobs/segundo
- **Satura√ß√£o em ~73% da capacidade te√≥rica**

**Por que acontece**:
- Workers processam ~100ms por job (publish + redis + metadata)
- 10 workers = 100 jobs/segundo m√°ximo
- 5 c√¢meras @ 30 FPS = 150 jobs/segundo necess√°rio
- Buffer de 100 n√£o compensa lat√™ncia de processamento

**C√°lculo**:
```
Capacidade: 10 workers √ó (1000ms / 100ms) = 100 jobs/s
Demanda: 5 c√¢meras √ó 30 FPS = 150 jobs/s
D√©ficit: 50 jobs/s perdidos = 33% frame drop
```

**Solu√ß√£o**:
```yaml
optimization:
  max_workers: 20      # Aumentar para 15-20
  buffer_size: 200     # Aumentar para 200-300
```

---

### 3. ‚ö†Ô∏è **Buffer Persistente Pequeno (10 frames)**

**Arquivo**: `pkg/camera/persistent_capture.go` (linha 37)

**Problema**:
```go
frameBuffer: make(chan []byte, 10),  // Apenas 10 frames!
```

**Impacto**:
- A 30 FPS, 10 frames = 333ms de buffer
- Se ticker loop processa a cada 1 segundo, perde 20 frames
- **Estimativa de perda**: 5-10% mesmo em modo persistente

**Por que acontece**:
- FFmpeg captura @ 10 FPS (hardcoded: `-r`, "10")
- Ticker consome @ 30 FPS configurado
- Buffer de 10 frames s√≥ aguenta 1 segundo de produ√ß√£o
- Se consumer atrasado, producer descarta novos frames

**C√°lculo**:
```
Produ√ß√£o FFmpeg: 10 FPS
Consumo Ticker: 30 FPS (configurado)
Buffer: 10 frames = 1 segundo @ 10 FPS

Se consumo para por 2s:
- FFmpeg produz 20 frames
- Buffer aceita 10 frames
- Descarta 10 frames = 50% perda
```

**Solu√ß√£o**:
```go
// persistent_capture.go
frameBuffer: make(chan []byte, 50), // Aumentar para 30-50
```

---

### 4. ‚ö†Ô∏è **FFmpeg Rate Hardcoded em 10 FPS**

**Arquivo**: `pkg/camera/persistent_capture.go` (linha 79)

**Problema**:
```go
"-r", "10",  // HARDCODED! Ignora config.target_fps
```

**Impacto**:
- Usu√°rio configura 30 FPS no config.yaml
- FFmpeg captura apenas 10 FPS
- **Frames "perdidos" nunca s√£o capturados**

**Por que acontece**:
- `-r 10` limita FFmpeg a 10 frames por segundo
- Config `target_fps: 30` s√≥ afeta o ticker interval
- Resultado: ticker pede 30 FPS, FFmpeg entrega 10 FPS

**Solu√ß√£o**:
```go
func (pc *PersistentCapture) startFFmpeg() error {
    // Calcular FPS do config ao inv√©s de hardcode
    fps := "30" // Passar como par√¢metro
    
    pc.cmd = exec.CommandContext(
        pc.ctx,
        "ffmpeg",
        "-rtsp_transport", "tcp",
        "-i", pc.rtspURL,
        "-f", "image2pipe",
        "-vcodec", "mjpeg",
        "-q:v", fmt.Sprintf("%d", pc.quality),
        "-r", fps,  // Usar FPS configurado
        "-",
    )
}
```

---

### 5. ‚ö†Ô∏è **GetFrameNonBlocking Descarta Frames**

**Arquivo**: `pkg/camera/camera.go` (linha 113)

**Problema**:
```go
frame, ok := c.persistentCapture.GetFrameNonBlocking()
if !ok {
    metrics.FramesDropped.WithLabelValues(c.config.ID, "no_frame_available").Inc()
    continue  // Pula este tick
}
```

**Impacto**:
- Se FFmpeg atrasar 100ms, ticker n√£o espera
- Frame perdido mesmo que chegasse 50ms depois
- **Estimativa de perda**: 5-15% em redes inst√°veis

**Por que acontece**:
- Ticker n√£o espera frame dispon√≠vel
- NonBlocking retorna imediatamente se buffer vazio
- Frame chega 50ms depois, mas ticker j√° passou

**Timeline**:
```
T=0ms:    Ticker fire
T=5ms:    GetFrameNonBlocking() -> buffer vazio, retorna false
T=50ms:   FFmpeg envia frame -> buffer
T=33ms:   Pr√≥ximo ticker fire (frame anterior perdido)
```

**Solu√ß√£o**:
```go
// Op√ß√£o 1: Usar GetFrame() bloqueante com timeout
ctx, cancel := context.WithTimeout(c.ctx, c.interval/2)
frame, ok := c.persistentCapture.GetFrameWithTimeout(ctx)
cancel()

// Op√ß√£o 2: M√∫ltiplos consumers do buffer
```

---

### 6. üåê **Rede/RTSP (√∫nica causa externa)**

**Causas de rede**:
- Lat√™ncia RTSP > 1s
- Packet loss > 5%
- Bandwidth insuficiente
- C√¢mera congestionada

**Impacto**: Vari√°vel, 0-50% dependendo da rede

**Como identificar**:
```bash
# Testar lat√™ncia RTSP
ffprobe -rtsp_transport tcp -i "rtsp://..." -show_frames

# Monitorar packet loss
tcpdump -i any host <camera_ip> -w capture.pcap
```

---

## üìä Resumo de Impactos

| Causa | Impacto Estimado | Severidade | Tipo |
|-------|-----------------|------------|------|
| 1. Ticker Fixo | 15-30% | üö® CR√çTICO | C√≥digo |
| 2. Worker Pool Cheio | 10-33% | ‚ö†Ô∏è ALTO | Config |
| 3. Buffer Pequeno (10 frames) | 5-10% | ‚ö†Ô∏è M√âDIO | C√≥digo |
| 4. FFmpeg 10 FPS Hardcoded | 66% (30‚Üí10 FPS) | üö® CR√çTICO | C√≥digo |
| 5. NonBlocking Drop | 5-15% | ‚ö†Ô∏è M√âDIO | C√≥digo |
| 6. Rede/RTSP | 0-50% | üåê EXTERNO | Rede |

**Perda Total Potencial**: 40-80% dos frames (sem corre√ß√µes)

---

## ‚úÖ SOLU√á√ïES RECOMENDADAS

### Corre√ß√£o Imediata (1 hora)

**1. Aumentar Workers e Buffer**
```yaml
# config.yaml
optimization:
  max_workers: 20        # Aumentar de 10 para 20
  buffer_size: 200       # Aumentar de 100 para 200
```

**2. Aumentar Buffer Persistente**
```go
// pkg/camera/persistent_capture.go:37
frameBuffer: make(chan []byte, 50),  // Aumentar de 10 para 50
```

### Corre√ß√£o Importante (2-4 horas)

**3. Remover Hardcode de FPS**
```go
// persistent_capture.go
func NewPersistentCapture(ctx context.Context, cameraID, rtspURL string, quality int, fps int) *PersistentCapture {
    // ...
}

func (pc *PersistentCapture) startFFmpeg() error {
    pc.cmd = exec.CommandContext(
        pc.ctx,
        "ffmpeg",
        "-rtsp_transport", "tcp",
        "-i", pc.rtspURL,
        "-f", "image2pipe",
        "-vcodec", "mjpeg",
        "-q:v", fmt.Sprintf("%d", pc.quality),
        "-r", fmt.Sprintf("%d", pc.fps),  // Usar FPS configurado
        "-",
    )
}
```

**4. Ticker Adaptativo**
```go
// camera.go - substituir ticker fixo
func (c *Capture) classicCaptureLoop() {
    for {
        select {
        case <-c.ctx.Done():
            return
        default:
        }
        
        start := time.Now()
        c.captureAndPublish()
        
        elapsed := time.Since(start)
        sleepTime := c.interval - elapsed
        if sleepTime > 0 {
            time.Sleep(sleepTime)
        }
    }
}
```

**5. GetFrame com Timeout**
```go
// persistent_capture.go
func (pc *PersistentCapture) GetFrameWithTimeout(ctx context.Context, timeout time.Duration) ([]byte, bool) {
    ctx, cancel := context.WithTimeout(ctx, timeout)
    defer cancel()
    
    select {
    case frame := <-pc.frameBuffer:
        return frame, true
    case <-ctx.Done():
        return nil, false
    }
}

// camera.go - usar com timeout
ctx, cancel := context.WithTimeout(c.ctx, c.interval/2)
frame, ok := c.persistentCapture.GetFrameWithTimeout(ctx, c.interval/2)
cancel()
```

---

## üìà Ganho Esperado

| Corre√ß√£o | Ganho | Dificuldade |
|----------|-------|-------------|
| Workers 10‚Üí20 + Buffer 100‚Üí200 | +20-30% | F√°cil (config) |
| Buffer Persistente 10‚Üí50 | +5-10% | F√°cil (1 linha) |
| FPS configur√°vel | +66% | M√©dio (refactor) |
| Ticker adaptativo | +15-20% | M√©dio (refactor) |
| GetFrame com timeout | +5-10% | F√°cil (novo m√©todo) |

**Ganho Total Esperado**: 50-80% de redu√ß√£o na perda de frames

**Frame Drop Rate**:
- Atual: 30-50%
- Com corre√ß√µes: 5-15%
- Ideal: < 5%

---

## üß™ Como Validar

**1. M√©tricas Prometheus**:
```promql
# Frame drop rate
rate(edge_video_frames_dropped_total[5m]) / rate(edge_video_frames_processed_total[5m])

# Raz√µes de drop
sum by (reason) (rate(edge_video_frames_dropped_total[5m]))
```

**2. Logs**:
```bash
# Contar drops por raz√£o
grep "frame descartado" logs.txt | sort | uniq -c

# Verificar worker pool saturation
grep "Worker pool cheio" logs.txt | wc -l
```

**3. Teste de Carga**:
```bash
# Monitorar 1 c√¢mera com m√©tricas detalhadas
curl http://localhost:9090/metrics | grep edge_video_frames
```

---

## üéØ Prioridades

1. **AGORA** (1h): Aumentar workers/buffer (config)
2. **HOJE** (2h): Buffer persistente + FPS configur√°vel
3. **ESTA SEMANA** (4h): Ticker adaptativo + GetFrame timeout
4. **DEPOIS**: Rede/RTSP otimization (fora do escopo)
</file>

<file path="docs/guides/implementation-summary.md">
# Otimiza√ß√µes Implementadas - Edge Video

## üìä Resumo Executivo

**Status**: ‚úÖ **COMPLETO** - Todas as otimiza√ß√µes implementadas e testadas

**Capacidade Esperada**:
- **Antes**: 15-20 c√¢meras (limite cr√≠tico)
- **Depois**: 50-100 c√¢meras (ganho de 5-10x)

**Commit**: `69f5985` - "feat: implement complete optimization stack for 50-100 camera capacity"

---

## üéØ Componentes Implementados

### 1. Worker Pool (`pkg/worker/pool.go`)
**Ganho Esperado**: 2x capacidade

**Funcionalidades**:
- Pool de goroutines com tamanho configur√°vel (padr√£o: 10 workers)
- Fila de jobs com buffer para evitar cria√ß√£o ilimitada de goroutines
- Tracking de estat√≠sticas: jobs processados, erros, tamanho da fila
- Shutdown gracioso com timeout de 5 segundos
- Submiss√£o n√£o-bloqueante de jobs

**Testes**: 9 testes unit√°rios (TestNewPool, TestPoolSubmit, TestPoolSubmitMultiple, TestPoolBufferFull, etc.)

**Uso**:
```go
pool := worker.NewPool(ctx, 10, 100) // 10 workers, buffer de 100
job := &FrameProcessJob{...}
pool.Submit(job)
stats := pool.Stats() // Worker pool stats
pool.Close()
```

---

### 2. Frame Buffer (`pkg/buffer/frame_buffer.go`)
**Ganho Esperado**: 50% redu√ß√£o em frame drops

**Funcionalidades**:
- Fila bufferizada para frames com tamanho configur√°vel
- Tracking de frames descartados e taxa de drop
- Opera√ß√µes push/pop n√£o-bloqueantes
- Estat√≠sticas em tempo real

**Testes**: 8 testes unit√°rios (TestNewFrameBuffer, TestFrameBufferPush, TestFrameBufferStats, etc.)

**Uso**:
```go
buffer := buffer.NewFrameBuffer(100) // Buffer de 100 frames
frame := buffer.Frame{CameraID: "cam1", Data: frameData}
buffer.Push(frame)
frame, ok := buffer.Pop()
stats := buffer.Stats() // Drop rate, total frames, etc.
```

---

### 3. Circuit Breaker (`pkg/circuit/breaker.go`)
**Ganho Esperado**: Resili√™ncia do sistema

**Funcionalidades**:
- Estados: Closed (normal), Open (falhas), HalfOpen (recupera√ß√£o)
- Recovery autom√°tico com timeout configur√°vel
- Threshold de falhas antes de abrir circuito
- Estat√≠sticas de falhas e sucessos

**Testes**: 9 testes unit√°rios (TestBreakerStateClosed, TestBreakerStateOpen, TestBreakerRecovery, etc.)

**Uso**:
```go
breaker := circuit.NewBreaker("cam1", 5, 60*time.Second)
err := breaker.Call(func() error {
    return captureFrame()
})
state := breaker.State() // CLOSED, OPEN, HALF_OPEN
```

---

### 4. Persistent FFmpeg Capture (`pkg/camera/persistent_capture.go`)
**Ganho Esperado**: 3-5x capacidade (maior ganho individual)

**Funcionalidades**:
- Processo FFmpeg persistente por c√¢mera (elimina recria√ß√£o)
- Parsing de stream MJPEG com detec√ß√£o SOI/EOI
- Restart autom√°tico em caso de erro com exponential backoff
- Health monitoring com timeout de frames
- Buffer interno de frames

**Uso**:
```go
capture := NewPersistentCapture(ctx, "cam1", rtspURL, 5)
capture.Start()
frame, ok := capture.GetFrame() // Blocking
frame, ok := capture.GetFrameNonBlocking()
capture.Stop()
```

---

### 5. Structured Logging (`pkg/logger/logger.go`)
**Ganho Esperado**: 10-15% redu√ß√£o de CPU

**Funcionalidades**:
- Zap structured logger com sampling (100 inicial, 100 depois)
- N√≠veis: Debug, Info, Warn, Error
- Logging baseado em fields para melhor performance
- Substitui√ß√£o de log.Printf por logger estruturado

**Uso**:
```go
logger.InitLogger(false) // production mode
logger.Log.Infow("C√¢mera iniciada",
    "camera_id", camID,
    "fps", targetFPS)
logger.Log.Errorw("Erro na captura",
    "camera_id", camID,
    "error", err)
```

---

### 6. Prometheus Metrics (`pkg/metrics/collector.go`)
**Ganho Esperado**: Observabilidade completa

**M√©tricas Implementadas** (10 tipos):
1. `edge_video_frames_processed_total` - Frames processados por c√¢mera
2. `edge_video_frames_dropped_total` - Frames descartados (por raz√£o)
3. `edge_video_capture_latency_seconds` - Lat√™ncia de captura (histogram)
4. `edge_video_worker_pool_queue_size` - Tamanho da fila do pool
5. `edge_video_worker_pool_processing` - Jobs em processamento
6. `edge_video_buffer_size` - Tamanho do buffer de frames
7. `edge_video_circuit_breaker_state` - Estado do circuit breaker
8. `edge_video_camera_connected` - Status de conex√£o da c√¢mera
9. `edge_video_publish_latency_seconds` - Lat√™ncia de publica√ß√£o
10. `edge_video_storage_operations_total` - Opera√ß√µes de storage

**Endpoint**: `http://localhost:9090/metrics`

**Uso**:
```go
metrics.FramesProcessed.WithLabelValues(cameraID).Inc()
metrics.CaptureLatency.WithLabelValues(cameraID).Observe(duration.Seconds())
metrics.FramesDropped.WithLabelValues(cameraID, "buffer_full").Inc()
```

---

### 7. Enhanced Configuration (`pkg/config/config.go`)

**Novas Configura√ß√µes**:
```yaml
optimization:
  max_workers: 10                  # N√∫mero de workers do pool
  buffer_size: 100                 # Tamanho do buffer de frames
  frame_quality: 5                 # Qualidade JPEG (2-31, menor = melhor)
  frame_resolution: "1280x720"     # Resolu√ß√£o dos frames
  use_persistent: true             # Usar captura persistente FFmpeg
  circuit_max_failures: 5          # Falhas antes de abrir circuit breaker
  circuit_reset_seconds: 60        # Tempo para tentar reconectar (segundos)
```

**Compatibilidade**:
- `use_persistent: false` - Modo cl√°ssico (backward compatible)
- `use_persistent: true` - Modo persistente (recomendado)

---

### 8. Main Application Refactoring (`cmd/edge-video/main.go`)

**Mudan√ßas**:
- Inicializa√ß√£o de Worker Pool global
- Cria√ß√£o de Frame Buffer e Circuit Breaker por c√¢mera
- Servidor de m√©tricas em `:9090/metrics`
- System monitoring a cada 30 segundos
- Structured logging em toda aplica√ß√£o
- Suporte para captura persistente e cl√°ssica

**Fluxo**:
```
main.go
  ‚îú‚îÄ> Inicializar Logger (Zap)
  ‚îú‚îÄ> Carregar Config (config.yaml)
  ‚îú‚îÄ> Criar Worker Pool (global)
  ‚îú‚îÄ> Inicializar Publisher (AMQP/MQTT)
  ‚îú‚îÄ> Para cada c√¢mera:
  ‚îÇ     ‚îú‚îÄ> Criar Frame Buffer
  ‚îÇ     ‚îú‚îÄ> Criar Circuit Breaker
  ‚îÇ     ‚îú‚îÄ> Criar Capture (persistente ou cl√°ssica)
  ‚îÇ     ‚îî‚îÄ> Iniciar captura
  ‚îú‚îÄ> Iniciar Metrics Server (:9090)
  ‚îú‚îÄ> Iniciar System Monitor (stats a cada 30s)
  ‚îî‚îÄ> Aguardar sinal de finaliza√ß√£o
```

---

## üß™ Testes

**Total**: 26 testes unit√°rios, todos passando ‚úÖ

### Worker Pool (9 testes)
- `TestNewPool` - Cria√ß√£o do pool
- `TestPoolSubmit` - Submiss√£o de job
- `TestPoolSubmitMultiple` - Submiss√£o de m√∫ltiplos jobs
- `TestPoolBufferFull` - Comportamento quando buffer est√° cheio
- `TestPoolWithErrors` - Handling de erros
- `TestPoolClose` - Shutdown gracioso
- `TestPoolStats` - Estat√≠sticas do pool
- `BenchmarkPoolSubmit` - Benchmark de performance

### Circuit Breaker (9 testes)
- `TestNewBreaker` - Cria√ß√£o do breaker
- `TestBreakerStateClosed` - Estado fechado (normal)
- `TestBreakerStateOpen` - Estado aberto (falhas)
- `TestBreakerStateHalfOpen` - Estado de recupera√ß√£o
- `TestBreakerRecovery` - Recovery autom√°tico
- `TestBreakerStats` - Estat√≠sticas
- `TestBreakerReset` - Reset manual
- `TestBreakerHalfOpenFailure` - Falha durante recupera√ß√£o
- `TestBreakerConcurrent` - Seguran√ßa de concorr√™ncia

### Frame Buffer (8 testes)
- `TestNewFrameBuffer` - Cria√ß√£o do buffer
- `TestFrameBufferPush` - Push de frames
- `TestFrameBufferPushFull` - Overflow do buffer
- `TestFrameBufferPop` - Pop de frames
- `TestFrameBufferPopEmpty` - Pop de buffer vazio
- `TestFrameBufferStats` - Estat√≠sticas e drop rate
- `TestFrameBufferClose` - Fechamento do buffer
- `TestFrameBufferConcurrent` - Opera√ß√µes concorrentes

**Executar testes**:
```bash
go test ./pkg/worker ./pkg/circuit ./pkg/buffer -v
go test ./pkg/worker ./pkg/circuit ./pkg/buffer -bench=.
```

---

## üìà Ganhos Esperados

| Otimiza√ß√£o | Ganho Individual | Impacto |
|------------|-----------------|---------|
| Worker Pool | 2x | Remove cria√ß√£o ilimitada de goroutines |
| Frame Buffer | 1.5x | Reduz 50% dos frame drops |
| Circuit Breaker | Resili√™ncia | Previne cascade failures |
| Persistent FFmpeg | 3-5x | **MAIOR GANHO** - Elimina recria√ß√£o de processos |
| Structured Logging | 10-15% CPU | Menos overhead de logging |
| Prometheus Metrics | Observabilidade | Visibilidade completa do sistema |

**Ganho Combinado Estimado**: 5-10x capacidade
- **Antes**: 15-20 c√¢meras
- **Depois**: 50-100 c√¢meras

---

## üöÄ Pr√≥ximos Passos

### 1. Atualizar Documenta√ß√£o
**Status**: Pendente
- [ ] Atualizar README.md com novas configura√ß√µes
- [ ] Documentar m√©tricas dispon√≠veis
- [ ] Criar guia de migra√ß√£o do modo cl√°ssico para persistente
- [ ] Adicionar exemplos de queries Prometheus
- [ ] Documentar troubleshooting de circuit breakers

### 2. Deploy Gradual
**Recomenda√ß√£o**:
1. Come√ßar com 5-10 c√¢meras em `use_persistent: false` (validar Worker Pool + Buffer)
2. Habilitar `use_persistent: true` em 2-3 c√¢meras (validar Persistent FFmpeg)
3. Aumentar gradualmente para 20-30 c√¢meras
4. Monitorar m√©tricas por 24-48h
5. Expandir para 50+ c√¢meras

### 3. Monitoramento
**M√©tricas Chave**:
- `edge_video_frames_dropped_total` - Deve ser < 5%
- `edge_video_capture_latency_seconds` - Deve ser < 1s p99
- `edge_video_worker_pool_queue_size` - Deve ser < 80% da capacidade
- `edge_video_circuit_breaker_state` - Monitorar transi√ß√µes para OPEN
- `edge_video_camera_connected` - Todas c√¢meras devem estar = 1

**Alertas Sugeridos**:
```yaml
# Prometheus AlertManager
- alert: HighFrameDropRate
  expr: rate(edge_video_frames_dropped_total[5m]) / rate(edge_video_frames_processed_total[5m]) > 0.1
  for: 5m
  
- alert: WorkerPoolSaturated
  expr: edge_video_worker_pool_queue_size / edge_video_worker_pool_capacity > 0.9
  for: 5m
  
- alert: CircuitBreakerOpen
  expr: edge_video_circuit_breaker_state == 1
  for: 1m
```

### 4. Tuning de Configura√ß√£o
**Ajustes Recomendados**:
- `max_workers`: Iniciar com 10, aumentar para 20-30 se necess√°rio
- `buffer_size`: Iniciar com 100, aumentar para 200-500 em alta carga
- `frame_quality`: 5 (balanceado), reduzir para 8-10 se CPU alto
- `circuit_max_failures`: 5 (conservador), ajustar baseado em estabilidade
- `circuit_reset_seconds`: 60s (padr√£o), aumentar para 120s se muitas reconex√µes

---

## üìä Valida√ß√£o de Capacidade

**Teste Recomendado**:
```bash
# 1. Iniciar com m√©tricas
curl http://localhost:9090/metrics | grep edge_video

# 2. Adicionar c√¢meras gradualmente
# Monitorar:
# - CPU usage (deve ficar < 80%)
# - Memory usage (deve ficar < 4GB)
# - Frame drop rate (deve ficar < 5%)
# - Capture latency p99 (deve ficar < 2s)

# 3. Identificar ponto de satura√ß√£o
# Quando m√©tricas come√ßarem a degradar, voc√™ atingiu o limite
```

**Capacidade Te√≥rica**:
- **Worker Pool**: 10 workers √ó 10 frames/s = 100 frames/s
- **Persistent FFmpeg**: 100 c√¢meras √ó 1 frame/s = 100 frames/s
- **Bottleneck**: RabbitMQ publishing (depende do cluster)

**Gargalos Poss√≠veis**:
1. CPU: FFmpeg MJPEG encoding (otimizar com frame_quality)
2. Network: RTSP bandwidth (otimizar com frame_resolution)
3. RabbitMQ: Publishing rate (considerar batching)
4. Redis: Storage operations (considerar TTL menor)

---

## üéâ Conclus√£o

**Implementa√ß√£o Completa**:
- ‚úÖ 8 componentes principais
- ‚úÖ 26 testes unit√°rios (100% passando)
- ‚úÖ Backward compatible
- ‚úÖ Prometheus metrics completo
- ‚úÖ Structured logging
- ‚úÖ Circuit breakers para resili√™ncia

**Expectativa Realista**:
- **Cen√°rio Conservador**: 40-50 c√¢meras (3x ganho)
- **Cen√°rio Otimista**: 80-100 c√¢meras (6x ganho)
- **Cen√°rio M√°ximo**: 100+ c√¢meras (requer tuning fino)

**Commit para Deploy**: `69f5985`

**Pr√≥ximo Milestone**: Documenta√ß√£o + Deploy Gradual + Monitoramento
</file>

<file path="docs/guides/monitoring.md">
# Monitoramento\n\nEm desenvolvimento.
</file>

<file path="docs/guides/performance-analysis.md">
# An√°lise de Performance e Capacidade

## üéØ Resumo Executivo

**Capacidade Atual Estimada:** 15-30 c√¢meras simult√¢neas  
**FPS Configurado:** 30 FPS por c√¢mera  
**Gargalos Identificados:** 8 pontos cr√≠ticos  
**Melhorias Propostas:** 12 otimiza√ß√µes que podem aumentar para 100+ c√¢meras

---

## üìä An√°lise de Capacidade Atual

### Configura√ß√£o Atual
```yaml
target_fps: 30  # 30 frames por segundo por c√¢mera
cameras: 5      # 5 c√¢meras configuradas
```

### C√°lculo de Throughput

**Por C√¢mera (30 FPS):**
- Intervalo entre frames: ~33ms
- Tempo de captura FFmpeg: ~50-100ms (vari√°vel)
- Tempo de processamento: ~10-20ms
- **Total por frame: ~100ms**
- **Throughput real: ~10 FPS efetivo**

**Sistema Completo:**
```
5 c√¢meras √ó 10 FPS = 50 frames/segundo total
Lat√™ncia m√©dia: 100-200ms por frame
CPU: ~40-60% (5 c√¢meras)
Mem√≥ria: ~200-500MB (5 c√¢meras)
```

### Estimativa de Escalabilidade

| C√¢meras | FPS Real | CPU Estimado | RAM Estimada | Status |
|---------|----------|--------------|--------------|--------|
| 5       | 10 FPS   | 40-60%       | 300 MB       | ‚úÖ OK |
| 10      | 8-10 FPS | 70-80%       | 600 MB       | ‚ö†Ô∏è Limite |
| 15      | 6-8 FPS  | 85-95%       | 900 MB       | ‚ùå Cr√≠tico |
| 20+     | <5 FPS   | 100%         | 1.2+ GB      | ‚ùå Invi√°vel |

**Conclus√£o:** Com a arquitetura atual, o sistema suporta **15-20 c√¢meras no m√°ximo** antes de degrada√ß√£o severa.

---

## üîç Gargalos Identificados

### 1. ‚ö†Ô∏è Captura S√≠ncrona com FFmpeg (CR√çTICO)

**Problema:**
```go
// pkg/camera/camera.go:68
cmd := exec.CommandContext(c.ctx, "ffmpeg", ...)
err := cmd.Run()  // BLOQUEANTE - aguarda FFmpeg terminar
```

**Impacto:**
- Cada captura bloqueia por 50-100ms
- Processo FFmpeg criado/destru√≠do a cada frame
- Overhead de fork/exec enorme
- CPU 100% com 15+ c√¢meras

**Solu√ß√£o Proposta:**
```go
// Usar FFmpeg em modo streaming persistente
type PersistentCapture struct {
    cmd    *exec.Cmd
    stdout io.ReadCloser
    stdin  io.WriteCloser
}

func (pc *PersistentCapture) CaptureFrame() ([]byte, error) {
    // FFmpeg j√° rodando, apenas l√™ pr√≥ximo frame
    return pc.readNextFrame()
}
```

**Ganho Esperado:** 3-5x mais c√¢meras (30-50 c√¢meras)

---

### 2. ‚ö†Ô∏è Goroutines Ilimitadas (CR√çTICO)

**Problema:**
```go
// pkg/camera/camera.go:111
if c.redisStore.Enabled() {
    go func() {  // Nova goroutine POR FRAME
        // Salva no Redis
        // Publica metadata
    }()
}
```

**Impacto:**
- 5 c√¢meras √ó 10 FPS = 50 goroutines/segundo
- 20 c√¢meras √ó 10 FPS = 200 goroutines/segundo
- Memory leak potencial
- Overhead de scheduling

**Solu√ß√£o Proposta:**
```go
// Worker pool pattern
type WorkerPool struct {
    jobs    chan FrameJob
    workers int
}

func NewWorkerPool(workers int) *WorkerPool {
    wp := &WorkerPool{
        jobs:    make(chan FrameJob, 1000),
        workers: workers,
    }
    
    for i := 0; i < workers; i++ {
        go wp.worker()
    }
    
    return wp
}

func (wp *WorkerPool) worker() {
    for job := range wp.jobs {
        job.Process()
    }
}
```

**Ganho Esperado:** 2x mais c√¢meras (30-40 c√¢meras)

---

### 3. ‚ö†Ô∏è Aus√™ncia de Buffer/Queue (ALTO)

**Problema:**
- Sem fila de frames pendentes
- Frames descartados se processamento atrasa
- Picos de lat√™ncia n√£o s√£o absorvidos

**Solu√ß√£o Proposta:**
```go
type FrameBuffer struct {
    frames chan Frame
    size   int
}

func NewFrameBuffer(size int) *FrameBuffer {
    return &FrameBuffer{
        frames: make(chan Frame, size),
        size:   size,
    }
}

func (fb *FrameBuffer) Push(frame Frame) error {
    select {
    case fb.frames <- frame:
        return nil
    default:
        // Buffer cheio, pode descartar frame mais antigo
        <-fb.frames
        fb.frames <- frame
        return ErrBufferFull
    }
}
```

**Ganho Esperado:** Redu√ß√£o de 50% em frames perdidos

---

### 4. ‚ö†Ô∏è Timestamp Hardcoded (M√âDIO)

**Problema:**
```go
// pkg/camera/camera.go:115
width, height := 1280, 720  // TODO: Obter do frame real
```

**Impacto:**
- Metadata imprecisa
- N√£o detecta mudan√ßas de resolu√ß√£o
- Imposs√≠vel otimizar por resolu√ß√£o

**Solu√ß√£o Proposta:**
```go
func extractFrameInfo(data []byte) (width, height int, err error) {
    // Usar biblioteca de imagem para detectar dimens√µes
    img, _, err := image.DecodeConfig(bytes.NewReader(data))
    if err != nil {
        return 0, 0, err
    }
    return img.Width, img.Height, nil
}
```

**Ganho Esperado:** Metadata precisa, otimiza√ß√µes futuras

---

### 5. ‚ö†Ô∏è Logging Excessivo (M√âDIO)

**Problema:**
```go
log.Printf("capturado frame da camera %s (%d bytes)", c.config.ID, len(frameData))
// Log a cada frame = 50+ logs/segundo com 5 c√¢meras
```

**Impacto:**
- I/O disk intensivo
- CPU desperdi√ßada em formata√ß√£o
- Logs gigantes

**Solu√ß√£o Proposta:**
```go
// Usar n√≠veis de log e sampling
if frameCount%100 == 0 {  // Log apenas 1 a cada 100 frames
    logger.Debug("Stats",
        zap.String("camera", c.config.ID),
        zap.Int("frames", frameCount),
        zap.Duration("avg_latency", avgLatency))
}
```

**Ganho Esperado:** 10-15% CPU liberada

---

### 6. ‚ö†Ô∏è Compress√£o N√£o Otimizada (M√âDIO)

**Problema:**
```yaml
compression:
  enabled: false  # Desabilitado na config atual
```

**Impacto:**
- Frames JPEG sem otimiza√ß√£o
- Tamanho t√≠pico: 50-200 KB/frame
- Bandwidth RabbitMQ: 5 c√¢meras √ó 10 FPS √ó 100 KB = 5 MB/s

**Solu√ß√£o Proposta:**
```go
// Ajustar qualidade JPEG dinamicamente
func (c *Capture) optimizeQuality(bandwidth float64) int {
    if bandwidth > 10.0 {  // MB/s
        return 5  // Alta qualidade
    } else if bandwidth > 5.0 {
        return 10  // M√©dia qualidade
    }
    return 15  // Baixa qualidade
}
```

**Ganho Esperado:** 30-50% redu√ß√£o de bandwidth

---

### 7. ‚ö†Ô∏è Redis TTL Fixo (BAIXO)

**Problema:**
```yaml
redis:
  ttl_seconds: 300  # 5 minutos fixo
```

**Impacto:**
- Frames antigos ocupam mem√≥ria desnecessariamente
- Redis pode ficar saturado com muitas c√¢meras

**Solu√ß√£o Proposta:**
```go
// TTL din√¢mico baseado em uso
func (rs *RedisStore) calculateTTL(cameraID string) time.Duration {
    accessFreq := rs.getAccessFrequency(cameraID)
    
    if accessFreq > 10 {  // Acessos por minuto
        return 10 * time.Minute  // C√¢mera muito acessada
    } else if accessFreq > 1 {
        return 5 * time.Minute
    }
    return 1 * time.Minute  // C√¢mera pouco acessada
}
```

**Ganho Esperado:** 40% redu√ß√£o de uso de mem√≥ria Redis

---

### 8. ‚ö†Ô∏è Aus√™ncia de Circuit Breaker (ALTO)

**Problema:**
- Sem prote√ß√£o contra falhas em cascata
- Uma c√¢mera offline pode afetar outras
- Reconnection storms ao RabbitMQ/Redis

**Solu√ß√£o Proposta:**
```go
type CircuitBreaker struct {
    maxFailures int
    timeout     time.Duration
    state       State  // Closed, Open, HalfOpen
}

func (cb *CircuitBreaker) Call(fn func() error) error {
    if cb.state == Open {
        if time.Since(cb.lastFailure) > cb.timeout {
            cb.state = HalfOpen
        } else {
            return ErrCircuitOpen
        }
    }
    
    err := fn()
    if err != nil {
        cb.failures++
        if cb.failures >= cb.maxFailures {
            cb.state = Open
            cb.lastFailure = time.Now()
        }
    } else if cb.state == HalfOpen {
        cb.state = Closed
        cb.failures = 0
    }
    
    return err
}
```

**Ganho Esperado:** 99% uptime, resil√™ncia a falhas

---

## üöÄ Plano de Otimiza√ß√£o Recomendado

### Fase 1: Quick Wins (1-2 dias)

#### 1.1 Implementar Worker Pool
```go
// cmd/edge-video/main.go
workerPool := NewWorkerPool(runtime.NumCPU() * 2)

for _, camCfg := range cfg.Cameras {
    capture := camera.NewCapture(
        ctx,
        camera.Config{ID: camCfg.ID, URL: camCfg.URL},
        interval,
        compressor,
        publisher,
        redisStore,
        metaPublisher,
        workerPool,  // <-- Novo par√¢metro
    )
    capture.Start()
}
```

**Resultado:** 2x capacidade (30 c√¢meras)

#### 1.2 Reduzir Logging
```go
// Usar structured logging com n√≠veis
logger := zap.NewProduction()
defer logger.Sync()

// Apenas erros e warnings em produ√ß√£o
if err != nil {
    logger.Error("capture failed",
        zap.String("camera", c.config.ID),
        zap.Error(err))
}
```

**Resultado:** 10% CPU liberada

#### 1.3 Adicionar Frame Buffer
```go
type Capture struct {
    // ...campos existentes...
    frameBuffer *FrameBuffer
}

func (c *Capture) captureAndPublish() {
    // ...captura frame...
    
    // Enfileira ao inv√©s de processar imediatamente
    c.frameBuffer.Push(Frame{
        CameraID: c.config.ID,
        Data:     frameData,
        Timestamp: time.Now(),
    })
}
```

**Resultado:** 50% menos frames perdidos

---

### Fase 2: Otimiza√ß√µes M√©dias (3-5 dias)

#### 2.1 FFmpeg Persistente
```go
type PersistentFFmpeg struct {
    cmd       *exec.Cmd
    stdout    *bufio.Reader
    frameChan chan []byte
}

func (pf *PersistentFFmpeg) Start(url string) error {
    pf.cmd = exec.Command("ffmpeg",
        "-rtsp_transport", "tcp",
        "-i", url,
        "-f", "image2pipe",
        "-vcodec", "mjpeg",
        "-q:v", "5",
        "-r", "10",  // 10 FPS fixo
        "-",
    )
    
    stdout, _ := pf.cmd.StdoutPipe()
    pf.stdout = bufio.NewReader(stdout)
    
    go pf.readFrames()
    return pf.cmd.Start()
}

func (pf *PersistentFFmpeg) readFrames() {
    for {
        frame, err := pf.readJPEG()
        if err != nil {
            break
        }
        pf.frameChan <- frame
    }
}
```

**Resultado:** 3-5x capacidade (50-100 c√¢meras)

#### 2.2 Compress√£o Adaptativa
```go
func (c *Capture) adaptiveCompress(data []byte) []byte {
    size := len(data)
    
    if size > 200*1024 {  // > 200 KB
        // Alta compress√£o
        return c.compressor.Compress(data, 9)
    } else if size > 100*1024 {  // > 100 KB
        // M√©dia compress√£o
        return c.compressor.Compress(data, 5)
    }
    // Sem compress√£o para frames pequenos
    return data
}
```

**Resultado:** 40% redu√ß√£o bandwidth

#### 2.3 Circuit Breaker
```go
type Capture struct {
    // ...campos existentes...
    circuitBreaker *CircuitBreaker
}

func (c *Capture) captureAndPublish() {
    err := c.circuitBreaker.Call(func() error {
        return c.doCapture()
    })
    
    if err == ErrCircuitOpen {
        log.Printf("circuit open for camera %s, skipping", c.config.ID)
        return
    }
}
```

**Resultado:** Sistema resiliente a falhas

---

### Fase 3: Arquitetura Avan√ßada (1-2 semanas)

#### 3.1 Distributed Processing
```go
// Separar captura de processamento
type CaptureService struct {
    cameras []*Camera
    queue   *DistributedQueue  // Redis Streams ou Kafka
}

type ProcessingService struct {
    queue     *DistributedQueue
    workers   []*Worker
}

// Permite escalar horizontalmente:
// - 1 inst√¢ncia de CaptureService
// - N inst√¢ncias de ProcessingService
```

**Resultado:** 200+ c√¢meras com m√∫ltiplos n√≥s

#### 3.2 Metrics e Observabilidade
```go
// Prometheus metrics
var (
    framesProcessed = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "frames_processed_total",
        },
        []string{"camera_id"},
    )
    
    captureLatency = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "capture_latency_seconds",
        },
        []string{"camera_id"},
    )
)
```

**Resultado:** Visibilidade total, auto-scaling informado

#### 3.3 GPU Acceleration (Opcional)
```go
// Usar GPU para decode/encode se dispon√≠vel
import "github.com/giorgisio/goav/avcodec"

type GPUDecoder struct {
    codec *avcodec.Codec
}

func (gd *GPUDecoder) DecodeFrame(data []byte) (*Frame, error) {
    // Decode em GPU usando NVDEC/QuickSync
    return gd.decode(data)
}
```

**Resultado:** 500+ c√¢meras com GPU dedicada

---

## üìà Roadmap de Capacidade

### Hoje (Baseline)
```
Arquitetura: Atual
C√¢meras: 15-20
FPS Real: 6-10
CPU: 100%
Status: ‚ö†Ô∏è Limite t√©cnico
```

### Ap√≥s Fase 1 (Quick Wins)
```
Melhorias: Worker Pool + Buffer + Less Logging
C√¢meras: 30-40
FPS Real: 8-10
CPU: 80%
Status: ‚úÖ Produ√ß√£o est√°vel
Esfor√ßo: 2 dias
```

### Ap√≥s Fase 2 (Otimiza√ß√µes)
```
Melhorias: FFmpeg Persistente + Circuit Breaker
C√¢meras: 50-100
FPS Real: 8-10
CPU: 70%
Status: ‚úÖ Alta capacidade
Esfor√ßo: 1 semana
```

### Ap√≥s Fase 3 (Arquitetura Avan√ßada)
```
Melhorias: Distributed + GPU
C√¢meras: 200+
FPS Real: 10-30
CPU: 60% (distribu√≠do)
Status: ‚úÖ Enterprise grade
Esfor√ßo: 2 semanas
```

---

## üéØ Recomenda√ß√µes Imediatas

### Para Produ√ß√£o Hoje:
1. **Reduzir FPS para 5-10:** Mais realista e sustent√°vel
2. **Implementar Worker Pool:** 2 dias de trabalho, 2x capacidade
3. **Adicionar Monitoring:** Prometheus + Grafana

### Para Escalar (Pr√≥ximos 30 dias):
1. **FFmpeg Persistente:** Maior impacto na capacidade
2. **Circuit Breaker:** Essencial para produ√ß√£o
3. **Frame Buffer:** Reduz perda de frames

### Para Long-Term:
1. **Arquitetura Distribu√≠da:** Se precisar 100+ c√¢meras
2. **GPU Acceleration:** Para casos extremos (500+ c√¢meras)
3. **Edge Computing:** Processar localmente antes de enviar

---

## üìä Benchmarks Sugeridos

```bash
# Teste de carga com 1 c√¢mera
go test -bench=BenchmarkSingleCamera -benchtime=60s

# Teste de carga com N c√¢meras
go test -bench=BenchmarkMultipleCamera -benchtime=60s

# Profile de CPU
go test -cpuprofile=cpu.prof -bench=.
go tool pprof cpu.prof

# Profile de mem√≥ria
go test -memprofile=mem.prof -bench=.
go tool pprof mem.prof
```

---

## üîó Refer√™ncias

- [Go Concurrency Patterns](https://go.dev/blog/pipelines)
- [FFmpeg Streaming](https://trac.ffmpeg.org/wiki/StreamingGuide)
- [Worker Pool Pattern](https://gobyexample.com/worker-pools)
- [Circuit Breaker Pattern](https://martinfowler.com/bliki/CircuitBreaker.html)
- [Prometheus Best Practices](https://prometheus.io/docs/practices/)

---

**√öltima Atualiza√ß√£o:** 2025-11-07  
**Autor:** An√°lise T√©cnica de Performance
</file>

<file path="docs/guides/performance-summary.md">
# Resumo: Performance e Capacidade do Sistema

## üéØ Resposta R√°pida

**Quantas c√¢meras o sistema atual suporta?**
- **Hoje:** 15-20 c√¢meras (limite cr√≠tico)
- **Com otimiza√ß√µes simples:** 30-40 c√¢meras (2 dias de trabalho)
- **Com otimiza√ß√µes completas:** 50-100 c√¢meras (1 semana)
- **Com arquitetura distribu√≠da:** 200+ c√¢meras (2 semanas)

## üìä An√°lise Atual

### Configura√ß√£o
- **FPS configurado:** 30 FPS por c√¢mera
- **FPS real:** ~10 FPS (devido a gargalos)
- **C√¢meras ativas:** 5
- **CPU:** 40-60%
- **Mem√≥ria:** 300 MB

### Gargalos Cr√≠ticos

| # | Problema | Impacto | Solu√ß√£o | Esfor√ßo |
|---|----------|---------|---------|---------|
| 1 | FFmpeg recriado a cada frame | ‚ö†Ô∏è **CR√çTICO** | FFmpeg persistente | 3 dias |
| 2 | Goroutines ilimitadas | ‚ö†Ô∏è **CR√çTICO** | Worker Pool | 2 dias |
| 3 | Sem buffer de frames | ‚ö†Ô∏è **ALTO** | Frame Buffer | 1 dia |
| 4 | Logging excessivo | ‚ö†Ô∏è **M√âDIO** | Structured logging | 4 horas |
| 5 | Sem Circuit Breaker | ‚ö†Ô∏è **ALTO** | Circuit Breaker pattern | 2 dias |
| 6 | Sem m√©tricas | ‚ö†Ô∏è **M√âDIO** | Prometheus metrics | 1 dia |

## üöÄ Plano de A√ß√£o Recomendado

### Fase 1: Quick Wins (2 dias)
```
Implementar:
‚úÖ Worker Pool Pattern
‚úÖ Reduzir logging
‚úÖ Frame Buffer

Resultado:
üìà 2x capacidade: 30-40 c√¢meras
üíª 15% menos CPU
üß† 40% menos mem√≥ria
```

### Fase 2: Otimiza√ß√µes (1 semana)
```
Implementar:
‚úÖ FFmpeg persistente
‚úÖ Circuit Breaker
‚úÖ Compress√£o adaptativa

Resultado:
üìà 3-5x capacidade: 50-100 c√¢meras
üíª 30% menos CPU
üìä 99% uptime
```

### Fase 3: Escala Enterprise (2 semanas)
```
Implementar:
‚úÖ Arquitetura distribu√≠da
‚úÖ Prometheus + Grafana
‚úÖ Auto-scaling

Resultado:
üìà 10x+ capacidade: 200+ c√¢meras
üåç Multi-node deployment
üìä Observabilidade completa
```

## üí° Recomenda√ß√£o Imediata

Para produ√ß√£o **hoje**:

```yaml
# config.yaml - Configura√ß√£o otimizada
target_fps: 10  # Ao inv√©s de 30
protocol: amqp

optimization:
  max_workers: 16       # 2x CPU cores
  buffer_size: 500      # 100 por c√¢mera
  frame_quality: 10     # Reduzir qualidade se necess√°rio

cameras:
  # Limite a 15 c√¢meras por inst√¢ncia
```

**Justificativa:**
- 10 FPS √© suficiente para maioria dos casos
- Sistema mant√©m performance est√°vel
- Escalabilidade horizontal poss√≠vel (m√∫ltiplas inst√¢ncias)

## üìà C√°lculos de Capacidade

### Por C√¢mera (10 FPS)
```
Intervalo: 100ms/frame
FFmpeg: 50-80ms
Processamento: 10-20ms
Redis + MQ: 10-20ms
Total: ~100ms ‚úÖ
```

### Sistema Completo (Otimizado)

| C√¢meras | FPS | Frames/s Total | CPU | RAM | Status |
|---------|-----|----------------|-----|-----|--------|
| 10      | 10  | 100            | 40% | 400 MB | ‚úÖ OK |
| 20      | 10  | 200            | 60% | 600 MB | ‚úÖ OK |
| 30      | 10  | 300            | 75% | 900 MB | ‚ö†Ô∏è Alerta |
| 40      | 10  | 400            | 90% | 1.2 GB | ‚ùå Limite |

## üîó Documenta√ß√£o Completa

- **An√°lise Detalhada:** [performance-analysis.md](performance-analysis.md)
- **Implementa√ß√£o Worker Pool:** [worker-pool-implementation.md](worker-pool-implementation.md)
- **Guia de Monitoramento:** [monitoring.md](monitoring.md)
- **Troubleshooting:** [troubleshooting.md](troubleshooting.md)

## ‚úÖ Checklist de Otimiza√ß√£o

### Prioridade Alta (Fazer Agora)
- [ ] Implementar Worker Pool
- [ ] Adicionar Frame Buffer
- [ ] Reduzir FPS para 10
- [ ] Implementar structured logging
- [ ] Adicionar Prometheus metrics

### Prioridade M√©dia (Pr√≥ximas 2 Semanas)
- [ ] FFmpeg persistente
- [ ] Circuit Breaker
- [ ] Compress√£o adaptativa
- [ ] Grafana dashboards
- [ ] Load testing automatizado

### Prioridade Baixa (Roadmap)
- [ ] Arquitetura distribu√≠da
- [ ] GPU acceleration
- [ ] Auto-scaling din√¢mico
- [ ] Edge computing
- [ ] Machine learning para otimiza√ß√£o

---

**TL;DR:**
- **Hoje:** 15-20 c√¢meras (limite)
- **Quick wins (2 dias):** 30-40 c√¢meras
- **Otimizado (1 semana):** 50-100 c√¢meras
- **Enterprise (2 semanas):** 200+ c√¢meras

**A√ß√£o Imediata:** Implementar Worker Pool (2 dias, 2x capacidade)
</file>

<file path="docs/guides/troubleshooting.md">
# Troubleshooting\n\nEm desenvolvimento.
</file>

<file path="docs/guides/worker-pool-implementation.md">
# Implementa√ß√£o: Worker Pool Pattern

## üìã Objetivo

Substituir a cria√ß√£o ilimitada de goroutines por um pool controlado de workers, reduzindo overhead e melhorando performance.

## üéØ Ganho Esperado

- **2x** mais c√¢meras suportadas
- **30-40** c√¢meras simult√¢neas
- **50%** redu√ß√£o de aloca√ß√µes de mem√≥ria
- **CPU** mais previs√≠vel

## üìù Implementa√ß√£o

### 1. Criar Worker Pool

```go
// pkg/worker/pool.go
package worker

import (
	"context"
	"log"
	"time"
)

// Job representa uma tarefa a ser processada
type Job interface {
	Process(ctx context.Context) error
	GetID() string
}

// FrameJob √© um job espec√≠fico para processar frames
type FrameJob struct {
	CameraID   string
	FrameData  []byte
	Timestamp  time.Time
	RedisStore RedisStorer
	MetaPub    MetadataPublisher
}

func (fj *FrameJob) GetID() string {
	return fj.CameraID
}

func (fj *FrameJob) Process(ctx context.Context) error {
	// Salva no Redis
	if fj.RedisStore != nil && fj.RedisStore.Enabled() {
		width, height := 1280, 720 // TODO: Extrair do frame
		
		key, err := fj.RedisStore.SaveFrame(
			ctx,
			fj.CameraID,
			fj.Timestamp,
			fj.FrameData,
		)
		if err != nil {
			return fmt.Errorf("redis save error: %w", err)
		}
		
		// Publica metadata
		if fj.MetaPub != nil && fj.MetaPub.Enabled() {
			err = fj.MetaPub.PublishMetadata(
				fj.CameraID,
				fj.Timestamp,
				key,
				width,
				height,
				len(fj.FrameData),
				"jpeg",
			)
			if err != nil {
				return fmt.Errorf("metadata publish error: %w", err)
			}
		}
	}
	
	return nil
}

// Pool gerencia um conjunto fixo de workers
type Pool struct {
	jobs       chan Job
	results    chan error
	workers    int
	ctx        context.Context
	cancel     context.CancelFunc
	processing int32  // Contador at√¥mico de jobs em processamento
}

// NewPool cria um novo worker pool
func NewPool(ctx context.Context, workers int, bufferSize int) *Pool {
	ctx, cancel := context.WithCancel(ctx)
	
	pool := &Pool{
		jobs:    make(chan Job, bufferSize),
		results: make(chan error, bufferSize),
		workers: workers,
		ctx:     ctx,
		cancel:  cancel,
	}
	
	// Inicia os workers
	for i := 0; i < workers; i++ {
		go pool.worker(i)
	}
	
	// Inicia collector de resultados
	go pool.resultCollector()
	
	log.Printf("Worker pool inicializado com %d workers e buffer de %d", workers, bufferSize)
	
	return pool
}

// worker processa jobs da fila
func (p *Pool) worker(id int) {
	log.Printf("Worker %d iniciado", id)
	
	for {
		select {
		case <-p.ctx.Done():
			log.Printf("Worker %d parando", id)
			return
			
		case job, ok := <-p.jobs:
			if !ok {
				log.Printf("Worker %d: canal de jobs fechado", id)
				return
			}
			
			atomic.AddInt32(&p.processing, 1)
			
			// Processa o job
			err := job.Process(p.ctx)
			
			atomic.AddInt32(&p.processing, -1)
			
			// Envia resultado
			select {
			case p.results <- err:
			case <-p.ctx.Done():
				return
			default:
				// Descarta resultado se buffer estiver cheio
				if err != nil {
					log.Printf("Worker %d: descartando erro: %v", id, err)
				}
			}
		}
	}
}

// resultCollector processa resultados assincronamente
func (p *Pool) resultCollector() {
	errorCount := 0
	successCount := 0
	lastReport := time.Now()
	
	for {
		select {
		case <-p.ctx.Done():
			return
			
		case err, ok := <-p.results:
			if !ok {
				return
			}
			
			if err != nil {
				errorCount++
				// Log apenas erros cr√≠ticos
				if errorCount%100 == 0 {
					log.Printf("Worker pool: %d erros acumulados", errorCount)
				}
			} else {
				successCount++
			}
			
			// Reporta estat√≠sticas a cada minuto
			if time.Since(lastReport) > time.Minute {
				log.Printf("Worker pool stats: %d sucessos, %d erros, %d processando",
					successCount, errorCount, atomic.LoadInt32(&p.processing))
				lastReport = time.Now()
			}
		}
	}
}

// Submit envia um job para processamento
func (p *Pool) Submit(job Job) error {
	select {
	case p.jobs <- job:
		return nil
	case <-p.ctx.Done():
		return fmt.Errorf("pool fechado")
	default:
		return fmt.Errorf("buffer cheio: %d jobs aguardando", len(p.jobs))
	}
}

// SubmitNonBlocking tenta enviar um job sem bloquear
func (p *Pool) SubmitNonBlocking(job Job) bool {
	select {
	case p.jobs <- job:
		return true
	default:
		return false
	}
}

// Close para o pool gracefully
func (p *Pool) Close() {
	log.Println("Fechando worker pool...")
	
	// Para de aceitar novos jobs
	close(p.jobs)
	
	// Aguarda jobs em processamento terminarem (timeout de 5s)
	timeout := time.After(5 * time.Second)
	ticker := time.NewTicker(100 * time.Millisecond)
	defer ticker.Stop()
	
	for {
		select {
		case <-timeout:
			log.Printf("Timeout aguardando workers: %d jobs ainda processando",
				atomic.LoadInt32(&p.processing))
			p.cancel()
			return
			
		case <-ticker.C:
			if atomic.LoadInt32(&p.processing) == 0 {
				log.Println("Todos os workers finalizaram")
				p.cancel()
				return
			}
		}
	}
}

// Stats retorna estat√≠sticas do pool
func (p *Pool) Stats() PoolStats {
	return PoolStats{
		Workers:    p.workers,
		QueueSize:  len(p.jobs),
		Processing: int(atomic.LoadInt32(&p.processing)),
		Capacity:   cap(p.jobs),
	}
}

type PoolStats struct {
	Workers    int
	QueueSize  int
	Processing int
	Capacity   int
}

func (ps PoolStats) String() string {
	return fmt.Sprintf("Workers: %d, Queue: %d/%d, Processing: %d",
		ps.Workers, ps.QueueSize, ps.Capacity, ps.Processing)
}
```

### 2. Atualizar Capture para usar Worker Pool

```go
// pkg/camera/camera.go
package camera

import (
	// ...imports existentes...
	"github.com/T3-Labs/edge-video/pkg/worker"
	"sync/atomic"
)

type Capture struct {
	ctx           context.Context
	config        Config
	interval      time.Duration
	compressor    *util.Compressor
	publisher     mq.Publisher
	redisStore    *storage.RedisStore
	metaPublisher *metadata.Publisher
	workerPool    *worker.Pool  // NOVO
	
	// M√©tricas
	frameCount    int64
	errorCount    int64
	lastFrameTime time.Time
}

func NewCapture(
	ctx context.Context,
	config Config,
	interval time.Duration,
	compressor *util.Compressor,
	publisher mq.Publisher,
	redisStore *storage.RedisStore,
	metaPublisher *metadata.Publisher,
	workerPool *worker.Pool,  // NOVO par√¢metro
) *Capture {
	return &Capture{
		ctx:           ctx,
		config:        config,
		interval:      interval,
		compressor:    compressor,
		publisher:     publisher,
		redisStore:    redisStore,
		metaPublisher: metaPublisher,
		workerPool:    workerPool,  // NOVO
		lastFrameTime: time.Now(),
	}
}

func (c *Capture) captureAndPublish() {
	// ...c√≥digo de captura existente...
	
	frameData := stdout.Bytes()
	if len(frameData) == 0 {
		atomic.AddInt64(&c.errorCount, 1)
		return
	}
	
	atomic.AddInt64(&c.frameCount, 1)
	c.lastFrameTime = time.Now()
	
	// Publica√ß√£o principal (s√≠ncrona)
	err = c.publisher.Publish(c.ctx, c.config.ID, frameData)
	if err != nil {
		atomic.AddInt64(&c.errorCount, 1)
		// Log apenas a cada 100 erros
		if atomic.LoadInt64(&c.errorCount)%100 == 0 {
			log.Printf("camera %s: %d erros de publica√ß√£o", c.config.ID, c.errorCount)
		}
		return
	}
	
	// Opera√ß√µes ass√≠ncronas via Worker Pool
	if c.redisStore.Enabled() && c.workerPool != nil {
		job := &worker.FrameJob{
			CameraID:   c.config.ID,
			FrameData:  frameData,
			Timestamp:  time.Now(),
			RedisStore: c.redisStore,
			MetaPub:    c.metaPublisher,
		}
		
		// Tenta enviar sem bloquear
		if !c.workerPool.SubmitNonBlocking(job) {
			// Pool cheio, descarta frame ou loga warning
			if atomic.LoadInt64(&c.frameCount)%100 == 0 {
				log.Printf("camera %s: worker pool cheio, frame descartado", c.config.ID)
			}
		}
	}
}

// GetStats retorna estat√≠sticas da c√¢mera
func (c *Capture) GetStats() CameraStats {
	return CameraStats{
		CameraID:      c.config.ID,
		FrameCount:    atomic.LoadInt64(&c.frameCount),
		ErrorCount:    atomic.LoadInt64(&c.errorCount),
		LastFrameTime: c.lastFrameTime,
		Uptime:        time.Since(c.lastFrameTime),
	}
}

type CameraStats struct {
	CameraID      string
	FrameCount    int64
	ErrorCount    int64
	LastFrameTime time.Time
	Uptime        time.Duration
}
```

### 3. Atualizar main.go

```go
// cmd/edge-video/main.go
package main

import (
	"context"
	"log"
	"os"
	"os/signal"
	"runtime"
	"syscall"
	"time"

	"github.com/T3-Labs/edge-video/internal/metadata"
	"github.com/T3-Labs/edge-video/internal/storage"
	"github.com/T3-Labs/edge-video/pkg/camera"
	"github.com/T3-Labs/edge-video/pkg/config"
	"github.com/T3-Labs/edge-video/pkg/mq"
	"github.com/T3-Labs/edge-video/pkg/util"
	"github.com/T3-Labs/edge-video/pkg/worker"  // NOVO import
)

func main() {
	cfg, err := config.LoadConfig("config.toml")
	if err != nil {
		log.Fatalf("erro ao carregar config: %v", err)
	}

	interval := cfg.GetFrameInterval()

	// ... c√≥digo de setup do publisher existente ...

	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// NOVO: Criar Worker Pool
	// Workers = 2x n√∫cleos de CPU
	// Buffer = 100 jobs por c√¢mera
	numWorkers := runtime.NumCPU() * 2
	bufferSize := len(cfg.Cameras) * 100
	
	log.Printf("Criando worker pool: %d workers, buffer de %d", numWorkers, bufferSize)
	workerPool := worker.NewPool(ctx, numWorkers, bufferSize)
	defer workerPool.Close()

	// Inicia captures com worker pool
	captures := make([]*camera.Capture, 0, len(cfg.Cameras))
	
	for _, camCfg := range cfg.Cameras {
		capture := camera.NewCapture(
			ctx,
			camera.Config{ID: camCfg.ID, URL: camCfg.URL},
			interval,
			compressor,
			publisher,
			redisStore,
			metaPublisher,
			workerPool,  // NOVO: passa o worker pool
		)

		capture.Start()
		captures = append(captures, capture)
	}

	// NOVO: Goroutine para reportar stats
	go func() {
		ticker := time.NewTicker(30 * time.Second)
		defer ticker.Stop()
		
		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				// Stats do worker pool
				poolStats := workerPool.Stats()
				log.Printf("Worker Pool: %s", poolStats.String())
				
				// Stats das c√¢meras
				for _, capture := range captures {
					stats := capture.GetStats()
					log.Printf("Camera %s: %d frames, %d erros, √∫ltima captura h√° %v",
						stats.CameraID,
						stats.FrameCount,
						stats.ErrorCount,
						time.Since(stats.LastFrameTime))
				}
			}
		}
	}()

	// Graceful shutdown
	sig := make(chan os.Signal, 1)
	signal.Notify(sig, syscall.SIGINT, syscall.SIGTERM)
	<-sig
	
	log.Println("Recebido sinal, finalizando gracefully...")
	cancel()
	
	// Aguarda worker pool drenar
	log.Println("Aguardando worker pool finalizar...")
	time.Sleep(time.Second)
}
```

### 4. Adicionar ao config.yaml

```yaml
# config.yaml
target_fps: 10  # Reduzido para teste
protocol: amqp

# NOVO: Configura√ß√µes de otimiza√ß√£o
optimization:
  max_workers: 0  # 0 = auto (2 * CPU cores)
  buffer_size: 0  # 0 = auto (100 * num_cameras)
  frame_quality: 5
  frame_resolution: "1280x720"

cameras:
  - id: "cam1"
    url: "rtsp://..."
  # ... mais c√¢meras ...
```

## üß™ Testes

### 1. Teste Unit√°rio do Worker Pool

```go
// pkg/worker/pool_test.go
package worker

import (
	"context"
	"sync/atomic"
	"testing"
	"time"
)

type testJob struct {
	id        string
	processed *int32
}

func (tj *testJob) GetID() string {
	return tj.id
}

func (tj *testJob) Process(ctx context.Context) error {
	time.Sleep(10 * time.Millisecond)  // Simula trabalho
	atomic.AddInt32(tj.processed, 1)
	return nil
}

func TestWorkerPool(t *testing.T) {
	ctx := context.Background()
	pool := NewPool(ctx, 4, 100)
	defer pool.Close()

	var processed int32
	numJobs := 1000

	// Submete jobs
	for i := 0; i < numJobs; i++ {
		job := &testJob{
			id:        fmt.Sprintf("job-%d", i),
			processed: &processed,
		}
		err := pool.Submit(job)
		if err != nil {
			t.Fatalf("Erro ao submeter job: %v", err)
		}
	}

	// Aguarda processamento
	time.Sleep(3 * time.Second)

	// Verifica se todos foram processados
	if atomic.LoadInt32(&processed) != int32(numJobs) {
		t.Errorf("Esperado %d jobs processados, obteve %d",
			numJobs, atomic.LoadInt32(&processed))
	}
}

func BenchmarkWorkerPool(b *testing.B) {
	ctx := context.Background()
	pool := NewPool(ctx, runtime.NumCPU()*2, 1000)
	defer pool.Close()

	var processed int32

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		job := &testJob{
			id:        fmt.Sprintf("job-%d", i),
			processed: &processed,
		}
		_ = pool.Submit(job)
	}

	// Aguarda drenar
	for atomic.LoadInt32(&processed) < int32(b.N) {
		time.Sleep(10 * time.Millisecond)
	}
}
```

### 2. Teste de Integra√ß√£o

```bash
# Teste com 10 c√¢meras
./edge-video --config config.yaml

# Monitorar logs
tail -f app.log | grep "Worker Pool:"

# Esperado:
# Worker Pool: Workers: 16, Queue: 45/1000, Processing: 12
# Camera cam1: 300 frames, 0 erros, √∫ltima captura h√° 100ms
# Camera cam2: 295 frames, 2 erros, √∫ltima captura h√° 110ms
```

## üìä M√©tricas de Sucesso

### Antes (sem Worker Pool):
```
5 c√¢meras: 50 goroutines/segundo
CPU: 60%
Mem√≥ria: 400 MB
Lat√™ncia m√©dia: 150ms
```

### Depois (com Worker Pool):
```
10 c√¢meras: 16 workers fixos
CPU: 45%
Mem√≥ria: 250 MB
Lat√™ncia m√©dia: 100ms
```

### Ganhos:
- ‚úÖ **2x mais c√¢meras** (10 vs 5)
- ‚úÖ **25% menos CPU**
- ‚úÖ **37% menos mem√≥ria**
- ‚úÖ **33% menor lat√™ncia**

## üöÄ Pr√≥ximos Passos

1. **Frame Buffer**: Adicionar fila de frames antes do worker pool
2. **Circuit Breaker**: Proteger contra falhas em cascata
3. **Metrics**: Exportar para Prometheus
4. **Auto-scaling**: Ajustar n√∫mero de workers dinamicamente

---

**√öltima Atualiza√ß√£o:** 2025-11-07
</file>

<file path="docs/javascripts/extra.js">
// Custom JavaScript para Edge Video Documentation

document.addEventListener('DOMContentLoaded', function() {
  // Add copy button feedback
  document.querySelectorAll('.md-clipboard').forEach(function(button) {
    button.addEventListener('click', function() {
      const icon = button.querySelector('svg');
      if (icon) {
        icon.style.color = '#4caf50';
        setTimeout(() => {
          icon.style.color = '';
        }, 2000);
      }
    });
  });

  // Smooth scroll para √¢ncoras
  document.querySelectorAll('a[href^="#"]').forEach(anchor => {
    anchor.addEventListener('click', function (e) {
      const href = this.getAttribute('href');
      if (href !== '#') {
        e.preventDefault();
        const target = document.querySelector(href);
        if (target) {
          target.scrollIntoView({
            behavior: 'smooth',
            block: 'start'
          });
        }
      }
    });
  });

  // External links open in new tab
  document.querySelectorAll('a[href^="http"]').forEach(link => {
    if (!link.hostname.includes(window.location.hostname)) {
      link.setAttribute('target', '_blank');
      link.setAttribute('rel', 'noopener noreferrer');
    }
  });

  // Add badges to version numbers
  document.querySelectorAll('code').forEach(code => {
    const text = code.textContent;
    if (/^v?\d+\.\d+\.\d+$/.test(text)) {
      code.classList.add('badge', 'badge-info');
    }
  });
});

// Analytics (opcional - configurar se necess√°rio)
// window.dataLayer = window.dataLayer || [];
// function gtag(){dataLayer.push(arguments);}
// gtag('js', new Date());
// gtag('config', 'G-XXXXXXXXXX');
</file>

<file path="docs/javascripts/mathjax.js">
// MathJax Configuration
window.MathJax = {
  tex: {
    inlineMath: [["\\(", "\\)"]],
    displayMath: [["\\[", "\\]"]],
    processEscapes: true,
    processEnvironments: true
  },
  options: {
    ignoreHtmlClass: ".*|",
    processHtmlClass: "arithmatex"
  }
};

document$.subscribe(() => {
  MathJax.typesetPromise()
})
</file>

<file path="docs/stylesheets/extra.css">
/* Custom CSS para Edge Video Documentation */

/* Melhorias no grid de cards */
.md-typeset .grid.cards > :is(ul, ol) {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
  gap: 1rem;
}

/* Badges customizados */
.md-typeset .badge {
  display: inline-block;
  padding: 0.25rem 0.5rem;
  font-size: 0.75rem;
  font-weight: 700;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: 0.25rem;
}

.badge-success {
  background-color: #28a745;
}

.badge-warning {
  background-color: #ffc107;
  color: #212529;
}

.badge-danger {
  background-color: #dc3545;
}

.badge-info {
  background-color: #17a2b8;
}

/* Melhorias em tabelas */
.md-typeset table:not([class]) {
  border: 1px solid var(--md-default-fg-color--lightest);
  border-radius: 0.2rem;
  font-size: 0.85em;
}

.md-typeset table:not([class]) th {
  background-color: var(--md-code-bg-color);
  font-weight: 700;
}

/* Code blocks com t√≠tulo */
.md-typeset .highlight > pre > code {
  display: block;
  padding: 1em;
}

/* Admonitions customizados */
.md-typeset .admonition {
  border-left: 0.2rem solid;
  border-radius: 0.2rem;
  box-shadow: 0 0.2rem 0.5rem rgba(0, 0, 0, 0.05);
}

/* Stats cards */
.stats-card {
  background: var(--md-code-bg-color);
  border-radius: 0.5rem;
  padding: 1.5rem;
  text-align: center;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
}

.stats-card h3 {
  margin: 0;
  font-size: 2rem;
  color: var(--md-primary-fg-color);
}

.stats-card p {
  margin: 0.5rem 0 0;
  color: var(--md-default-fg-color--light);
}

/* Mermaid diagrams styling */
.mermaid {
  text-align: center;
  background: var(--md-code-bg-color);
  border-radius: 0.5rem;
  padding: 1rem;
}

/* Footer customizado */
.md-footer-meta {
  background-color: var(--md-footer-bg-color);
}

/* Anima√ß√µes suaves */
.md-typeset a {
  transition: color 0.125s;
}

.md-typeset .md-button {
  transition: all 0.2s ease-in-out;
}

.md-typeset .md-button:hover {
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
}

/* Breadcrumbs melhorados */
.md-path {
  font-size: 0.8rem;
  opacity: 0.7;
}

/* Search highlights */
.md-search-result__article--document {
  border-left: 3px solid var(--md-primary-fg-color);
}

/* Syntax highlighting customizado */
.md-typeset code {
  background-color: var(--md-code-bg-color);
  border-radius: 0.2rem;
  padding: 0.1em 0.3em;
}

/* Mobile improvements */
@media screen and (max-width: 76.1875em) {
  .md-typeset .grid.cards > :is(ul, ol) {
    grid-template-columns: 1fr;
  }
}

/* Print styles */
@media print {
  .md-header,
  .md-footer,
  .md-sidebar,
  .md-nav__link--active {
    display: none !important;
  }
}
</file>

<file path="docs/changelog.md">
# Changelog

Todas as mudan√ßas not√°veis neste projeto ser√£o documentadas neste arquivo.

O formato √© baseado em [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
e este projeto adere ao [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

<!-- towncrier release notes start -->

## [1.1.0] - 2025-11-06

### ‚ú® Features

- Convers√£o do formato de configura√ß√£o de YAML para TOML para melhor legibilidade e suporte nativo ([#[#1](https://github.com/T3-Labs/edge-video/issues/1)](https://github.com/T3-Labs/edge-video/issues/[#1](https://github.com/T3-Labs/edge-video/issues/1)))
- Implementa pipeline CI/CD com GitHub Actions para testes automatizados em qualquer branch ([#[#3](https://github.com/T3-Labs/edge-video/issues/3)](https://github.com/T3-Labs/edge-video/issues/[#3](https://github.com/T3-Labs/edge-video/issues/3)))
- Adiciona visualiza√ß√£o em tempo real de frames com OpenCV no script de teste Python ([#[#4](https://github.com/T3-Labs/edge-video/issues/4)](https://github.com/T3-Labs/edge-video/issues/[#4](https://github.com/T3-Labs/edge-video/issues/4)))

### üîí Security

- Adiciona autentica√ß√£o por senha para Redis com configura√ß√£o via config.toml ([#[#2](https://github.com/T3-Labs/edge-video/issues/2)](https://github.com/T3-Labs/edge-video/issues/[#2](https://github.com/T3-Labs/edge-video/issues/2)))
</file>

<file path="docs/MKDOCS_GUIDE.md">
# Guia de Configura√ß√£o: MkDocs Documentation

Este guia explica como trabalhar com a documenta√ß√£o do Edge Video usando MkDocs.

## üì¶ Instala√ß√£o Local

### 1. Instalar Depend√™ncias

```bash
# Criar ambiente virtual (recomendado)
python3 -m venv .venv-docs
source .venv-docs/bin/activate

# Instalar depend√™ncias
pip install -r requirements-docs.txt
```

### 2. Servir Documenta√ß√£o Localmente

```bash
# Servir com hot-reload
mkdocs serve

# Acessar em: http://localhost:8000
```

### 3. Build da Documenta√ß√£o

```bash
# Build para produ√ß√£o
mkdocs build

# Arquivos gerados em: site/
```

## üìù Estrutura da Documenta√ß√£o

```
docs/
‚îú‚îÄ‚îÄ index.md                 # P√°gina inicial
‚îú‚îÄ‚îÄ getting-started/         # Guia de in√≠cio
‚îÇ   ‚îú‚îÄ‚îÄ installation.md
‚îÇ   ‚îú‚îÄ‚îÄ configuration.md
‚îÇ   ‚îî‚îÄ‚îÄ quickstart.md
‚îú‚îÄ‚îÄ architecture/            # Arquitetura
‚îÇ   ‚îú‚îÄ‚îÄ overview.md
‚îÇ   ‚îú‚îÄ‚îÄ components.md
‚îÇ   ‚îî‚îÄ‚îÄ data-flow.md
‚îú‚îÄ‚îÄ features/                # Funcionalidades
‚îÇ   ‚îú‚îÄ‚îÄ camera-capture.md
‚îÇ   ‚îú‚îÄ‚îÄ redis-storage.md
‚îÇ   ‚îú‚îÄ‚îÄ metadata.md
‚îÇ   ‚îî‚îÄ‚îÄ message-queue.md
‚îú‚îÄ‚îÄ guides/                  # Guias pr√°ticos
‚îÇ   ‚îú‚îÄ‚îÄ docker.md
‚îÇ   ‚îú‚îÄ‚îÄ advanced-config.md
‚îÇ   ‚îú‚îÄ‚îÄ monitoring.md
‚îÇ   ‚îî‚îÄ‚îÄ troubleshooting.md
‚îú‚îÄ‚îÄ development/             # Desenvolvimento
‚îÇ   ‚îú‚îÄ‚îÄ contributing.md
‚îÇ   ‚îú‚îÄ‚îÄ precommit-towncrier.md
‚îÇ   ‚îú‚îÄ‚îÄ testing.md
‚îÇ   ‚îî‚îÄ‚îÄ cicd.md
‚îú‚îÄ‚îÄ api/                     # API Reference
‚îÇ   ‚îú‚îÄ‚îÄ config.md
‚îÇ   ‚îú‚îÄ‚îÄ camera.md
‚îÇ   ‚îú‚îÄ‚îÄ storage.md
‚îÇ   ‚îî‚îÄ‚îÄ mq.md
‚îú‚îÄ‚îÄ about/                   # Sobre
‚îÇ   ‚îú‚îÄ‚îÄ license.md
‚îÇ   ‚îî‚îÄ‚îÄ credits.md
‚îú‚îÄ‚îÄ changelog.md             # Changelog
‚îú‚îÄ‚îÄ stylesheets/             # CSS customizado
‚îÇ   ‚îî‚îÄ‚îÄ extra.css
‚îî‚îÄ‚îÄ javascripts/             # JS customizado
    ‚îú‚îÄ‚îÄ extra.js
    ‚îî‚îÄ‚îÄ mathjax.js
```

## ‚úçÔ∏è Escrevendo Documenta√ß√£o

### Sintaxe B√°sica

```markdown
# T√≠tulo H1

## T√≠tulo H2

Par√°grafo com **negrito** e *it√°lico*.

- Lista item 1
- Lista item 2

1. Lista numerada
2. Item 2

[Link](https://exemplo.com)

![Imagem](path/to/image.png)

\```python
# Bloco de c√≥digo
print("Hello World")
\```
```

### Admonitions

```markdown
!!! note "Nota"
    Conte√∫do da nota

!!! tip "Dica"
    Dica √∫til

!!! warning "Aviso"
    Conte√∫do de aviso

!!! danger "Perigo"
    Alerta importante
```

### Tabs

```markdown
=== "Tab 1"

    Conte√∫do da tab 1

=== "Tab 2"

    Conte√∫do da tab 2
```

### Diagramas Mermaid

```markdown
\```mermaid
graph LR
    A[In√≠cio] --> B[Processo]
    B --> C[Fim]
\```
```

### Grids

```markdown
<div class="grid cards" markdown>

-   :material-icon:{ .lg } **T√≠tulo**
    
    Descri√ß√£o

-   :material-icon:{ .lg } **T√≠tulo 2**
    
    Descri√ß√£o 2

</div>
```

## üöÄ Deploy

### GitHub Pages (Autom√°tico via CI)

O deploy √© feito automaticamente pelo GitHub Actions quando voc√™ faz push para `main`.

**Workflow:** `.github/workflows/mkdocs.yml`

### Deploy Manual

```bash
# Build e deploy
mkdocs gh-deploy

# Ou especificar branch
mkdocs gh-deploy --force
```

## üé® Customiza√ß√£o

### Adicionar Nova P√°gina

1. Criar arquivo em `docs/`
2. Adicionar no `nav` em `mkdocs.yml`

```yaml
nav:
  - Home: index.md
  - Nova Se√ß√£o:
      - Nova P√°gina: nova-secao/pagina.md
```

### Modificar Tema

Editar `mkdocs.yml`:

```yaml
theme:
  palette:
    primary: indigo
    accent: blue
```

### Adicionar CSS Customizado

Editar `docs/stylesheets/extra.css`

### Adicionar JavaScript

Editar `docs/javascripts/extra.js`

## üìä Plugins Dispon√≠veis

| Plugin | Descri√ß√£o |
|--------|-----------|
| `search` | Busca na documenta√ß√£o |
| `git-revision-date-localized` | Data de √∫ltima modifica√ß√£o |
| `minify` | Minifica√ß√£o de HTML/CSS/JS |
| `awesome-pages` | Navega√ß√£o autom√°tica |

## üîß Comandos √öteis

### Desenvolvimento

```bash
# Servir com hot-reload
mkdocs serve

# Servir em porta espec√≠fica
mkdocs serve -a 0.0.0.0:8080

# Build
mkdocs build

# Build strict (falha em warnings)
mkdocs build --strict
```

### Valida√ß√£o

```bash
# Verificar links quebrados
mkdocs build --strict

# Validar configura√ß√£o
mkdocs --version
python -m mkdocs --help
```

### Limpeza

```bash
# Remover site/ gerado
rm -rf site/
```

## üéØ Boas Pr√°ticas

### 1. Estrutura Clara
- Use hierarquia l√≥gica de pastas
- Nomes de arquivos descritivos
- URLs amig√°veis (sem espa√ßos)

### 2. Conte√∫do
- Par√°grafos curtos e objetivos
- Use listas para facilitar leitura
- Adicione exemplos pr√°ticos
- Inclua screenshots quando relevante

### 3. Links
- Use links relativos entre p√°ginas
- Verifique links externos periodicamente
- Adicione `target="_blank"` para links externos

### 4. Imagens
- Otimize tamanho das imagens
- Use formatos modernos (WebP, SVG)
- Adicione alt text descritivo

### 5. Code Blocks
- Especifique a linguagem
- Use syntax highlighting
- Adicione coment√°rios explicativos

## üìö Recursos

- [MkDocs Documentation](https://www.mkdocs.org/)
- [Material for MkDocs](https://squidfunk.github.io/mkdocs-material/)
- [Markdown Guide](https://www.markdownguide.org/)
- [Mermaid Diagrams](https://mermaid.js.org/)

## üêõ Troubleshooting

### Erro: "Config file not found"

```bash
# Verificar se mkdocs.yml existe
ls -la mkdocs.yml

# Executar do diret√≥rio raiz
cd /path/to/edge-video
mkdocs serve
```

### Erro: "Template not found"

```bash
# Reinstalar mkdocs-material
pip install --force-reinstall mkdocs-material
```

### P√°ginas n√£o aparecem

```bash
# Verificar nav em mkdocs.yml
cat mkdocs.yml | grep -A 20 "^nav:"

# Verificar se arquivo existe
ls -la docs/path/to/file.md
```

---

**Data de cria√ß√£o:** 2025-11-06  
**√öltima atualiza√ß√£o:** Veja rodap√© das p√°ginas
</file>

<file path="docs/PRECOMMIT_TOWNCRIER_GUIDE.md">
# Guia de Configura√ß√£o: Pre-commit + Towncrier

Este guia mostra como configurar e usar o sistema de changelog autom√°tico com Towncrier e pre-commit hooks.

## üì¶ Instala√ß√£o

### 1. Instalar Pre-commit

```bash
# Via pip
pip install pre-commit

# Ou via pipx (recomendado)
pipx install pre-commit

# Verificar instala√ß√£o
pre-commit --version
```

### 2. Instalar Towncrier

```bash
# Via pip
pip install towncrier

# Ou adicionar ao requirements
echo "towncrier>=23.11.0" >> requirements-dev.txt
pip install -r requirements-dev.txt
```

### 3. Instalar os Hooks

```bash
# Instalar hooks do pre-commit no reposit√≥rio
pre-commit install

# Instalar hook para mensagens de commit (commitizen)
pre-commit install --hook-type commit-msg

# Verificar instala√ß√£o
pre-commit --version
```

## üöÄ Uso Di√°rio

### Workflow Completo:

#### 1. **Fazer Mudan√ßas no C√≥digo**
```bash
git checkout -b feature/nova-funcionalidade
# ... fazer mudan√ßas ...
```

#### 2. **Criar Fragment de Changelog**
```bash
# Sintaxe: <numero>.tipo.md
# Tipos: feature, bugfix, docs, removal, security, performance, refactor, misc

# Exemplo 1: Nova funcionalidade
echo "Adiciona suporte a PostgreSQL" > changelog.d/$(date +%s).feature.md

# Exemplo 2: Corre√ß√£o de bug
echo "Corrige memory leak no processamento de frames" > changelog.d/$(date +%s).bugfix.md

# Exemplo 3: Com n√∫mero de issue
echo "Implementa retry autom√°tico para falhas de rede" > changelog.d/123.feature.md
```

#### 3. **Fazer Commit**
```bash
git add .
git commit -m "feat: adiciona suporte a PostgreSQL"
```

**O que acontece automaticamente:**
- ‚úÖ C√≥digo Go √© formatado (gofmt)
- ‚úÖ Imports s√£o organizados (goimports)
- ‚úÖ `go mod tidy` √© executado
- ‚úÖ Lint √© executado (go vet)
- ‚úÖ Verifica se h√° changelog fragment (towncrier-check)
- ‚úÖ Valida formato do commit (commitizen)
- ‚úÖ Detecta segredos no c√≥digo
- ‚úÖ Valida arquivos YAML/TOML/JSON

#### 4. **Push para Remote**
```bash
git push origin feature/nova-funcionalidade
```

## üìù Gerando o CHANGELOG

### Quando Criar Release:

```bash
# 1. Merge todas as features para main
git checkout main
git merge develop

# 2. Gerar CHANGELOG para nova vers√£o
towncrier build --version 1.0.0

# Isso ir√°:
# - Coletar todos os fragments de changelog.d/
# - Gerar as notas de release no CHANGELOG.md
# - Remover os fragments processados

# 3. Commit e tag
git add CHANGELOG.md
git commit -m "chore: release v1.0.0"
git tag -a v1.0.0 -m "Release v1.0.0"
git push origin main --tags
```

### Preview do CHANGELOG (Dry Run):

```bash
# Ver como ficar√° o changelog sem modificar arquivos
towncrier build --version 1.0.0 --draft
```

## üéØ Tipos de Changelog Fragments

| Tipo | Emoji | Descri√ß√£o | Exemplo |
|------|-------|-----------|---------|
| `feature` | ‚ú® | Nova funcionalidade | Adiciona cache Redis |
| `bugfix` | üêõ | Corre√ß√£o de bug | Corrige race condition |
| `docs` | üìö | Documenta√ß√£o | Atualiza README com exemplos |
| `removal` | üóëÔ∏è | Remo√ß√£o/deprecia√ß√£o | Remove API v1 depreciada |
| `security` | üîí | Corre√ß√£o de seguran√ßa | Adiciona valida√ß√£o de entrada |
| `performance` | ‚ö° | Melhoria de performance | Otimiza query de banco de dados |
| `refactor` | ‚ôªÔ∏è | Refatora√ß√£o | Reestrutura m√≥dulo de cache |
| `misc` | üîß | Outras mudan√ßas | Atualiza depend√™ncias |

## üîß Comandos √öteis

### Pre-commit:

```bash
# Executar todos os hooks manualmente
pre-commit run --all-files

# Executar hook espec√≠fico
pre-commit run go-fmt --all-files
pre-commit run towncrier-check --all-files

# Atualizar vers√µes dos hooks
pre-commit autoupdate

# Desinstalar hooks
pre-commit uninstall

# Bypass hooks temporariamente
git commit --no-verify -m "commit sem hooks"
```

### Towncrier:

```bash
# Listar fragments pendentes
ls -la changelog.d/*.md

# Validar configura√ß√£o
towncrier --help

# Gerar changelog sem remover fragments
towncrier build --version 1.0.0 --keep

# Gerar changelog automaticamente
towncrier build --version 1.0.0 --yes
```

## üõ†Ô∏è Troubleshooting

### Erro: "towncrier-check failed"

**Problema:** Voc√™ tentou fazer commit sem criar um fragment de changelog.

**Solu√ß√£o:**
```bash
# Op√ß√£o 1: Criar fragment
echo "Sua mudan√ßa aqui" > changelog.d/$(date +%s).feature.md
git add changelog.d/
git commit -m "feat: sua mudan√ßa"

# Op√ß√£o 2: Bypass (n√£o recomendado)
git commit --no-verify -m "feat: sua mudan√ßa"
```

### Erro: "go-fmt failed"

**Problema:** C√≥digo n√£o est√° formatado corretamente.

**Solu√ß√£o:**
```bash
# Pre-commit j√° formatou automaticamente
git add -u
git commit -m "feat: sua mudan√ßa"
```

### Erro: "commitizen failed"

**Problema:** Mensagem de commit n√£o segue o formato Conventional Commits.

**Solu√ß√£o:**
Use o formato: `tipo: descri√ß√£o`

Tipos v√°lidos:
- `feat:` - nova funcionalidade
- `fix:` - corre√ß√£o de bug
- `docs:` - mudan√ßas na documenta√ß√£o
- `refactor:` - refatora√ß√£o de c√≥digo
- `test:` - adiciona ou corrige testes
- `chore:` - mudan√ßas em build, CI, etc.
- `perf:` - melhoria de performance
- `style:` - mudan√ßas de formata√ß√£o

**Exemplo:**
```bash
git commit -m "feat: adiciona suporte a PostgreSQL"
```

### Erro: "detect-secrets failed"

**Problema:** Poss√≠vel segredo detectado no c√≥digo.

**Solu√ß√£o:**
```bash
# Revisar o arquivo apontado
# Se for falso positivo, atualizar baseline:
detect-secrets scan --baseline .secrets.baseline

# E commitar
git add .secrets.baseline
```

## üé® Customiza√ß√£o

### Modificar Tipos de Fragments:

Edite `pyproject.toml`:

```toml
[[tool.towncrier.type]]
directory = "breaking"
name = "üí• Breaking Changes"
showcontent = true
```

### Modificar Hooks do Pre-commit:

Edite `.pre-commit-config.yaml`:

```yaml
repos:
  - repo: https://github.com/seu/hook
    rev: v1.0.0
    hooks:
      - id: seu-hook
```

## üìö Recursos

- [Pre-commit Documentation](https://pre-commit.com/)
- [Towncrier Documentation](https://towncrier.readthedocs.io/)
- [Conventional Commits](https://www.conventionalcommits.org/)
- [Keep a Changelog](https://keepachangelog.com/)
- [Semantic Versioning](https://semver.org/)

## ü§ù Contribuindo

Ao contribuir com este projeto:

1. ‚úÖ **Sempre crie um fragment de changelog** para suas mudan√ßas
2. ‚úÖ **Use commits sem√¢nticos** (feat:, fix:, docs:, etc.)
3. ‚úÖ **Deixe os hooks executarem** (n√£o use --no-verify sem necessidade)
4. ‚úÖ **Revise o preview do changelog** antes de criar release

---

**√öltima atualiza√ß√£o:** 2025-11-06
</file>

<file path="internal/storage/redis_store.go">
package storage

import (
	"context"
	"fmt"
	"time"

	"github.com/go-redis/redis/v8"
)

// RedisStore handles storing frames in Redis with a configurable TTL.
type RedisStore struct {
	client  *redis.Client
	ttl     time.Duration
	prefix  string
	enabled bool
}

// NewRedisStore creates a new RedisStore.
func NewRedisStore(addr string, ttlSeconds int, prefix string, enabled bool) *RedisStore {
	if !enabled {
		return &RedisStore{enabled: false}
	}

	rdb := redis.NewClient(&redis.Options{
		Addr: addr,
	})

	return &RedisStore{
		client:  rdb,
		ttl:     time.Duration(ttlSeconds) * time.Second,
		prefix:  prefix,
		enabled: true,
	}
}

// Enabled returns true if the Redis store is enabled.
func (r *RedisStore) Enabled() bool {
	return r.enabled
}

// SaveFrame stores a frame in Redis with the configured TTL.
// The key is constructed as <prefix>:<cameraID>:<timestamp_RFC3339Nano>.
func (r *RedisStore) SaveFrame(ctx context.Context, cameraID string, timestamp time.Time, data []byte) (string, error) {
	if !r.enabled {
		return "", nil
	}

	key := fmt.Sprintf("%s:%s:%s", r.prefix, cameraID, timestamp.Format(time.RFC3339Nano))
	err := r.client.Set(ctx, key, data, r.ttl).Err()
	if err != nil {
		return "", fmt.Errorf("failed to save frame to redis: %w", err)
	}
	return key, nil
}
</file>

<file path="pkg/buffer/frame_buffer_test.go">
package buffer

import (
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
)

func TestNewFrameBuffer(t *testing.T) {
	buffer := NewFrameBuffer(10)
	
	assert.NotNil(t, buffer)
	assert.Equal(t, 10, buffer.Capacity())
	assert.Equal(t, 0, buffer.Size())
}

func TestFrameBufferPush(t *testing.T) {
	buffer := NewFrameBuffer(5)
	
	frame := Frame{
		CameraID:  "cam1",
		Data:      []byte("test data"),
		Timestamp: time.Now().Unix(),
		Metadata:  map[string]interface{}{"key": "value"},
	}
	
	err := buffer.Push(frame)
	assert.NoError(t, err)
	assert.Equal(t, 1, buffer.Size())
}

func TestFrameBufferPushFull(t *testing.T) {
	buffer := NewFrameBuffer(2)
	
	frame1 := Frame{CameraID: "cam1", Data: []byte("data1"), Timestamp: 1}
	frame2 := Frame{CameraID: "cam2", Data: []byte("data2"), Timestamp: 2}
	frame3 := Frame{CameraID: "cam3", Data: []byte("data3"), Timestamp: 3}
	
	err := buffer.Push(frame1)
	assert.NoError(t, err)
	
	err = buffer.Push(frame2)
	assert.NoError(t, err)
	
	err = buffer.Push(frame3)
	assert.Error(t, err)
	assert.Contains(t, err.Error(), "buffer cheio")
	
	stats := buffer.Stats()
	assert.Equal(t, int64(1), stats.DroppedFrames)
	assert.Equal(t, int64(3), stats.TotalFrames)
}

func TestFrameBufferPop(t *testing.T) {
	buffer := NewFrameBuffer(5)
	
	frame := Frame{
		CameraID:  "cam1",
		Data:      []byte("test"),
		Timestamp: 123456,
	}
	
	_ = buffer.Push(frame)
	
	popped, ok := buffer.Pop()
	assert.True(t, ok)
	assert.Equal(t, "cam1", popped.CameraID)
	assert.Equal(t, []byte("test"), popped.Data)
	assert.Equal(t, int64(123456), popped.Timestamp)
}

func TestFrameBufferPopEmpty(t *testing.T) {
	buffer := NewFrameBuffer(5)
	
	_, ok := buffer.Pop()
	assert.False(t, ok)
}

func TestFrameBufferStats(t *testing.T) {
	buffer := NewFrameBuffer(3)
	
	for i := 0; i < 5; i++ {
		frame := Frame{
			CameraID:  "cam1",
			Data:      []byte("data"),
			Timestamp: int64(i),
		}
		_ = buffer.Push(frame)
	}
	
	stats := buffer.Stats()
	
	assert.Equal(t, int64(5), stats.TotalFrames)
	assert.Equal(t, int64(2), stats.DroppedFrames)
	assert.Equal(t, 3, stats.Size)
	assert.Equal(t, 3, stats.Capacity)
	
	dropRate := (float64(2) / float64(5)) * 100
	assert.InDelta(t, dropRate, stats.DropRate, 0.01)
}

func TestFrameBufferClose(t *testing.T) {
	buffer := NewFrameBuffer(5)
	
	frame := Frame{CameraID: "cam1", Data: []byte("test")}
	_ = buffer.Push(frame)
	
	buffer.Close()
	
	_, ok := buffer.PopBlocking()
	assert.True(t, ok)
	
	_, ok = buffer.PopBlocking()
	assert.False(t, ok)
}

func TestFrameBufferConcurrent(t *testing.T) {
	buffer := NewFrameBuffer(100)
	
	done := make(chan bool)
	
	go func() {
		for i := 0; i < 50; i++ {
			frame := Frame{
				CameraID:  "cam1",
				Data:      []byte("data"),
				Timestamp: int64(i),
			}
			_ = buffer.Push(frame)
			time.Sleep(1 * time.Millisecond)
		}
		done <- true
	}()
	
	go func() {
		for i := 0; i < 50; i++ {
			buffer.Pop()
			time.Sleep(2 * time.Millisecond)
		}
		done <- true
	}()
	
	<-done
	<-done
	
	stats := buffer.Stats()
	assert.Equal(t, int64(50), stats.TotalFrames)
}

func BenchmarkFrameBufferPush(b *testing.B) {
	buffer := NewFrameBuffer(10000)
	
	frame := Frame{
		CameraID:  "cam1",
		Data:      make([]byte, 1024),
		Timestamp: time.Now().Unix(),
	}
	
	b.ResetTimer()
	
	for i := 0; i < b.N; i++ {
		_ = buffer.Push(frame)
	}
}

func BenchmarkFrameBufferPop(b *testing.B) {
	buffer := NewFrameBuffer(10000)
	
	for i := 0; i < 10000; i++ {
		frame := Frame{
			CameraID:  "cam1",
			Data:      []byte("data"),
			Timestamp: int64(i),
		}
		_ = buffer.Push(frame)
	}
	
	b.ResetTimer()
	
	for i := 0; i < b.N; i++ {
		buffer.Pop()
	}
}
</file>

<file path="pkg/buffer/frame_buffer.go">
package buffer

import (
	"fmt"
	"sync"
	"sync/atomic"
)

type Frame struct {
	CameraID  string
	Data      []byte
	Timestamp int64
	Metadata  map[string]interface{}
}

type FrameBuffer struct {
	buffer         chan Frame
	capacity       int
	droppedFrames  int64
	totalFrames    int64
	mu             sync.RWMutex
}

func NewFrameBuffer(capacity int) *FrameBuffer {
	return &FrameBuffer{
		buffer:   make(chan Frame, capacity),
		capacity: capacity,
	}
}

func (fb *FrameBuffer) Push(frame Frame) error {
	atomic.AddInt64(&fb.totalFrames, 1)
	
	select {
	case fb.buffer <- frame:
		return nil
	default:
		atomic.AddInt64(&fb.droppedFrames, 1)
		return fmt.Errorf("buffer cheio: frame descartado")
	}
}

func (fb *FrameBuffer) Pop() (Frame, bool) {
	select {
	case frame := <-fb.buffer:
		return frame, true
	default:
		return Frame{}, false
	}
}

func (fb *FrameBuffer) PopBlocking() (Frame, bool) {
	frame, ok := <-fb.buffer
	return frame, ok
}

func (fb *FrameBuffer) Size() int {
	return len(fb.buffer)
}

func (fb *FrameBuffer) Capacity() int {
	return fb.capacity
}

func (fb *FrameBuffer) Stats() BufferStats {
	dropped := atomic.LoadInt64(&fb.droppedFrames)
	total := atomic.LoadInt64(&fb.totalFrames)
	
	dropRate := float64(0)
	if total > 0 {
		dropRate = float64(dropped) / float64(total) * 100
	}
	
	return BufferStats{
		Size:          fb.Size(),
		Capacity:      fb.capacity,
		DroppedFrames: dropped,
		TotalFrames:   total,
		DropRate:      dropRate,
	}
}

func (fb *FrameBuffer) Close() {
	close(fb.buffer)
}

type BufferStats struct {
	Size          int
	Capacity      int
	DroppedFrames int64
	TotalFrames   int64
	DropRate      float64
}

func (bs BufferStats) String() string {
	return fmt.Sprintf("Buffer: %d/%d, Total: %d, Dropped: %d (%.2f%%)",
		bs.Size, bs.Capacity, bs.TotalFrames, bs.DroppedFrames, bs.DropRate)
}
</file>

<file path="pkg/circuit/breaker_test.go">
package circuit

import (
	"errors"
	"sync/atomic"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
)

func TestNewBreaker(t *testing.T) {
	breaker := NewBreaker("test", 3, 10*time.Second)
	
	assert.NotNil(t, breaker)
	assert.Equal(t, "test", breaker.name)
	assert.Equal(t, int64(3), breaker.maxFailures)
	assert.Equal(t, 10*time.Second, breaker.resetTimeout)
	assert.Equal(t, StateClosed, breaker.State())
}

func TestBreakerStateClosed(t *testing.T) {
	breaker := NewBreaker("test", 3, 1*time.Second)
	
	assert.Equal(t, StateClosed, breaker.State())
	
	err := breaker.Call(func() error {
		return nil
	})
	
	assert.NoError(t, err)
	assert.Equal(t, StateClosed, breaker.State())
}

func TestBreakerStateOpen(t *testing.T) {
	breaker := NewBreaker("test", 3, 1*time.Second)
	
	for i := 0; i < 3; i++ {
		_ = breaker.Call(func() error {
			return errors.New("test error")
		})
	}
	
	assert.Equal(t, StateOpen, breaker.State())
	
	err := breaker.Call(func() error {
		return nil
	})
	
	assert.Error(t, err)
	assert.Contains(t, err.Error(), "circuit breaker")
}

func TestBreakerStateHalfOpen(t *testing.T) {
	breaker := NewBreaker("test", 2, 100*time.Millisecond)
	
	_ = breaker.Call(func() error {
		return errors.New("error 1")
	})
	_ = breaker.Call(func() error {
		return errors.New("error 2")
	})
	
	assert.Equal(t, StateOpen, breaker.State())
	
	time.Sleep(150 * time.Millisecond)
	
	err := breaker.Call(func() error {
		return nil
	})
	
	assert.NoError(t, err)
}

func TestBreakerRecovery(t *testing.T) {
	breaker := NewBreaker("test", 2, 100*time.Millisecond)
	breaker.halfOpenSuccesses = 3
	
	breaker.RecordFailure()
	breaker.RecordFailure()
	
	assert.Equal(t, StateOpen, breaker.State())
	
	time.Sleep(150 * time.Millisecond)
	
	assert.True(t, breaker.Allow())
	
	for i := 0; i < 3; i++ {
		breaker.RecordSuccess()
	}
	
	assert.Equal(t, StateClosed, breaker.State())
}

func TestBreakerStats(t *testing.T) {
	breaker := NewBreaker("test", 5, 1*time.Second)
	
	breaker.RecordSuccess()
	breaker.RecordFailure()
	
	stats := breaker.Stats()
	
	assert.Equal(t, "test", stats.Name)
	assert.Equal(t, StateClosed, stats.State)
	assert.Equal(t, int64(1), stats.Failures)
}

func TestBreakerReset(t *testing.T) {
	breaker := NewBreaker("test", 2, 1*time.Second)
	
	breaker.RecordFailure()
	breaker.RecordFailure()
	
	assert.Equal(t, StateOpen, breaker.State())
	
	breaker.Reset()
	
	assert.Equal(t, StateClosed, breaker.State())
	assert.Equal(t, int64(0), breaker.failures)
	assert.Equal(t, int64(0), breaker.successes)
}

func TestBreakerHalfOpenFailure(t *testing.T) {
	breaker := NewBreaker("test", 2, 50*time.Millisecond)
	
	breaker.RecordFailure()
	breaker.RecordFailure()
	assert.Equal(t, StateOpen, breaker.State())
	
	time.Sleep(100 * time.Millisecond)
	
	assert.True(t, breaker.Allow())
	assert.Equal(t, StateHalfOpen, breaker.State())
	
	breaker.RecordFailure()
	assert.Equal(t, StateOpen, breaker.State())
}

func TestBreakerConcurrent(t *testing.T) {
	breaker := NewBreaker("test", 50, 1*time.Second)
	
	done := make(chan bool)
	successCount := int64(0)
	failureCount := int64(0)
	
	for i := 0; i < 10; i++ {
		go func() {
			for j := 0; j < 100; j++ {
				if j%2 == 0 {
					breaker.RecordSuccess()
					atomic.AddInt64(&successCount, 1)
				} else {
					breaker.RecordFailure()
					atomic.AddInt64(&failureCount, 1)
				}
			}
			done <- true
		}()
	}
	
	for i := 0; i < 10; i++ {
		<-done
	}
	
	total := atomic.LoadInt64(&successCount) + atomic.LoadInt64(&failureCount)
	assert.Equal(t, int64(1000), total)
}

func BenchmarkBreakerCall(b *testing.B) {
	breaker := NewBreaker("test", 1000, 10*time.Second)
	
	b.ResetTimer()
	
	for i := 0; i < b.N; i++ {
		_ = breaker.Call(func() error {
			return nil
		})
	}
}
</file>

<file path="pkg/circuit/breaker.go">
package circuit

import (
	"fmt"
	"sync"
	"time"
)

type State int

const (
	StateClosed State = iota
	StateOpen
	StateHalfOpen
)

func (s State) String() string {
	switch s {
	case StateClosed:
		return "CLOSED"
	case StateOpen:
		return "OPEN"
	case StateHalfOpen:
		return "HALF_OPEN"
	default:
		return "UNKNOWN"
	}
}

type Breaker struct {
	name              string
	maxFailures       int64
	resetTimeout      time.Duration
	halfOpenSuccesses int
	
	mu            sync.RWMutex
	state         State
	failures      int64
	successes     int64
	lastFailTime  time.Time
	lastStateTime time.Time
}

func NewBreaker(name string, maxFailures int64, resetTimeout time.Duration) *Breaker {
	return &Breaker{
		name:              name,
		maxFailures:       maxFailures,
		resetTimeout:      resetTimeout,
		halfOpenSuccesses: 3,
		state:             StateClosed,
		lastStateTime:     time.Now(),
	}
}

func (cb *Breaker) Call(fn func() error) error {
	if !cb.Allow() {
		return fmt.Errorf("circuit breaker %s aberto", cb.name)
	}
	
	err := fn()
	
	if err != nil {
		cb.RecordFailure()
		return err
	}
	
	cb.RecordSuccess()
	return nil
}

func (cb *Breaker) Allow() bool {
	cb.mu.Lock()
	defer cb.mu.Unlock()
	
	switch cb.state {
	case StateClosed:
		return true
		
	case StateOpen:
		if time.Since(cb.lastFailTime) > cb.resetTimeout {
			cb.setState(StateHalfOpen)
			return true
		}
		return false
		
	case StateHalfOpen:
		return true
		
	default:
		return false
	}
}

func (cb *Breaker) RecordSuccess() {
	cb.mu.Lock()
	defer cb.mu.Unlock()
	
	cb.successes++
	
	switch cb.state {
	case StateClosed:
		cb.failures = 0
		
	case StateHalfOpen:
		if cb.successes >= int64(cb.halfOpenSuccesses) {
			cb.setState(StateClosed)
			cb.failures = 0
			cb.successes = 0
		}
	}
}

func (cb *Breaker) RecordFailure() {
	cb.mu.Lock()
	defer cb.mu.Unlock()
	
	cb.failures++
	cb.lastFailTime = time.Now()
	cb.successes = 0
	
	switch cb.state {
	case StateClosed:
		if cb.failures >= cb.maxFailures {
			cb.setState(StateOpen)
		}
		
	case StateHalfOpen:
		cb.setState(StateOpen)
	}
}

func (cb *Breaker) setState(newState State) {
	if cb.state != newState {
		oldState := cb.state
		cb.state = newState
		cb.lastStateTime = time.Now()
		fmt.Printf("Circuit breaker %s: %s -> %s (falhas: %d)\n",
			cb.name, oldState, newState, cb.failures)
	}
}

func (cb *Breaker) State() State {
	cb.mu.RLock()
	defer cb.mu.RUnlock()
	return cb.state
}

func (cb *Breaker) Stats() BreakerStats {
	cb.mu.RLock()
	defer cb.mu.RUnlock()
	
	return BreakerStats{
		Name:            cb.name,
		State:           cb.state,
		Failures:        cb.failures,
		Successes:       cb.successes,
		MaxFailures:     cb.maxFailures,
		LastFailTime:    cb.lastFailTime,
		LastStateChange: cb.lastStateTime,
	}
}

func (cb *Breaker) Reset() {
	cb.mu.Lock()
	defer cb.mu.Unlock()
	
	cb.state = StateClosed
	cb.failures = 0
	cb.successes = 0
	cb.lastStateTime = time.Now()
}

type BreakerStats struct {
	Name            string
	State           State
	Failures        int64
	Successes       int64
	MaxFailures     int64
	LastFailTime    time.Time
	LastStateChange time.Time
}

func (bs BreakerStats) String() string {
	return fmt.Sprintf("Circuit[%s]: %s, Failures: %d/%d, Successes: %d",
		bs.Name, bs.State, bs.Failures, bs.MaxFailures, bs.Successes)
}
</file>

<file path="pkg/logger/logger.go">
package logger

import (
	"go.uber.org/zap"
)

var (
	Log *zap.SugaredLogger
)

func InitLogger(development bool) error {
	var logger *zap.Logger
	var err error
	
	if development {
		config := zap.NewDevelopmentConfig()
		config.Sampling = &zap.SamplingConfig{
			Initial:    100,
			Thereafter: 100,
		}
		logger, err = config.Build()
	} else {
		config := zap.NewProductionConfig()
		config.Sampling = &zap.SamplingConfig{
			Initial:    100,
			Thereafter: 100,
		}
		logger, err = config.Build()
	}
	
	if err != nil {
		return err
	}
	
	Log = logger.Sugar()
	return nil
}

func Sync() {
	if Log != nil {
		_ = Log.Sync()
	}
}

func WithFields(fields map[string]interface{}) *zap.SugaredLogger {
	if Log == nil {
		return nil
	}
	
	keyValuePairs := make([]interface{}, 0, len(fields)*2)
	for k, v := range fields {
		keyValuePairs = append(keyValuePairs, k, v)
	}
	
	return Log.With(keyValuePairs...)
}
</file>

<file path="pkg/metrics/collector.go">
package metrics

import (
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
)

var (
	FramesProcessed = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "edge_video_frames_processed_total",
			Help: "Total de frames processados por c√¢mera",
		},
		[]string{"camera_id"},
	)
	
	FramesDropped = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "edge_video_frames_dropped_total",
			Help: "Total de frames descartados por c√¢mera",
		},
		[]string{"camera_id", "reason"},
	)
	
	CaptureLatency = promauto.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "edge_video_capture_latency_seconds",
			Help:    "Lat√™ncia de captura de frames",
			Buckets: []float64{.001, .005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5},
		},
		[]string{"camera_id"},
	)
	
	WorkerPoolQueueSize = promauto.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "edge_video_worker_pool_queue_size",
			Help: "Tamanho atual da fila do worker pool",
		},
		[]string{"pool_name"},
	)
	
	WorkerPoolProcessing = promauto.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "edge_video_worker_pool_processing",
			Help: "N√∫mero de jobs em processamento",
		},
		[]string{"pool_name"},
	)
	
	BufferSize = promauto.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "edge_video_buffer_size",
			Help: "Tamanho atual do buffer de frames",
		},
		[]string{"camera_id"},
	)
	
	CircuitBreakerState = promauto.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "edge_video_circuit_breaker_state",
			Help: "Estado do circuit breaker (0=closed, 1=open, 2=half-open)",
		},
		[]string{"breaker_name"},
	)
	
	CameraConnected = promauto.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "edge_video_camera_connected",
			Help: "Status de conex√£o da c√¢mera (0=desconectada, 1=conectada)",
		},
		[]string{"camera_id"},
	)
	
	PublishLatency = promauto.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "edge_video_publish_latency_seconds",
			Help:    "Lat√™ncia de publica√ß√£o de mensagens",
			Buckets: []float64{.001, .005, .01, .025, .05, .1, .25, .5, 1},
		},
		[]string{"publisher_type"},
	)
	
	StorageOperations = promauto.NewCounterVec(
		prometheus.CounterOpts{
			Name: "edge_video_storage_operations_total",
			Help: "Total de opera√ß√µes de armazenamento",
		},
		[]string{"operation", "status"},
	)
	
	FrameSizeBytes = promauto.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "edge_video_frame_size_bytes",
			Help:    "Tamanho dos frames em bytes",
			Buckets: []float64{1024, 5120, 10240, 51200, 102400, 512000, 1048576},
		},
		[]string{"camera_id"},
	)
)
</file>

<file path="pkg/worker/pool_test.go">
package worker

import (
	"context"
	"errors"
	"sync/atomic"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
)

type TestJob struct {
	id        string
	shouldErr bool
	delay     time.Duration
	processed int32
}

func (j *TestJob) GetID() string {
	return j.id
}

func (j *TestJob) Process(ctx context.Context) error {
	if j.delay > 0 {
		time.Sleep(j.delay)
	}
	
	atomic.AddInt32(&j.processed, 1)
	
	if j.shouldErr {
		return errors.New("test error")
	}
	
	return nil
}

func TestNewPool(t *testing.T) {
	ctx := context.Background()
	pool := NewPool(ctx, 5, 10)
	
	assert.NotNil(t, pool)
	assert.Equal(t, 5, pool.workers)
	assert.Equal(t, 10, cap(pool.jobs))
	
	pool.Close()
}

func TestPoolSubmit(t *testing.T) {
	ctx := context.Background()
	pool := NewPool(ctx, 2, 10)
	defer pool.Close()
	
	job := &TestJob{id: "test1"}
	
	err := pool.Submit(job)
	assert.NoError(t, err)
	
	time.Sleep(100 * time.Millisecond)
	
	assert.Equal(t, int32(1), atomic.LoadInt32(&job.processed))
}

func TestPoolSubmitMultiple(t *testing.T) {
	ctx := context.Background()
	pool := NewPool(ctx, 5, 100)
	defer pool.Close()
	
	jobCount := 50
	jobs := make([]*TestJob, jobCount)
	
	for i := 0; i < jobCount; i++ {
		jobs[i] = &TestJob{
			id:    string(rune(i)),
			delay: 10 * time.Millisecond,
		}
		err := pool.Submit(jobs[i])
		assert.NoError(t, err)
	}
	
	time.Sleep(2 * time.Second)
	
	for i, job := range jobs {
		assert.Equal(t, int32(1), atomic.LoadInt32(&job.processed),
			"Job %d n√£o foi processado", i)
	}
	
	stats := pool.Stats()
	assert.Equal(t, int64(jobCount), stats.TotalProcessed)
}

func TestPoolBufferFull(t *testing.T) {
	ctx := context.Background()
	pool := NewPool(ctx, 1, 2)
	defer pool.Close()
	
	job1 := &TestJob{id: "job1", delay: 1 * time.Second}
	job2 := &TestJob{id: "job2", delay: 1 * time.Second}
	job3 := &TestJob{id: "job3", delay: 1 * time.Second}
	
	err := pool.Submit(job1)
	assert.NoError(t, err)
	
	time.Sleep(10 * time.Millisecond)
	
	err = pool.Submit(job2)
	assert.NoError(t, err)
	
	err = pool.Submit(job3)
	assert.NoError(t, err)
	
	err = pool.Submit(&TestJob{id: "job4"})
	assert.Error(t, err)
	assert.Contains(t, err.Error(), "buffer cheio")
	
	time.Sleep(3 * time.Second)
	
	stats := pool.Stats()
	assert.Equal(t, int64(3), stats.TotalProcessed)
}

func TestPoolWithErrors(t *testing.T) {
	ctx := context.Background()
	pool := NewPool(ctx, 2, 10)
	defer pool.Close()
	
	successJob := &TestJob{id: "success", shouldErr: false}
	errorJob := &TestJob{id: "error", shouldErr: true}
	
	err := pool.Submit(successJob)
	assert.NoError(t, err)
	
	err = pool.Submit(errorJob)
	assert.NoError(t, err)
	
	time.Sleep(200 * time.Millisecond)
	
	stats := pool.Stats()
	assert.Equal(t, int64(2), stats.TotalProcessed)
	assert.Equal(t, int64(1), stats.TotalErrors)
}

func TestPoolClose(t *testing.T) {
	ctx := context.Background()
	pool := NewPool(ctx, 2, 10)
	
	job := &TestJob{id: "test", delay: 100 * time.Millisecond}
	err := pool.Submit(job)
	assert.NoError(t, err)
	
	time.Sleep(200 * time.Millisecond)
	
	pool.Close()
	
	assert.Equal(t, int32(1), atomic.LoadInt32(&job.processed))
}

func TestPoolStats(t *testing.T) {
	ctx := context.Background()
	pool := NewPool(ctx, 3, 20)
	defer pool.Close()
	
	stats := pool.Stats()
	assert.Equal(t, 3, stats.Workers)
	assert.Equal(t, 20, stats.Capacity)
	assert.Equal(t, int64(0), stats.TotalProcessed)
	assert.Equal(t, int64(0), stats.TotalErrors)
	
	for i := 0; i < 10; i++ {
		job := &TestJob{
			id:        string(rune(i)),
			shouldErr: i%3 == 0,
		}
		_ = pool.Submit(job)
	}
	
	time.Sleep(500 * time.Millisecond)
	
	stats = pool.Stats()
	assert.Equal(t, int64(10), stats.TotalProcessed)
	assert.Greater(t, stats.TotalErrors, int64(0))
}

func BenchmarkPoolSubmit(b *testing.B) {
	ctx := context.Background()
	pool := NewPool(ctx, 10, 1000)
	defer pool.Close()
	
	b.ResetTimer()
	
	for i := 0; i < b.N; i++ {
		job := &TestJob{id: string(rune(i))}
		_ = pool.Submit(job)
	}
	
	pool.Close()
}
</file>

<file path="pkg/worker/pool.go">
package worker

import (
	"context"
	"fmt"
	"log"
	"sync/atomic"
	"time"
)

type Job interface {
	Process(ctx context.Context) error
	GetID() string
}

type Pool struct {
	jobs       chan Job
	results    chan error
	workers    int
	ctx        context.Context
	cancel     context.CancelFunc
	processing int32
	
	totalProcessed int64
	totalErrors    int64
}

func NewPool(ctx context.Context, workers int, bufferSize int) *Pool {
	ctx, cancel := context.WithCancel(ctx)
	
	pool := &Pool{
		jobs:    make(chan Job, bufferSize),
		results: make(chan error, bufferSize),
		workers: workers,
		ctx:     ctx,
		cancel:  cancel,
	}
	
	for i := 0; i < workers; i++ {
		go pool.worker(i)
	}
	
	go pool.resultCollector()
	
	log.Printf("Worker pool inicializado: %d workers, buffer de %d", workers, bufferSize)
	
	return pool
}

func (p *Pool) worker(id int) {
	for {
		select {
		case <-p.ctx.Done():
			return
			
		case job, ok := <-p.jobs:
			if !ok {
				return
			}
			
			atomic.AddInt32(&p.processing, 1)
			
			err := job.Process(p.ctx)
			
			atomic.AddInt32(&p.processing, -1)
			atomic.AddInt64(&p.totalProcessed, 1)
			
			if err != nil {
				atomic.AddInt64(&p.totalErrors, 1)
			}
			
			select {
			case p.results <- err:
			case <-p.ctx.Done():
				return
			default:
			}
		}
	}
}

func (p *Pool) resultCollector() {
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()
	
	for {
		select {
		case <-p.ctx.Done():
			return
			
		case <-ticker.C:
			processed := atomic.LoadInt64(&p.totalProcessed)
			errors := atomic.LoadInt64(&p.totalErrors)
			if processed > 0 {
				errorRate := float64(errors) / float64(processed) * 100
				log.Printf("Worker pool stats: %d processados, %d erros (%.2f%%), %d em processamento",
					processed, errors, errorRate, atomic.LoadInt32(&p.processing))
			}
			
		case err := <-p.results:
			if err != nil {
				errorCount := atomic.LoadInt64(&p.totalErrors)
				if errorCount%100 == 0 {
					log.Printf("Worker pool: %d erros acumulados", errorCount)
				}
			}
		}
	}
}

func (p *Pool) Submit(job Job) error {
	select {
	case p.jobs <- job:
		return nil
	case <-p.ctx.Done():
		return fmt.Errorf("pool fechado")
	default:
		return fmt.Errorf("buffer cheio")
	}
}

func (p *Pool) SubmitNonBlocking(job Job) bool {
	select {
	case p.jobs <- job:
		return true
	default:
		return false
	}
}

func (p *Pool) Close() {
	log.Println("Fechando worker pool...")
	close(p.jobs)
	
	timeout := time.After(5 * time.Second)
	ticker := time.NewTicker(100 * time.Millisecond)
	defer ticker.Stop()
	
	for {
		select {
		case <-timeout:
			log.Printf("Timeout: %d jobs ainda processando", atomic.LoadInt32(&p.processing))
			p.cancel()
			return
			
		case <-ticker.C:
			if atomic.LoadInt32(&p.processing) == 0 {
				log.Println("Worker pool finalizado")
				p.cancel()
				return
			}
		}
	}
}

func (p *Pool) Stats() PoolStats {
	return PoolStats{
		Workers:        p.workers,
		QueueSize:      len(p.jobs),
		Processing:     int(atomic.LoadInt32(&p.processing)),
		Capacity:       cap(p.jobs),
		TotalProcessed: atomic.LoadInt64(&p.totalProcessed),
		TotalErrors:    atomic.LoadInt64(&p.totalErrors),
	}
}

type PoolStats struct {
	Workers        int
	QueueSize      int
	Processing     int
	Capacity       int
	TotalProcessed int64
	TotalErrors    int64
}

func (ps PoolStats) String() string {
	return fmt.Sprintf("Workers: %d, Queue: %d/%d, Processing: %d, Total: %d (erros: %d)",
		ps.Workers, ps.QueueSize, ps.Capacity, ps.Processing, ps.TotalProcessed, ps.TotalErrors)
}
</file>

<file path="scripts/build-changelog.sh">
#!/usr/bin/env bash
# Script helper para gerar CHANGELOG com Towncrier
# Uso: ./scripts/build-changelog.sh <vers√£o>

set -euo pipefail

# Cores
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

show_help() {
    cat << EOF
üìö Helper para Gerar CHANGELOG

Uso: $0 [op√ß√µes] <vers√£o>

Op√ß√µes:
  -h, --help      Mostra esta mensagem
  -d, --draft     Preview sem modificar arquivos
  -k, --keep      Mant√©m os fragments ap√≥s gerar
  -y, --yes       N√£o pede confirma√ß√£o

Exemplos:
  $0 1.0.0                    # Gera changelog para v1.0.0
  $0 --draft 1.0.0            # Preview do changelog
  $0 --keep 1.0.0             # Gera mas mant√©m fragments
  $0 --yes 1.0.0              # Gera sem pedir confirma√ß√£o

EOF
}

# Defaults
DRAFT=false
KEEP=false
YES=false
VERSION=""

# Processar argumentos
while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help)
            show_help
            exit 0
            ;;
        -d|--draft)
            DRAFT=true
            shift
            ;;
        -k|--keep)
            KEEP=true
            shift
            ;;
        -y|--yes)
            YES=true
            shift
            ;;
        *)
            VERSION=$1
            shift
            ;;
    esac
done

# Validar vers√£o
if [ -z "$VERSION" ]; then
    echo -e "${RED}‚ùå Erro: Vers√£o n√£o especificada${NC}" >&2
    echo -e "${YELLOW}Uso: $0 <vers√£o>${NC}" >&2
    exit 1
fi

# Remover 'v' prefixo se existir
VERSION=${VERSION#v}

# Verificar se towncrier est√° instalado
if ! command -v towncrier &> /dev/null; then
    echo -e "${RED}‚ùå Erro: towncrier n√£o est√° instalado${NC}" >&2
    echo -e "${YELLOW}Instale com: pip install towncrier${NC}" >&2
    exit 1
fi

# Contar fragments
FRAGMENT_COUNT=$(find changelog.d -name "*.md" ! -name "README.md" ! -name "template.md.j2" 2>/dev/null | wc -l)

if [ "$FRAGMENT_COUNT" -eq 0 ]; then
    echo -e "${YELLOW}‚ö†Ô∏è  Aviso: Nenhum fragment encontrado em changelog.d/${NC}"
    echo -e "${BLUE}‚ÑπÔ∏è  Nada para adicionar ao CHANGELOG${NC}"
    exit 0
fi

echo -e "${BLUE}üìã Fragments encontrados: ${FRAGMENT_COUNT}${NC}"
echo ""

# Listar fragments
echo -e "${BLUE}Fragments que ser√£o processados:${NC}"
for file in changelog.d/*.md; do
    [ -f "$file" ] || continue
    [[ "$file" == *"README.md" ]] && continue
    [[ "$file" == *"template.md.j2" ]] && continue
    
    filename=$(basename "$file")
    content=$(head -n1 "$file")
    type=$(echo "$filename" | cut -d'.' -f2)
    
    case $type in
        feature)     emoji="‚ú®" ;;
        bugfix)      emoji="üêõ" ;;
        docs)        emoji="üìö" ;;
        removal)     emoji="üóëÔ∏è" ;;
        security)    emoji="üîí" ;;
        performance) emoji="‚ö°" ;;
        refactor)    emoji="‚ôªÔ∏è" ;;
        misc)        emoji="üîß" ;;
        *)           emoji="üìÑ" ;;
    esac
    
    echo -e "  ${emoji} ${GREEN}${filename}${NC}: ${content}"
done
echo ""

# Construir comando
CMD="towncrier build --version ${VERSION}"

if [ "$DRAFT" = true ]; then
    CMD="$CMD --draft"
    echo -e "${YELLOW}üîç Modo DRAFT: Nenhum arquivo ser√° modificado${NC}"
    echo ""
fi

if [ "$KEEP" = true ]; then
    CMD="$CMD --keep"
fi

# Confirma√ß√£o
if [ "$YES" = false ] && [ "$DRAFT" = false ]; then
    echo -e "${YELLOW}‚ö†Ô∏è  Isso ir√°:${NC}"
    echo -e "   1. Atualizar ${BLUE}CHANGELOG.md${NC} com as mudan√ßas acima"
    if [ "$KEEP" = false ]; then
        echo -e "   2. ${RED}Remover${NC} os fragments processados"
    else
        echo -e "   2. ${GREEN}Manter${NC} os fragments (--keep ativado)"
    fi
    echo ""
    read -p "Continuar? (s/N) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Ss]$ ]]; then
        echo -e "${BLUE}‚ÑπÔ∏è  Opera√ß√£o cancelada${NC}"
        exit 0
    fi
fi

# Executar towncrier
echo -e "${BLUE}üî® Gerando CHANGELOG...${NC}"
echo ""

if $CMD; then
    if [ "$DRAFT" = true ]; then
        echo ""
        echo -e "${GREEN}‚úÖ Preview gerado com sucesso!${NC}"
        echo -e "${YELLOW}üí° Para gerar de verdade, execute sem --draft${NC}"
    else
        echo ""
        echo -e "${GREEN}‚úÖ CHANGELOG gerado com sucesso!${NC}"
        echo ""
        echo -e "${YELLOW}üí° Pr√≥ximos passos:${NC}"
        echo -e "   1. ${BLUE}git add CHANGELOG.md${NC}"
        if [ "$KEEP" = false ]; then
            echo -e "   2. ${BLUE}git add changelog.d/${NC} (fragments removidos)"
        fi
        echo -e "   3. ${BLUE}git commit -m \"chore: release v${VERSION}\"${NC}"
        echo -e "   4. ${BLUE}git tag -a v${VERSION} -m \"Release v${VERSION}\"${NC}"
        echo -e "   5. ${BLUE}git push origin main --tags${NC}"
    fi
else
    echo -e "${RED}‚ùå Erro ao gerar CHANGELOG${NC}" >&2
    exit 1
fi
</file>

<file path="scripts/new-changelog.sh">
#!/usr/bin/env bash
# Script helper para criar changelog fragments
# Uso: ./scripts/new-changelog.sh <tipo> "mensagem"

set -euo pipefail

# Cores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Fun√ß√£o de ajuda
show_help() {
    cat << EOF
üìù Helper para Criar Changelog Fragments

Uso: $0 <tipo> "mensagem" [issue-number]

Tipos dispon√≠veis:
  feature       ‚ú® Nova funcionalidade
  bugfix        üêõ Corre√ß√£o de bug
  docs          üìö Mudan√ßas na documenta√ß√£o
  removal       üóëÔ∏è  Remo√ß√µes e deprecia√ß√µes
  security      üîí Corre√ß√µes de seguran√ßa
  performance   ‚ö° Melhorias de performance
  refactor      ‚ôªÔ∏è  Refatora√ß√£o de c√≥digo
  misc          üîß Outras mudan√ßas

Exemplos:
  $0 feature "Adiciona suporte a PostgreSQL"
  $0 bugfix "Corrige memory leak" 123
  $0 docs "Atualiza README com novos exemplos"

Op√ß√µes:
  -h, --help    Mostra esta mensagem de ajuda
  -l, --list    Lista fragments existentes

EOF
}

# Listar fragments
list_fragments() {
    echo -e "${BLUE}üìã Fragments existentes:${NC}\n"
    if [ -d "changelog.d" ] && [ "$(ls -A changelog.d/*.md 2>/dev/null)" ]; then
        for file in changelog.d/*.md; do
            [ -f "$file" ] || continue
            filename=$(basename "$file")
            type=$(echo "$filename" | cut -d'.' -f2)
            content=$(head -n1 "$file")
            
            case $type in
                feature)     emoji="‚ú®" ;;
                bugfix)      emoji="üêõ" ;;
                docs)        emoji="üìö" ;;
                removal)     emoji="üóëÔ∏è" ;;
                security)    emoji="üîí" ;;
                performance) emoji="‚ö°" ;;
                refactor)    emoji="‚ôªÔ∏è" ;;
                misc)        emoji="üîß" ;;
                *)           emoji="üìÑ" ;;
            esac
            
            echo -e "${emoji} ${GREEN}${filename}${NC}: ${content}"
        done
    else
        echo -e "${YELLOW}Nenhum fragment encontrado em changelog.d/${NC}"
    fi
    echo ""
}

# Validar tipo
validate_type() {
    local type=$1
    case $type in
        feature|bugfix|docs|removal|security|performance|refactor|misc)
            return 0
            ;;
        *)
            echo -e "${RED}‚ùå Erro: Tipo inv√°lido '$type'${NC}" >&2
            echo -e "${YELLOW}Tipos v√°lidos: feature, bugfix, docs, removal, security, performance, refactor, misc${NC}" >&2
            return 1
            ;;
    esac
}

# Processar argumentos
if [ $# -eq 0 ]; then
    show_help
    exit 1
fi

# Op√ß√µes
case "${1:-}" in
    -h|--help)
        show_help
        exit 0
        ;;
    -l|--list)
        list_fragments
        exit 0
        ;;
esac

# Validar argumentos
if [ $# -lt 2 ]; then
    echo -e "${RED}‚ùå Erro: Argumentos insuficientes${NC}" >&2
    echo -e "${YELLOW}Uso: $0 <tipo> \"mensagem\" [issue-number]${NC}" >&2
    exit 1
fi

TYPE=$1
MESSAGE=$2
ISSUE_NUMBER=${3:-$(date +%s)}

# Validar tipo
if ! validate_type "$TYPE"; then
    exit 1
fi

# Criar diret√≥rio se n√£o existir
mkdir -p changelog.d

# Nome do arquivo
FILENAME="changelog.d/${ISSUE_NUMBER}.${TYPE}.md"

# Verificar se j√° existe
if [ -f "$FILENAME" ]; then
    echo -e "${YELLOW}‚ö†Ô∏è  Aviso: Arquivo ${FILENAME} j√° existe${NC}"
    read -p "Deseja sobrescrever? (s/N) " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Ss]$ ]]; then
        echo -e "${BLUE}‚ÑπÔ∏è  Opera√ß√£o cancelada${NC}"
        exit 0
    fi
fi

# Criar fragment
echo "$MESSAGE" > "$FILENAME"

# Emoji para o tipo
case $TYPE in
    feature)     emoji="‚ú®" ;;
    bugfix)      emoji="üêõ" ;;
    docs)        emoji="üìö" ;;
    removal)     emoji="üóëÔ∏è" ;;
    security)    emoji="üîí" ;;
    performance) emoji="‚ö°" ;;
    refactor)    emoji="‚ôªÔ∏è" ;;
    misc)        emoji="üîß" ;;
esac

# Sucesso
echo -e "${GREEN}‚úÖ Fragment criado com sucesso!${NC}"
echo -e "${emoji} ${BLUE}Arquivo:${NC} $FILENAME"
echo -e "${BLUE}Conte√∫do:${NC} $MESSAGE"
echo ""
echo -e "${YELLOW}üí° Pr√≥ximos passos:${NC}"
echo -e "   1. ${BLUE}git add $FILENAME${NC}"
echo -e "   2. ${BLUE}git commit -m \"${TYPE}: ${MESSAGE}\"${NC}"
echo ""
</file>

<file path=".dockerignore">
/src/

/tests/

.DS_Store
.git
.gitignore
.vscode
.idea
node_modules
.env
*.log
*.tmp
*.bak
*.swp
*.old
*.cache
*.dist
*.zip
*.tar.gz
*.exe
*.dll
*.so
*.dylib


# Created by https://www.toptal.com/developers/gitignore/api/go,vs,visualstudio,pycharm,pycharm+iml,pycharm+all,goland,goland+all,goland+iml
# Edit at https://www.toptal.com/developers/gitignore?templates=go,vs,visualstudio,pycharm,pycharm+iml,pycharm+all,goland,goland+all,goland+iml

### Go ###
# If you prefer the allow list template instead of the deny list, see community template:
# https://github.com/github/gitignore/blob/main/community/Golang/Go.AllowList.gitignore
#
# Binaries for programs and plugins
*.exe
*.exe~
*.dll
*.so
*.dylib

# Test binary, built with `go test -c`
*.test

# Output of the go coverage tool, specifically when used with LiteIDE
*.out

# Dependency directories (remove the comment below to include it)
# vendor/

# Go workspace file
go.work

### GoLand ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff
.idea/**/workspace.xml
.idea/**/tasks.xml
.idea/**/usage.statistics.xml
.idea/**/dictionaries
.idea/**/shelf

# AWS User-specific
.idea/**/aws.xml

# Generated files
.idea/**/contentModel.xml

# Sensitive or high-churn files
.idea/**/dataSources/
.idea/**/dataSources.ids
.idea/**/dataSources.local.xml
.idea/**/sqlDataSources.xml
.idea/**/dynamic.xml
.idea/**/uiDesigner.xml
.idea/**/dbnavigator.xml

# Gradle
.idea/**/gradle.xml
.idea/**/libraries

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake
cmake-build-*/

# Mongo Explorer plugin
.idea/**/mongoSettings.xml

# File-based project format
*.iws

# IntelliJ
out/

# mpeltonen/sbt-idea plugin
.idea_modules/

# JIRA plugin
atlassian-ide-plugin.xml

# Cursive Clojure plugin
.idea/replstate.xml

# SonarLint plugin
.idea/sonarlint/

# Crashlytics plugin (for Android Studio and IntelliJ)
com_crashlytics_export_strings.xml
crashlytics.properties
crashlytics-build.properties
fabric.properties

# Editor-based Rest Client
.idea/httpRequests

# Android studio 3.1+ serialized cache file
.idea/caches/build_file_checksums.ser

### GoLand Patch ###
# Comment Reason: https://github.com/joeblau/gitignore.io/issues/186#issuecomment-215987721

# *.iml
# modules.xml
# .idea/misc.xml
# *.ipr

# Sonarlint plugin
# https://plugins.jetbrains.com/plugin/7973-sonarlint
.idea/**/sonarlint/

# SonarQube Plugin
# https://plugins.jetbrains.com/plugin/7238-sonarqube-community-plugin
.idea/**/sonarIssues.xml

# Markdown Navigator plugin
# https://plugins.jetbrains.com/plugin/7896-markdown-navigator-enhanced
.idea/**/markdown-navigator.xml
.idea/**/markdown-navigator-enh.xml
.idea/**/markdown-navigator/

# Cache file creation bug
# See https://youtrack.jetbrains.com/issue/JBR-2257
.idea/$CACHE_FILE$

# CodeStream plugin
# https://plugins.jetbrains.com/plugin/12206-codestream
.idea/codestream.xml

# Azure Toolkit for IntelliJ plugin
# https://plugins.jetbrains.com/plugin/8053-azure-toolkit-for-intellij
.idea/**/azureSettings.xml

### GoLand+all ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff

# AWS User-specific

# Generated files

# Sensitive or high-churn files

# Gradle

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake

# Mongo Explorer plugin

# File-based project format

# IntelliJ

# mpeltonen/sbt-idea plugin

# JIRA plugin

# Cursive Clojure plugin

# SonarLint plugin

# Crashlytics plugin (for Android Studio and IntelliJ)

# Editor-based Rest Client

# Android studio 3.1+ serialized cache file

### GoLand+all Patch ###
# Ignore everything but code style settings and run configurations
# that are supposed to be shared within teams.

.idea/*

!.idea/codeStyles
!.idea/runConfigurations

### GoLand+iml ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff

# AWS User-specific

# Generated files

# Sensitive or high-churn files

# Gradle

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake

# Mongo Explorer plugin

# File-based project format

# IntelliJ

# mpeltonen/sbt-idea plugin

# JIRA plugin

# Cursive Clojure plugin

# SonarLint plugin

# Crashlytics plugin (for Android Studio and IntelliJ)

# Editor-based Rest Client

# Android studio 3.1+ serialized cache file

### GoLand+iml Patch ###
# Reason: https://github.com/joeblau/gitignore.io/issues/186#issuecomment-249601023

*.iml
modules.xml
.idea/misc.xml
*.ipr

### PyCharm ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff

# AWS User-specific

# Generated files

# Sensitive or high-churn files

# Gradle

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake

# Mongo Explorer plugin

# File-based project format

# IntelliJ

# mpeltonen/sbt-idea plugin

# JIRA plugin

# Cursive Clojure plugin

# SonarLint plugin

# Crashlytics plugin (for Android Studio and IntelliJ)

# Editor-based Rest Client

# Android studio 3.1+ serialized cache file

### PyCharm Patch ###
# Comment Reason: https://github.com/joeblau/gitignore.io/issues/186#issuecomment-215987721

# *.iml
# modules.xml
# .idea/misc.xml
# *.ipr

# Sonarlint plugin
# https://plugins.jetbrains.com/plugin/7973-sonarlint

# SonarQube Plugin
# https://plugins.jetbrains.com/plugin/7238-sonarqube-community-plugin

# Markdown Navigator plugin
# https://plugins.jetbrains.com/plugin/7896-markdown-navigator-enhanced

# Cache file creation bug
# See https://youtrack.jetbrains.com/issue/JBR-2257

# CodeStream plugin
# https://plugins.jetbrains.com/plugin/12206-codestream

# Azure Toolkit for IntelliJ plugin
# https://plugins.jetbrains.com/plugin/8053-azure-toolkit-for-intellij

### PyCharm+all ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff

# AWS User-specific

# Generated files

# Sensitive or high-churn files

# Gradle

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake

# Mongo Explorer plugin

# File-based project format

# IntelliJ

# mpeltonen/sbt-idea plugin

# JIRA plugin

# Cursive Clojure plugin

# SonarLint plugin

# Crashlytics plugin (for Android Studio and IntelliJ)

# Editor-based Rest Client

# Android studio 3.1+ serialized cache file

### PyCharm+all Patch ###
# Ignore everything but code style settings and run configurations
# that are supposed to be shared within teams.



### PyCharm+iml ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff

# AWS User-specific

# Generated files

# Sensitive or high-churn files

# Gradle

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake

# Mongo Explorer plugin

# File-based project format

# IntelliJ

# mpeltonen/sbt-idea plugin

# JIRA plugin

# Cursive Clojure plugin

# SonarLint plugin

# Crashlytics plugin (for Android Studio and IntelliJ)

# Editor-based Rest Client

# Android studio 3.1+ serialized cache file

### PyCharm+iml Patch ###
# Reason: https://github.com/joeblau/gitignore.io/issues/186#issuecomment-249601023


### vs ###
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from https://github.com/github/gitignore/blob/master/VisualStudio.gitignore

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET Core
project.lock.json
project.fragment.lock.json
artifacts/

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*[.json, .xml, .info]

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

### VisualStudio ###
## Get latest from https://github.com/github/gitignore/blob/main/VisualStudio.gitignore

# User-specific files

# User-specific files (MonoDevelop/Xamarin Studio)

# Mono auto generated files

# Build results
[Ww][Ii][Nn]32/

# Visual Studio 2015/2017 cache/options directory
# Uncomment if you have tasks that create the project's static files in wwwroot

# Visual Studio 2017 auto generated files

# MSTest test Results

# NUnit

# Build Results of an ATL Project

# Benchmark Results

# .NET Core

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop

# Files built by Visual Studio
*.tlog

# Chutzpah Test files

# Visual C++ cache files

# Visual Studio profiler

# Visual Studio Trace Files

# TFS 2012 Local Workspace

# Guidance Automation Toolkit

# ReSharper is a .NET coding add-in

# TeamCity is a build add-in

# DotCover is a Code Coverage Tool

# AxoCover is a Code Coverage Tool

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results

# NCrunch

# MightyMoose

# Web workbench (sass)

# Installshield output folder

# DocProject is a documentation generator add-in

# Click-Once directory

# Publish Web Output
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted

# NuGet Packages
# NuGet Symbol Packages
# The packages folder can be ignored because of Package Restore
# except build/, which is used as an MSBuild target.
# Uncomment if necessary however generally it will be regenerated when needed
# NuGet v3's project.json files produces more ignorable files

# Microsoft Azure Build Output

# Microsoft Azure Emulator

# Windows Store app package directories and files

# Visual Studio cache files
# files ending in .cache can be ignored
# but keep track of directories ending in .cache

# Others

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)

# RIA/Silverlight projects

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)

# SQL Server files

# Business Intelligence projects

# Microsoft Fakes

# GhostDoc plugin setting file

# Node.js Tools for Visual Studio

# Visual Studio 6 build log

# Visual Studio 6 workspace options file

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files

# Visual Studio LightSwitch build output

# Paket dependency manager

# FAKE - F# Make

# CodeRush personal settings

# Python Tools for Visual Studio (PTVS)

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio

# Telerik's JustMock configuration file

# BizTalk build output

# OpenCover UI analysis results

# Azure Stream Analytics local run output

# MSBuild Binary and Structured Log

# NVidia Nsight GPU debugger configuration file

# MFractors (Xamarin productivity tool) working folder

# Local History for Visual Studio

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database

# Backup folder for Package Reference Convert tool in Visual Studio 2017

# Ionide (cross platform F# VS Code tools) working folder

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml

### VisualStudio Patch ###
# Additional files built by Visual Studio

# End of https://www.toptal.com/developers/gitignore/api/go,vs,visualstudio,pycharm,pycharm+iml,pycharm+all,goland,goland+all,goland+iml



main_refactored.py
test_consumer.py
</file>

<file path=".golangci.yml">
# Configura√ß√£o do golangci-lint
# Documenta√ß√£o completa: https://golangci-lint.run/usage/configuration/

run:
  timeout: 5m
  tests: true
  modules-download-mode: readonly

linters:
  enable:
    - errcheck      # Verifica erros n√£o tratados
    - gosimple      # Simplifica√ß√µes de c√≥digo
    - govet         # An√°lise do go vet
    - ineffassign   # Deteta atribui√ß√µes ineficazes
    - staticcheck   # An√°lise est√°tica avan√ßada
    - unused        # C√≥digo n√£o utilizado
    - gofmt         # Verifica formata√ß√£o
    - goimports     # Verifica imports
    - misspell      # Verifica erros de ortografia
    - revive        # Linter r√°pido e configur√°vel
    - gosec         # Verifica problemas de seguran√ßa
    - bodyclose     # Verifica se response bodies s√£o fechados
    - noctx         # Verifica uso de context
    - errorlint     # An√°lise de erros wrapeados

linters-settings:
  errcheck:
    check-blank: true
    check-type-assertions: true
  
  govet:
    check-shadowing: true
    enable-all: true
  
  revive:
    confidence: 0.8
  
  gosec:
    severity: medium
    confidence: medium

issues:
  exclude-use-default: false
  max-issues-per-linter: 0
  max-same-issues: 0
  
  # Excluir alguns problemas comuns em testes
  exclude-rules:
    - path: _test\.go
      linters:
        - errcheck
        - gosec
</file>

<file path=".pre-commit-config.yaml">
# Configura√ß√£o do Pre-commit
# Documenta√ß√£o: https://pre-commit.com/

repos:
  # Hooks gerais de qualidade
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
        name: Remove espa√ßos em branco no final das linhas
      - id: end-of-file-fixer
        name: Garante nova linha no final dos arquivos
      - id: check-yaml
        name: Valida sintaxe YAML
        args: ['--unsafe']  # Permite templates no YAML
      - id: check-toml
        name: Valida sintaxe TOML
      - id: check-json
        name: Valida sintaxe JSON
      - id: check-added-large-files
        name: Previne commit de arquivos grandes
        args: ['--maxkb=1024']
      - id: check-merge-conflict
        name: Detecta marcadores de merge conflict
      - id: check-case-conflict
        name: Verifica conflitos de case em nomes de arquivos

  # Go: formata√ß√£o e lint
  - repo: https://github.com/dnephin/pre-commit-golang
    rev: v0.5.1
    hooks:
      - id: go-fmt
        name: Formata c√≥digo Go
      - id: go-vet
        name: Executa go vet
      - id: go-imports
        name: Organiza imports Go
      - id: go-build
        name: Verifica build Go
      - id: go-mod-tidy
        name: Executa go mod tidy

  # Python: formata√ß√£o com Ruff (se houver scripts Python)
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.1.6
    hooks:
      - id: ruff
        name: Lint Python com Ruff
        args: [--fix, --exit-non-zero-on-fix]
      - id: ruff-format
        name: Formata c√≥digo Python com Ruff

  # Towncrier: Valida changelog fragments
  - repo: https://github.com/twisted/towncrier
    rev: 23.11.0
    hooks:
      - id: towncrier-check
        name: Verifica changelog fragments
        # Permite commits sem fragments em branches espec√≠ficas
        exclude: '^(main|master|develop)$'
        args: ['--compare-with=origin/main']
        additional_dependencies: []

  # Commitizen: mensagens de commit sem√¢nticas
  - repo: https://github.com/commitizen-tools/commitizen
    rev: v3.13.0
    hooks:
      - id: commitizen
        name: Valida formato de commits
        stages: [commit-msg]

  # Detec√ß√£o de segredos
  - repo: https://github.com/Yelp/detect-secrets
    rev: v1.4.0
    hooks:
      - id: detect-secrets
        name: Detecta segredos no c√≥digo
        args: ['--baseline', '.secrets.baseline']
        exclude: |
          (?x)^(
              .*\.lock$|
              go\.sum$|
              \.git/.*
          )$

# Configura√ß√£o global
default_stages: [commit]
fail_fast: false
</file>

<file path=".secrets.baseline">
{
  "version": "1.4.0",
  "plugins_used": [
    {
      "name": "ArtifactoryDetector"
    },
    {
      "name": "AWSKeyDetector"
    },
    {
      "name": "Base64HighEntropyString",
      "limit": 4.5
    },
    {
      "name": "BasicAuthDetector"
    },
    {
      "name": "CloudantDetector"
    },
    {
      "name": "HexHighEntropyString",
      "limit": 3.0
    },
    {
      "name": "JwtTokenDetector"
    },
    {
      "name": "KeywordDetector"
    },
    {
      "name": "MailchimpDetector"
    },
    {
      "name": "PrivateKeyDetector"
    },
    {
      "name": "SlackDetector"
    },
    {
      "name": "StripeDetector"
    }
  ],
  "filters_used": [
    {
      "path": "detect_secrets.filters.allowlist.is_line_allowlisted"
    },
    {
      "path": "detect_secrets.filters.common.is_ignored_due_to_verification_policies",
      "min_level": 2
    }
  ],
  "results": {},
  "generated_at": "2025-11-06T23:10:00Z"
}
</file>

<file path="config.test.toml">
# Configura√ß√£o de Teste - Edge Video

target_fps = 15
protocol = "mqtt"

[mqtt]
broker = "tcp://test-broker:1883"
topic_prefix = "test/camera/"

[amqp]
amqp_url = "amqp://test:test@localhost:5672/"
exchange = "test_exchange"
routing_key_prefix = "test."

[optimization]
max_workers = 10
buffer_size = 100
frame_quality = 8
frame_resolution = "640x480"
use_persistent = false
circuit_max_failures = 3
circuit_reset_seconds = 30

[redis]
enabled = false
address = "localhost:6379"
ttl_seconds = 60
prefix = "test_frames"

[metadata]
enabled = false
exchange = "test.metadata"
routing_key = "test.metadata.event"

[[cameras]]
id = "test_cam1"
url = "rtsp://test:test@localhost:554/test1"

[[cameras]]
id = "test_cam2"
url = "rtsp://test:test@localhost:554/test2"
</file>

<file path="CONTRIBUTING.md">
# Guia de Desenvolvimento - CI/CD

## üöÄ Workflows Implementados

### 1. **Go Tests CI** (`go-test.yml`)
Executa automaticamente em **qualquer push ou PR** em **qualquer branch**.

#### Jobs:
- ‚úÖ **test**: Testes unit√°rios com race detector e cobertura
- ‚úÖ **lint**: An√°lise de c√≥digo com golangci-lint
- ‚úÖ **build**: Verifica√ß√£o de compila√ß√£o
- ‚úÖ **summary**: Resumo geral dos resultados

### 2. **Docker Build & Push** (`build-and-push.yml`)
Executa apenas quando voc√™ **cria uma release tag**.

#### A√ß√µes:
- Build da imagem Docker
- Push para GitHub Container Registry
- Tags: `vers√£o` + `latest`

---

## üìù Workflow de Desenvolvimento

### Passo a Passo:

#### 1. **Desenvolvimento Local**
```bash
# Clone o reposit√≥rio
git clone https://github.com/T3-Labs/edge-video.git
cd edge-video

# Instale as depend√™ncias
go mod download

# Execute os testes
go test -v -race ./...

# Verifique a cobertura
go test -coverprofile=coverage.out ./...
go tool cover -html=coverage.out

# Execute o lint
golangci-lint run

# Formate o c√≥digo
gofmt -s -w .
```

#### 2. **Criar Feature Branch**
```bash
git checkout -b feature/nova-funcionalidade
```

#### 3. **Fazer Commits**
```bash
git add .
git commit -m "feat: adiciona nova funcionalidade"
```

#### 4. **Push e Criar PR**
```bash
git push origin feature/nova-funcionalidade
```
- **Autom√°tico**: Os testes ser√£o executados no GitHub Actions
- Aguarde todos os checks passarem antes de fazer merge

#### 5. **Merge para Main**
```bash
git checkout main
git pull origin main
git merge feature/nova-funcionalidade
git push origin main
```
- **Autom√°tico**: Os testes ser√£o executados novamente

#### 6. **Criar Release**
```bash
# Criar tag local
git tag -a v1.0.0 -m "Release v1.0.0 - Descri√ß√£o das mudan√ßas"

# Push da tag
git push origin v1.0.0
```
- **Autom√°tico**: Build do Docker e push para GHCR

---

## üõ†Ô∏è Ferramentas Necess√°rias

### Instala√ß√£o Local:

#### golangci-lint
```bash
# macOS/Linux
curl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin

# Ou via Go
go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest
```

#### Go 1.24
```bash
# Baixe em: https://go.dev/dl/
```

---

## üìä Cobertura de Testes

### Atual:
- **pkg/config**: 80.0% ‚úÖ
- **Outros pacotes**: 0.0% (adicionar testes)

### Meta:
- Aumentar cobertura para pelo menos **70%**

### Como melhorar:
1. Adicione testes em `pkg/camera/`
2. Adicione testes em `internal/storage/`
3. Adicione testes em `internal/metadata/`
4. Adicione testes em `pkg/mq/`

---

## üîç Verifica√ß√µes Locais Antes de Commit

Execute este checklist:

```bash
# 1. Testes passando?
go test ./...

# 2. Cobertura adequada?
go test -cover ./...

# 3. Lint sem erros?
golangci-lint run

# 4. C√≥digo formatado?
gofmt -l .

# 5. Build funciona?
go build ./cmd/edge-video
```

Se tudo passar ‚úÖ, fa√ßa o commit!

---

## üêõ Troubleshooting

### Testes Falhando no CI mas Passando Localmente?
- Verifique se todas as depend√™ncias est√£o no `go.mod`
- Execute `go mod tidy`
- Verifique se n√£o h√° arquivos locais n√£o comitados

### golangci-lint Retornando Erros?
```bash
# Ver detalhes
golangci-lint run --verbose

# Corrigir automaticamente alguns problemas
golangci-lint run --fix
```

### Build Docker Falhando?
- Verifique se o `Dockerfile` est√° atualizado
- Teste localmente: `docker build -t edge-video:test .`

---

## üìö Recursos √öteis

- [GitHub Actions Docs](https://docs.github.com/actions)
- [golangci-lint](https://golangci-lint.run/)
- [Go Testing](https://go.dev/doc/tutorial/add-a-test)
- [Semantic Versioning](https://semver.org/)

---

## üéØ Boas Pr√°ticas

1. ‚úÖ **Sempre execute testes localmente** antes de push
2. ‚úÖ **Use commits sem√¢nticos**: `feat:`, `fix:`, `docs:`, `refactor:`
3. ‚úÖ **Mantenha PRs pequenos** e focados
4. ‚úÖ **Documente mudan√ßas** no changelog da release
5. ‚úÖ **N√£o force push** em branches compartilhadas
6. ‚úÖ **Revise c√≥digo** antes de aprovar PRs

---

## üöÄ Deploy em Produ√ß√£o

### Usar a imagem Docker:
```bash
# Latest
docker pull ghcr.io/t3-labs/edge-video:latest

# Vers√£o espec√≠fica
docker pull ghcr.io/t3-labs/edge-video:1.0.0

# Executar
docker run -d \
  --name edge-video \
  -v ./config.toml:/app/config.toml \
  ghcr.io/t3-labs/edge-video:latest
```

---

**√öltima atualiza√ß√£o:** 2025-11-06
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 T3-Labs

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="mkdocs.yml">
# Configura√ß√£o do MkDocs para Edge Video
site_name: Edge Video Documentation
site_description: Sistema de Captura e Distribui√ß√£o de V√≠deo para Edge Computing
site_author: T3 Labs
site_url: https://t3-labs.github.io/edge-video

# Reposit√≥rio
repo_name: T3-Labs/edge-video
repo_url: https://github.com/T3-Labs/edge-video
edit_uri: edit/main/docs/

# Copyright
copyright: Copyright &copy; 2025 T3 Labs

# Tema
theme:
  name: material
  language: pt-BR
  logo: assets/logo.png
  favicon: assets/favicon.png
  
  # Paleta de cores
  palette:
    # Light mode
    - media: "(prefers-color-scheme: light)"
      scheme: default
      primary: indigo
      accent: blue
      toggle:
        icon: material/brightness-7
        name: Mudar para modo escuro
    
    # Dark mode
    - media: "(prefers-color-scheme: dark)"
      scheme: slate
      primary: indigo
      accent: blue
      toggle:
        icon: material/brightness-4
        name: Mudar para modo claro
  
  # Funcionalidades
  features:
    - navigation.instant        # Navega√ß√£o instant√¢nea
    - navigation.instant.progress  # Barra de progresso
    - navigation.tracking       # Tracking de √¢ncoras na URL
    - navigation.tabs           # Tabs de navega√ß√£o
    - navigation.tabs.sticky    # Tabs fixas
    - navigation.sections       # Se√ß√µes expandidas
    - navigation.expand         # Expandir navega√ß√£o
    - navigation.path           # Breadcrumbs
    - navigation.indexes        # √çndices de se√ß√£o
    - navigation.top            # Bot√£o "voltar ao topo"
    - navigation.footer         # Navega√ß√£o no rodap√©
    - toc.follow                # TOC segue scroll
    - toc.integrate             # TOC integrado
    - search.suggest            # Sugest√µes de busca
    - search.highlight          # Destacar termos de busca
    - search.share              # Compartilhar busca
    - header.autohide           # Auto-hide header
    - content.code.copy         # Bot√£o copiar c√≥digo
    - content.code.annotate     # Anota√ß√µes em c√≥digo
    - content.tabs.link         # Link tabs
    - content.tooltips          # Tooltips
    - announce.dismiss          # Dismiss announcements

  # √çcones
  icon:
    repo: fontawesome/brands/github
    edit: material/pencil
    view: material/eye
    admonition:
      note: octicons/tag-16
      abstract: octicons/checklist-16
      info: octicons/info-16
      tip: octicons/squirrel-16
      success: octicons/check-16
      question: octicons/question-16
      warning: octicons/alert-16
      failure: octicons/x-circle-16
      danger: octicons/zap-16
      bug: octicons/bug-16
      example: octicons/beaker-16
      quote: octicons/quote-16

# Plugins
plugins:
  - search:
      lang: pt
      separator: '[\s\-\_]+'
  - git-revision-date-localized:
      enable_creation_date: true
      type: timeago
      fallback_to_build_date: true
  - minify:
      minify_html: true
      minify_js: true
      minify_css: true
      htmlmin_opts:
        remove_comments: true
  - awesome-pages

# Markdown Extensions
markdown_extensions:
  # Python Markdown
  - abbr
  - admonition
  - attr_list
  - def_list
  - footnotes
  - md_in_html
  - tables
  - toc:
      permalink: true
      permalink_title: Link permanente
      toc_depth: 3
  
  # Python Markdown Extensions
  - pymdownx.arithmatex:
      generic: true
  - pymdownx.betterem:
      smart_enable: all
  - pymdownx.caret
  - pymdownx.details
  - pymdownx.emoji:
      emoji_index: !!python/name:material.extensions.emoji.twemoji
      emoji_generator: !!python/name:material.extensions.emoji.to_svg
  - pymdownx.highlight:
      anchor_linenums: true
      line_spans: __span
      pygments_lang_class: true
  - pymdownx.inlinehilite
  - pymdownx.keys
  - pymdownx.mark
  - pymdownx.smartsymbols
  - pymdownx.snippets:
      auto_append:
        - includes/abbreviations.md
  - pymdownx.superfences:
      custom_fences:
        - name: mermaid
          class: mermaid
          format: !!python/name:pymdownx.superfences.fence_code_format
  - pymdownx.tabbed:
      alternate_style: true
  - pymdownx.tasklist:
      custom_checkbox: true
  - pymdownx.tilde

# Navega√ß√£o
nav:
  - Home: index.md
  - Guia de In√≠cio:
      - Instala√ß√£o: getting-started/installation.md
      - Configura√ß√£o: getting-started/configuration.md
      - Primeiro Uso: getting-started/quickstart.md
  - Arquitetura:
      - Vis√£o Geral: architecture/overview.md
      - Componentes: architecture/components.md
      - Fluxo de Dados: architecture/data-flow.md
  - Funcionalidades:
      - Captura de C√¢meras: features/camera-capture.md
      - Redis Storage: features/redis-storage.md
      - Metadata Publisher: features/metadata.md
      - Message Queue: features/message-queue.md
  - Guias:
      - Docker Deployment: guides/docker.md
      - Configura√ß√£o Avan√ßada: guides/advanced-config.md
      - Monitoramento: guides/monitoring.md
      - Troubleshooting: guides/troubleshooting.md
  - Desenvolvimento:
      - Contribuindo: development/contributing.md
      - Pre-commit & Changelog: development/precommit-towncrier.md
      - Testes: development/testing.md
      - CI/CD: development/cicd.md
  - API Reference:
      - Configura√ß√£o: api/config.md
      - C√¢meras: api/camera.md
      - Storage: api/storage.md
      - Message Queue: api/mq.md
  - Changelog: changelog.md
  - Sobre:
      - Licen√ßa: about/license.md
      - Cr√©ditos: about/credits.md

# Extra
extra:
  version:
    provider: mike
  
  social:
    - icon: fontawesome/brands/github
      link: https://github.com/T3-Labs
      name: T3 Labs no GitHub
    - icon: fontawesome/brands/docker
      link: https://github.com/orgs/T3-Labs/packages
      name: Docker Images
  
  analytics:
    feedback:
      title: Esta p√°gina foi √∫til?
      ratings:
        - icon: material/emoticon-happy-outline
          name: Sim, muito √∫til!
          data: 1
          note: >-
            Obrigado pelo feedback! Ajude-nos a melhorar editando esta p√°gina.
        - icon: material/emoticon-sad-outline
          name: N√£o, precisa melhorar
          data: 0
          note: >-
            Obrigado pelo feedback! Abra uma issue para nos contar o que podemos melhorar.
  
  consent:
    title: Consentimento de cookies
    description: >-
      Usamos cookies para reconhecer suas visitas e prefer√™ncias, bem como medir
      a efic√°cia da documenta√ß√£o. Com seu consentimento, voc√™ nos ajuda a melhorar.

# CSS e JS customizado
extra_css:
  - stylesheets/extra.css

extra_javascript:
  - javascripts/extra.js
  - javascripts/mathjax.js
  - https://polyfill.io/v3/polyfill.min.js?features=es6
  - https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js
</file>

<file path="requirements-docs.txt">
# Depend√™ncias do MkDocs para Edge Video Documentation

# Core
mkdocs>=1.5.3
mkdocs-material>=9.5.0

# Plugins
mkdocs-git-revision-date-localized-plugin>=1.2.0
mkdocs-minify-plugin>=0.8.0
mkdocs-redirects>=1.2.0
mkdocstrings[python]>=0.24.0
mkdocs-awesome-pages-plugin>=2.9.0

# Extensions
pymdown-extensions>=10.7.0

# Utilities
Jinja2>=3.1.0
Markdown>=3.5.0
</file>

<file path="test_camera_redis_amqp.py">
#!/usr/bin/env python3
"""
Test script para consumir metadados de frames do RabbitMQ e buscar frames no Redis.
Este script demonstra a integra√ß√£o completa entre Redis e RabbitMQ para o edge-video.
"""

import json
import sys
import signal
from typing import Optional

import numpy as np
import cv2
import pika
import redis


class CameraFrameConsumer:
    """
    Consome metadados de frames do RabbitMQ e busca os frames correspondentes no Redis.
    """

    def __init__(
        self,
        rabbitmq_url: str = "amqp://user:password@localhost:5672/supermercado_vhost",
        redis_host: str = "localhost",
        redis_port: int = 6379,
        metadata_exchange: str = "camera.metadata",
        metadata_routing_key: str = "camera.metadata.event",
        enable_visualization: bool = True,
    ):
        """
        Inicializa o consumer de frames.

        Args:
            rabbitmq_url: URL de conex√£o do RabbitMQ
            redis_host: Host do Redis
            redis_port: Porta do Redis
            metadata_exchange: Exchange do RabbitMQ para metadados
            metadata_routing_key: Routing key para metadados
            enable_visualization: Se True, exibe os frames em janelas OpenCV
        """
        self.rabbitmq_url = rabbitmq_url
        self.metadata_exchange = metadata_exchange
        self.metadata_routing_key = metadata_routing_key
        self.enable_visualization = enable_visualization

        # Inicializa conex√£o com Redis
        self.redis_client = redis.Redis(
            host=redis_host, port=redis_port, decode_responses=False
        )

        # Conex√µes do RabbitMQ (ser√£o inicializadas no connect)
        self.connection: Optional[pika.BlockingConnection] = None
        self.channel: Optional[pika.channel.Channel] = None
        self.queue_name: Optional[str] = None

        # Estat√≠sticas
        self.messages_received = 0
        self.frames_found = 0
        self.frames_not_found = 0

        # Janelas de visualiza√ß√£o (uma por c√¢mera)
        self.windows = {}
        self.window_positions = {
            "cam1": (50, 50),
            "cam2": (700, 50),
            "cam3": (1350, 50),
            "cam4": (50, 500),
            "cam5": (700, 500),
        }

    def connect(self):
        """Estabelece conex√£o com o RabbitMQ e declara a fila."""
        print(f"Conectando ao RabbitMQ: {self.rabbitmq_url}")

        # Conecta ao RabbitMQ
        parameters = pika.URLParameters(self.rabbitmq_url)
        self.connection = pika.BlockingConnection(parameters)
        self.channel = self.connection.channel()

        # Declara o exchange (caso n√£o exista)
        self.channel.exchange_declare(
            exchange=self.metadata_exchange, exchange_type="topic", durable=True
        )

        # Cria uma fila exclusiva para este consumer
        result = self.channel.queue_declare(queue="", exclusive=True)
        self.queue_name = result.method.queue

        # Faz o bind da fila ao exchange com a routing key
        self.channel.queue_bind(
            exchange=self.metadata_exchange,
            queue=self.queue_name,
            routing_key=self.metadata_routing_key,
        )

        print(f"‚úÖ Conectado ao RabbitMQ")
        print(f"üì• Aguardando mensagens de metadados em '{self.metadata_exchange}'...")
        print(f"üîë Routing Key: {self.metadata_routing_key}")
        print("-" * 80)

    def get_frame_from_redis(self, redis_key: str) -> Optional[bytes]:
        """
        Busca um frame do Redis pela chave.

        Args:
            redis_key: Chave do frame no Redis

        Returns:
            Dados bin√°rios do frame (JPEG) ou None se n√£o encontrado
        """
        try:
            frame_data = self.redis_client.get(redis_key)
            return frame_data
        except redis.RedisError as e:
            print(f"‚ùå Erro ao buscar frame do Redis: {e}")
            return None

    def decode_frame(self, frame_data: bytes) -> Optional[np.ndarray]:
        """
        Decodifica dados JPEG em uma imagem OpenCV.

        Args:
            frame_data: Dados bin√°rios do frame (JPEG)

        Returns:
            Imagem decodificada (numpy array) ou None se houver erro
        """
        try:
            # Converte bytes para numpy array
            nparr = np.frombuffer(frame_data, np.uint8)
            # Decodifica a imagem
            img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            return img
        except Exception as e:
            print(f"‚ùå Erro ao decodificar frame: {e}")
            return None

    def display_frame(self, camera_id: str, frame: np.ndarray, metadata: dict):
        """
        Exibe um frame em uma janela OpenCV.

        Args:
            camera_id: ID da c√¢mera
            frame: Imagem (numpy array)
            metadata: Metadados do frame para exibir
        """
        if not self.enable_visualization:
            return

        # Cria uma c√≥pia para adicionar informa√ß√µes
        display_frame = frame.copy()

        # Adiciona informa√ß√µes no frame
        timestamp = metadata.get("timestamp", "N/A")
        width = metadata.get("width", 0)
        height = metadata.get("height", 0)
        size_bytes = metadata.get("size_bytes", 0)

        # Texto de informa√ß√µes
        info_text = [
            f"Camera: {camera_id}",
            f"Time: {timestamp[-15:-5]}",  # Exibe apenas HH:MM:SS
            f"Size: {width}x{height}",
            f"Bytes: {size_bytes:,}",
        ]

        # Adiciona texto no frame
        y_offset = 30
        for i, text in enumerate(info_text):
            cv2.putText(
                display_frame,
                text,
                (10, y_offset + i * 25),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.6,
                (0, 255, 0),
                2,
            )

        # Nome da janela
        window_name = f"Camera {camera_id}"

        # Cria janela se n√£o existir
        if camera_id not in self.windows:
            cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
            cv2.resizeWindow(window_name, 640, 360)

            # Posiciona a janela
            if camera_id in self.window_positions:
                x, y = self.window_positions[camera_id]
                cv2.moveWindow(window_name, x, y)

            self.windows[camera_id] = window_name

        # Exibe o frame
        cv2.imshow(window_name, display_frame)
        cv2.waitKey(1)  # Necess√°rio para atualizar a janela

    def process_metadata(self, ch, method, properties, body):
        """
        Callback para processar mensagens de metadados do RabbitMQ.

        Args:
            ch: Canal do RabbitMQ
            method: M√©todo da mensagem
            properties: Propriedades da mensagem
            body: Corpo da mensagem (JSON com metadados)
        """
        self.messages_received += 1

        try:
            # Parse do JSON de metadados
            metadata = json.loads(body)

            camera_id = metadata.get("camera_id")
            timestamp = metadata.get("timestamp")
            redis_key = metadata.get("redis_key")
            width = metadata.get("width")
            height = metadata.get("height")
            encoding = metadata.get("encoding")
            size_bytes = metadata.get("size_bytes")

            print(f"\nüì∏ Frame recebido #{self.messages_received}")
            print(f"   Camera ID: {camera_id}")
            print(f"   Timestamp: {timestamp}")
            print(f"   Redis Key: {redis_key}")
            print(f"   Resolu√ß√£o: {width}x{height}")
            print(f"   Encoding: {encoding}")
            print(f"   Tamanho (metadata): {size_bytes:,} bytes")

            # Busca o frame no Redis
            if redis_key:
                frame_data = self.get_frame_from_redis(redis_key)

                if frame_data:
                    self.frames_found += 1
                    print(f"   ‚úÖ Frame encontrado no Redis: {len(frame_data):,} bytes")

                    # Verifica o TTL restante da chave
                    ttl = self.redis_client.ttl(redis_key)
                    if ttl > 0:
                        print(f"   ‚è±Ô∏è  TTL restante: {ttl} segundos")
                    else:
                        print(f"   ‚ö†Ô∏è  TTL: {ttl} (sem expira√ß√£o ou j√° expirado)")

                    # Decodifica e exibe o frame
                    if self.enable_visualization:
                        img = self.decode_frame(frame_data)
                        if img is not None:
                            self.display_frame(camera_id, img, metadata)
                            print(f"   üñºÔ∏è  Frame exibido em janela OpenCV")

                    # Aqui voc√™ pode processar o frame
                    # Por exemplo: salvar em disco, processar com OpenCV, etc.
                    # self.save_frame_to_disk(camera_id, timestamp, frame_data)

                else:
                    self.frames_not_found += 1
                    print("   ‚ùå Frame N√ÉO encontrado no Redis (pode ter expirado)")

            # Confirma o processamento da mensagem
            ch.basic_ack(delivery_tag=method.delivery_tag)

            # Imprime estat√≠sticas a cada 10 mensagens
            if self.messages_received % 10 == 0:
                self.print_statistics()

        except json.JSONDecodeError as e:
            print(f"‚ùå Erro ao decodificar JSON: {e}")
            ch.basic_ack(delivery_tag=method.delivery_tag)
        except Exception as e:
            print(f"‚ùå Erro ao processar mensagem: {e}")
            ch.basic_ack(delivery_tag=method.delivery_tag)

    def print_statistics(self):
        """Imprime estat√≠sticas do consumer."""
        print("\n" + "=" * 80)
        print("üìä ESTAT√çSTICAS")
        print(f"   Mensagens recebidas: {self.messages_received}")
        print(f"   Frames encontrados no Redis: {self.frames_found}")
        print(f"   Frames n√£o encontrados: {self.frames_not_found}")
        if self.messages_received > 0:
            success_rate = (self.frames_found / self.messages_received) * 100
            print(f"   Taxa de sucesso: {success_rate:.1f}%")
        print("=" * 80)

    def save_frame_to_disk(self, camera_id: str, timestamp: str, frame_data: bytes):
        """
        Salva um frame em disco (exemplo de processamento).

        Args:
            camera_id: ID da c√¢mera
            timestamp: Timestamp do frame
            frame_data: Dados bin√°rios do frame (JPEG)
        """
        import os

        # Cria diret√≥rio se n√£o existir
        output_dir = f"frames/{camera_id}"
        os.makedirs(output_dir, exist_ok=True)

        # Limpa o timestamp para usar como nome de arquivo
        clean_timestamp = timestamp.replace(":", "-").replace(".", "-")
        filename = f"{output_dir}/{clean_timestamp}.jpg"

        # Salva o frame
        with open(filename, "wb") as f:
            f.write(frame_data)

        print(f"   üíæ Frame salvo em: {filename}")

    def start_consuming(self):
        """Inicia o consumo de mensagens do RabbitMQ."""
        self.connect()

        # Configura o consumer
        self.channel.basic_qos(prefetch_count=1)
        self.channel.basic_consume(
            queue=self.queue_name, on_message_callback=self.process_metadata
        )

        try:
            print("\nüöÄ Iniciando consumo de mensagens. Pressione CTRL+C para parar.\n")
            self.channel.start_consuming()
        except KeyboardInterrupt:
            print("\n\n‚èπÔ∏è  Parando consumer...")
            self.stop()

    def stop(self):
        """Para o consumer e fecha as conex√µes."""
        if self.channel and self.channel.is_open:
            self.channel.stop_consuming()

        if self.connection and self.connection.is_open:
            self.connection.close()

        self.redis_client.close()

        # Fecha todas as janelas OpenCV
        if self.enable_visualization:
            cv2.destroyAllWindows()

        print("\n" + "=" * 80)
        print("üìä ESTAT√çSTICAS FINAIS")
        print(f"   Mensagens recebidas: {self.messages_received}")
        print(f"   Frames encontrados no Redis: {self.frames_found}")
        print(f"   Frames n√£o encontrados: {self.frames_not_found}")
        if self.messages_received > 0:
            success_rate = (self.frames_found / self.messages_received) * 100
            print(f"   Taxa de sucesso: {success_rate:.1f}%")
        print("=" * 80)
        print("‚úÖ Consumer encerrado com sucesso!")


def main():
    """Fun√ß√£o principal do script."""
    print("=" * 80)
    print("üé• Camera Frame Consumer - Redis + RabbitMQ + OpenCV")
    print("=" * 80)

    # Configura√ß√µes (ajuste conforme necess√°rio)
    consumer = CameraFrameConsumer(
        rabbitmq_url="amqp://user:password@localhost:5672/supermercado_vhost",
        redis_host="localhost",
        redis_port=6379,
        metadata_exchange="camera.metadata",
        metadata_routing_key="camera.metadata.event",
        enable_visualization=True,  # Habilita visualiza√ß√£o com OpenCV
    )

    print("\nüí° Dica: Para desabilitar a visualiza√ß√£o, defina enable_visualization=False")
    print("üí° Pressione 'q' em qualquer janela ou CTRL+C no terminal para sair\n")

    # Configura handler para SIGTERM
    def signal_handler(sig, frame):
        print("\n\n‚ö†Ô∏è  Sinal recebido, encerrando...")
        consumer.stop()
        sys.exit(0)

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # Inicia o consumo
    try:
        consumer.start_consuming()
    except Exception as e:
        print(f"‚ùå Erro fatal: {e}")
        consumer.stop()
        sys.exit(1)


if __name__ == "__main__":
    main()
</file>

<file path=".github/workflows/build-and-push.yml">
name: Docker CI/CD para GitHub Container Registry

on:
  release:
    types: [published, created]
  workflow_dispatch:

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout do c√≥digo
        uses: actions/checkout@v4

      # 1. Configurar Docker Buildx
      - name: Configurar Docker Buildx
        uses: docker/setup-buildx-action@v3

      # 2. Fazer login no GitHub Container Registry
      - name: Login no GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # 3. Converter nome do reposit√≥rio para min√∫sculas
      - name: Converter reposit√≥rio para min√∫sculas
        run: |
          echo "IMAGE_NAME_LC=${IMAGE_NAME,,}" >> $GITHUB_ENV
        env:
          IMAGE_NAME: ${{ env.IMAGE_NAME }}

      # 4. Definir tags da imagem (vers√£o + latest)
      - name: Definir tags da imagem
        id: tags
        run: |
          IMAGE_BASE="${{ env.REGISTRY }}/${{ env.IMAGE_NAME_LC }}"
          VERSION="${{ github.event.release.tag_name }}"
          VERSION=${VERSION#v}  # Remove 'v' se existir (ex: v1.0.0 -> 1.0.0)
          echo "TAGS=${IMAGE_BASE}:${VERSION},${IMAGE_BASE}:latest" >> $GITHUB_ENV

      # 5. Construir e enviar imagem Docker
      - name: Construir e enviar imagem Docker
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ env.TAGS }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Push da imagem bem-sucedido
        run: |
          echo "‚úÖ Imagens Docker enviadas para o GitHub Container Registry:"
          echo ""
          echo "üè∑Ô∏è Tags criadas:"
          echo "${{ env.TAGS }}" | tr ',' '\n' | sed 's/^/  - /'
          echo ""
          echo "üöÄ Deploy pronto!"
          echo "üìñ Para usar: docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest"
</file>

<file path="cmd/validate-config/main.go">
package main

import (
	"flag"
	"fmt"
	"github.com/T3-Labs/edge-video/pkg/config"
)

func main() {
	configFile := flag.String("config", "config.toml", "Caminho para o arquivo de configura√ß√£o")
	flag.Parse()

	cfg, err := config.LoadConfig(*configFile)
	if err != nil {
		fmt.Printf("‚ùå Erro ao carregar config: %v\n", err)
		return
	}

	fmt.Println("‚úÖ Configura√ß√£o carregada com sucesso!")
	fmt.Printf("\nüìÅ Arquivo: %s\n", *configFile)
	fmt.Println("\n=== Par√¢metros Principais ===")
	fmt.Printf("Target FPS: %v\n", cfg.TargetFPS)
	fmt.Printf("Protocol: %s\n", cfg.Protocol)
	
	fmt.Println("\n=== AMQP ===")
	fmt.Printf("AMQP URL: %s\n", cfg.AMQP.AmqpURL)
	fmt.Printf("Exchange: %s\n", cfg.AMQP.Exchange)
	fmt.Printf("Routing Key Prefix: %s\n", cfg.AMQP.RoutingKeyPrefix)
	
	fmt.Println("\n=== MQTT ===")
	fmt.Printf("Broker: %s\n", cfg.MQTT.Broker)
	fmt.Printf("Topic Prefix: %s\n", cfg.MQTT.TopicPrefix)
	
	fmt.Println("\n=== Optimization ===")
	fmt.Printf("Max Workers: %d\n", cfg.Optimization.MaxWorkers)
	fmt.Printf("Buffer Size: %d\n", cfg.Optimization.BufferSize)
	fmt.Printf("Frame Quality: %d\n", cfg.Optimization.FrameQuality)
	fmt.Printf("Frame Resolution: %s\n", cfg.Optimization.FrameResolution)
	fmt.Printf("Use Persistent: %v\n", cfg.Optimization.UsePersistent)
	fmt.Printf("Circuit Max Failures: %d\n", cfg.Optimization.CircuitMaxFailures)
	fmt.Printf("Circuit Reset Seconds: %d\n", cfg.Optimization.CircuitResetSec)
	
	fmt.Println("\n=== Redis ===")
	fmt.Printf("Enabled: %v\n", cfg.Redis.Enabled)
	fmt.Printf("Address: %s\n", cfg.Redis.Address)
	fmt.Printf("TTL Seconds: %d\n", cfg.Redis.TTLSeconds)
	fmt.Printf("Prefix: %s\n", cfg.Redis.Prefix)
	
	fmt.Println("\n=== Metadata ===")
	fmt.Printf("Enabled: %v\n", cfg.Metadata.Enabled)
	fmt.Printf("Exchange: %s\n", cfg.Metadata.Exchange)
	fmt.Printf("Routing Key: %s\n", cfg.Metadata.RoutingKey)
	
	fmt.Println("\n=== Cameras ===")
	fmt.Printf("Total: %d c√¢meras\n", len(cfg.Cameras))
	for i, cam := range cfg.Cameras {
		fmt.Printf("  [%d] ID: %s\n", i+1, cam.ID)
	}
	
	interval := cfg.GetFrameInterval()
	fmt.Printf("\n=== C√°lculo Derivado ===\n")
	fmt.Printf("Frame Interval: %v\n", interval)
	fmt.Printf("FPS Efetivo: %.2f\n", float64(1)/interval.Seconds())
}
</file>

<file path="docs/development/contributing.md">
# Contribuindo

Obrigado por considerar contribuir para o Edge Video!

## üìñ Guia Completo de Contribui√ß√£o

Para informa√ß√µes detalhadas sobre como contribuir, incluindo:

- Padr√µes de c√≥digo
- Processo de review  
- Configura√ß√£o do ambiente
- Padr√µes de commit (Conventional Commits)
- Sistema de changelog (Towncrier)

Consulte o [**Guia de Contribui√ß√£o Completo**](../CONTRIBUTING.md).

## üöÄ In√≠cio R√°pido

### 1. Fork e Clone

```bash
git clone https://github.com/SEU_USUARIO/edge-video.git
cd edge-video
git remote add upstream https://github.com/T3-Labs/edge-video.git
```

### 2. Configurar Ambiente

```bash
# Instalar depend√™ncias Go
go mod download

# Instalar pre-commit
pip install pre-commit towncrier
pre-commit install

# Subir depend√™ncias
docker-compose up -d redis rabbitmq
```

### 3. Criar Branch e Desenvolver

```bash
git checkout -b feature/minha-feature
# Fa√ßa suas altera√ß√µes...
go test ./...
```

### 4. Commit com Changelog

```bash
# Criar changelog fragment
towncrier create 123.feature.md --content "Descri√ß√£o da mudan√ßa"

# Commit (pre-commit rodar√° automaticamente)
git commit -m "feat: adiciona nova funcionalidade"
```

### 5. Push e Pull Request

```bash
git push origin feature/minha-feature
# Abra PR no GitHub: develop ‚Üê feature/minha-feature
```

## üìù Padr√µes de Commit

Seguimos [Conventional Commits](https://www.conventionalcommits.org/):

- `feat`: Nova funcionalidade
- `fix`: Corre√ß√£o de bug
- `docs`: Documenta√ß√£o
- `refactor`: Refatora√ß√£o
- `test`: Testes
- `chore`: Manuten√ß√£o

**Exemplo:**
```bash
git commit -m "feat(camera): add H.265 codec support"
```

## ‚úÖ Checklist do PR

Antes de abrir um PR:

- [ ] C√≥digo compila sem erros
- [ ] Testes passam (`go test ./...`)
- [ ] Pre-commit hooks passam
- [ ] Changelog fragment criado
- [ ] Documenta√ß√£o atualizada
- [ ] Commits seguem Conventional Commits

## üîó Links √öteis

- [Pre-commit & Changelog](precommit-towncrier.md)
- [Testes](testing.md)
- [CI/CD](cicd.md)
- [Guia Completo](../CONTRIBUTING.md)

## üí¨ D√∫vidas?

- [Issues](https://github.com/T3-Labs/edge-video/issues)
- [Discussions](https://github.com/T3-Labs/edge-video/discussions)

---

Obrigado por contribuir! üéâ
</file>

<file path="docs/CONTRIBUTING.md">
# Guia de Contribui√ß√£o

Obrigado por considerar contribuir para o Edge Video! Este documento fornece diretrizes para contribuir com o projeto.

## üìã √çndice

- [C√≥digo de Conduta](#c√≥digo-de-conduta)
- [Como Contribuir](#como-contribuir)
- [Padr√µes de Commit](#padr√µes-de-commit)
- [Processo de Review](#processo-de-review)
- [Configura√ß√£o do Ambiente](#configura√ß√£o-do-ambiente)

## ü§ù C√≥digo de Conduta

Este projeto segue um c√≥digo de conduta que todos os colaboradores devem respeitar. Seja respeitoso, inclusivo e construtivo em suas intera√ß√µes.

## üöÄ Como Contribuir

### 1. Fork e Clone

```bash
# Fork o reposit√≥rio no GitHub
# Clone seu fork
git clone https://github.com/SEU_USUARIO/edge-video.git
cd edge-video

# Adicione o reposit√≥rio upstream
git remote add upstream https://github.com/T3-Labs/edge-video.git
```

### 2. Crie uma Branch

```bash
# Sincronize com upstream
git checkout develop
git pull upstream develop

# Crie sua branch a partir de develop
git checkout -b feature/sua-feature
# ou
git checkout -b fix/seu-bugfix
```

### 3. Fa√ßa suas Altera√ß√µes

- Siga os [padr√µes de c√≥digo](development/contributing.md)
- Adicione testes para novas funcionalidades
- Atualize a documenta√ß√£o conforme necess√°rio
- Execute os testes localmente

```bash
# Testes Go
go test ./...

# Linters
go vet ./...
golangci-lint run
```

### 4. Commit suas Mudan√ßas

Use o sistema de [Pre-commit + Towncrier](development/precommit-towncrier.md):

```bash
# Adicione um changelog fragment
towncrier create 123.feature.md --content "Nova funcionalidade X"

# Commit (pre-commit rodar√° automaticamente)
git add .
git commit -m "feat: adiciona funcionalidade X"
```

### 5. Push e Pull Request

```bash
# Push para seu fork
git push origin feature/sua-feature

# Abra um Pull Request no GitHub
# Base: develop
# Compare: feature/sua-feature
```

## üìù Padr√µes de Commit

Seguimos [Conventional Commits](https://www.conventionalcommits.org/):

```
<tipo>[escopo opcional]: <descri√ß√£o>

[corpo opcional]

[rodap√© opcional]
```

### Tipos de Commit

- `feat`: Nova funcionalidade
- `fix`: Corre√ß√£o de bug
- `docs`: Documenta√ß√£o
- `style`: Formata√ß√£o (sem mudan√ßa de c√≥digo)
- `refactor`: Refatora√ß√£o
- `test`: Adi√ß√£o/corre√ß√£o de testes
- `chore`: Tarefas de manuten√ß√£o
- `perf`: Melhoria de performance
- `ci`: Altera√ß√µes em CI/CD

### Exemplos

```bash
# Feature
git commit -m "feat(camera): add support for H.265 codec"

# Bug fix
git commit -m "fix(redis): resolve connection timeout issue"

# Documentation
git commit -m "docs: update installation guide for Windows"

# Breaking change
git commit -m "feat!: change config file format to TOML

BREAKING CHANGE: Config files now use TOML instead of YAML.
See migration guide in docs/guides/migration.md"
```

## üîç Processo de Review

### Checklist do PR

Antes de abrir um PR, certifique-se de que:

- [ ] O c√≥digo compila sem erros
- [ ] Todos os testes passam
- [ ] Novos testes foram adicionados (se aplic√°vel)
- [ ] Documenta√ß√£o foi atualizada (se aplic√°vel)
- [ ] Changelog fragment foi criado
- [ ] Pre-commit hooks passam
- [ ] Commits seguem Conventional Commits
- [ ] PR tem t√≠tulo descritivo
- [ ] PR inclui descri√ß√£o detalhada

### O que Esperamos

1. **C√≥digo Limpo**: Siga as conven√ß√µes do Go
2. **Testes**: Cobertura m√≠nima de 80%
3. **Documenta√ß√£o**: Fun√ß√µes p√∫blicas documentadas
4. **Performance**: N√£o degrade significativamente
5. **Seguran√ßa**: Sem vulnerabilidades conhecidas

### Tempo de Review

- PRs pequenos: 1-2 dias √∫teis
- PRs m√©dios: 2-4 dias √∫teis
- PRs grandes: Considere dividir em PRs menores

## üõ†Ô∏è Configura√ß√£o do Ambiente

### Pr√©-requisitos

- Go 1.24+
- Docker & Docker Compose
- Git
- Make (opcional, mas recomendado)

### Setup Inicial

```bash
# 1. Instalar depend√™ncias
go mod download

# 2. Copiar arquivo de configura√ß√£o
cp config.yaml.example config.yaml

# 3. Instalar pre-commit hooks
pip install pre-commit towncrier
pre-commit install

# 4. Subir depend√™ncias (Redis, RabbitMQ)
docker-compose up -d redis rabbitmq

# 5. Executar testes
go test ./...

# 6. Executar aplica√ß√£o
go run cmd/edge-video/main.go
```

### Ferramentas √öteis

#### Linters

```bash
# Instalar golangci-lint
go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest

# Executar
golangci-lint run
```

#### Testes com Coverage

```bash
# Gerar relat√≥rio de cobertura
go test -coverprofile=coverage.out ./...
go tool cover -html=coverage.out -o coverage.html

# Ver no browser
xdg-open coverage.html
```

#### Benchmark

```bash
# Executar benchmarks
go test -bench=. -benchmem ./...
```

## üìö Recursos Adicionais

- [Documenta√ß√£o Completa](index.md)
- [Guia de Desenvolvimento](development/contributing.md)
- [Pre-commit + Towncrier](development/precommit-towncrier.md)
- [Testes](development/testing.md)
- [CI/CD](development/cicd.md)

## ‚ùì D√∫vidas?

- Abra uma [Issue](https://github.com/T3-Labs/edge-video/issues)
- Participe das [Discussions](https://github.com/T3-Labs/edge-video/discussions)
- Entre em contato: [T3 Labs](https://github.com/T3-Labs)

---

Obrigado por contribuir! üéâ
</file>

<file path="docs/index.md">
# Edge Video Documentation

<div align="center">

[![Go Tests](https://github.com/T3-Labs/edge-video/actions/workflows/go-test.yml/badge.svg)](https://github.com/T3-Labs/edge-video/actions/workflows/go-test.yml)
[![Docker Build](https://github.com/T3-Labs/edge-video/actions/workflows/build-and-push.yml/badge.svg)](https://github.com/T3-Labs/edge-video/actions/workflows/build-and-push.yml)
[![Documentation](https://github.com/T3-Labs/edge-video/actions/workflows/mkdocs.yml/badge.svg)](https://t3-labs.github.io/edge-video/)
[![Go Version](https://img.shields.io/badge/Go-1.24-00ADD8?logo=go)](https://go.dev/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](about/license.md)

**Sistema de Captura e Distribui√ß√£o de V√≠deo para Edge Computing**

[Come√ßar](getting-started/installation.md){ .md-button .md-button--primary }
[Ver no GitHub](https://github.com/T3-Labs/edge-video){ .md-button }

</div>

---

## üéØ Sobre o Projeto

O **Edge Video** √© um sistema distribu√≠do de captura e streaming de c√¢meras RTSP, projetado especificamente para ambientes de **edge computing**. O sistema captura frames de m√∫ltiplas c√¢meras IP em tempo real, processa-os localmente e distribui atrav√©s de uma infraestrutura de mensageria robusta.

## ‚ú® Principais Funcionalidades

<div class="grid cards" markdown>

-   :material-camera-multiple:{ .lg .middle } __Captura Multi-C√¢mera__

    ---

    Suporte a captura simult√¢nea de m√∫ltiplas c√¢meras RTSP/IP com processamento paralelo e otimizado.

    [:octicons-arrow-right-24: Saiba mais](features/camera-capture.md)

-   :material-memory:{ .lg .middle } __Redis Storage__

    ---

    Armazenamento tempor√°rio de frames no Redis com TTL configur√°vel e suporte a autentica√ß√£o.

    [:octicons-arrow-right-24: Configurar Redis](features/redis-storage.md)

-   :material-rabbit:{ .lg .middle } __RabbitMQ Integration__

    ---

    Distribui√ß√£o eficiente via AMQP com suporte a m√∫ltiplos consumidores e retry autom√°tico.

    [:octicons-arrow-right-24: Message Queue](features/message-queue.md)

-   :material-docker:{ .lg .middle } __Docker Ready__

    ---

    Deploy simplificado com Docker Compose incluindo Redis, RabbitMQ e RedisInsight.

    [:octicons-arrow-right-24: Deploy](guides/docker.md)

-   :material-chart-line:{ .lg .middle } __Monitoramento__

    ---

    M√©tricas detalhadas, logging estruturado e interfaces de gerenciamento web.

    [:octicons-arrow-right-24: Monitorar](guides/monitoring.md)

-   :material-cog:{ .lg .middle } __Configura√ß√£o Flex√≠vel__

    ---

    Configura√ß√£o via TOML com suporte a m√∫ltiplos protocolos (AMQP/MQTT).

    [:octicons-arrow-right-24: Configurar](getting-started/configuration.md)

</div>

## üöÄ Quick Start

=== "Docker Compose (Recomendado)"

    ```bash
    # Clone o reposit√≥rio
    git clone https://github.com/T3-Labs/edge-video.git
    cd edge-video

    # Configure as c√¢meras em config.toml
    nano config.toml

    # Inicie os servi√ßos
    docker-compose up -d

    # Verifique os logs
    docker logs -f camera-collector
    ```

=== "Docker Pull"

    ```bash
    # Pull da imagem
    docker pull ghcr.io/t3-labs/edge-video:latest

    # Execute com seu config
    docker run -d \
      --name edge-video \
      -v $(pwd)/config.toml:/app/config.toml \
      ghcr.io/t3-labs/edge-video:latest
    ```

=== "Build Local"

    ```bash
    # Clone e build
    git clone https://github.com/T3-Labs/edge-video.git
    cd edge-video
    
    # Instalar depend√™ncias
    go mod download
    
    # Build
    go build -o edge-video ./cmd/edge-video
    
    # Executar
    ./edge-video
    ```

## üèóÔ∏è Arquitetura

```mermaid
graph TB
    subgraph C√¢meras
        C1[C√¢mera 1<br/>RTSP]
        C2[C√¢mera 2<br/>RTSP]
        C3[C√¢mera N<br/>RTSP]
    end
    
    subgraph Edge Video
        CAP[Camera Collector<br/>Go App]
        REDIS[(Redis<br/>Frame Storage)]
        RMQ[RabbitMQ<br/>Message Broker]
    end
    
    subgraph Consumers
        CON1[Consumer 1<br/>Video Analytics]
        CON2[Consumer 2<br/>Recording]
        CON3[Consumer N<br/>Custom]
    end
    
    C1 --> CAP
    C2 --> CAP
    C3 --> CAP
    
    CAP -->|Frames| REDIS
    CAP -->|Metadata| RMQ
    
    RMQ --> CON1
    RMQ --> CON2
    RMQ --> CON3
    
    REDIS -.->|Fetch Frames| CON1
    REDIS -.->|Fetch Frames| CON2
    REDIS -.->|Fetch Frames| CON3
    
    style CAP fill:#4051b5
    style REDIS fill:#dc382d
    style RMQ fill:#ff6600
```

[:octicons-arrow-right-24: Ver Arquitetura Detalhada](architecture/overview.md)

## üìä Estat√≠sticas do Projeto

<div class="grid" markdown>

!!! info "Performance"
    - **30 FPS** por c√¢mera
    - **< 100ms** lat√™ncia m√©dia
    - **5+ c√¢meras** simult√¢neas
    - **TTL configur√°vel** no Redis

!!! success "Confiabilidade"
    - **99.9%** uptime
    - **Retry autom√°tico** em falhas
    - **Healthchecks** integrados
    - **Graceful shutdown**

!!! tip "Escalabilidade"
    - **Horizontal scaling** de consumers
    - **Load balancing** via RabbitMQ
    - **Cache distribu√≠do** Redis
    - **Stateless design**

!!! note "Desenvolvedor"
    - **80%** cobertura de testes
    - **CI/CD** automatizado
    - **Pre-commit hooks**
    - **Changelog** autom√°tico

</div>

## üõ†Ô∏è Tecnologias

| Componente | Tecnologia | Vers√£o |
|------------|-----------|--------|
| Backend | Go | 1.24 |
| Message Broker | RabbitMQ | 3.13 |
| Cache/Storage | Redis | 7 |
| Container | Docker | Latest |
| Capture | FFmpeg | Latest |
| Config | TOML | - |

## üìö Documenta√ß√£o

<div class="grid cards" markdown>

-   :material-play-circle:{ .lg } [**Guia de In√≠cio**](getting-started/installation.md)
    
    Instala√ß√£o, configura√ß√£o e primeiro uso

-   :material-book-open-variant:{ .lg } [**Guias**](guides/docker.md)
    
    Tutoriais pr√°ticos e casos de uso

-   :material-code-braces:{ .lg } [**API Reference**](api/config.md)
    
    Documenta√ß√£o t√©cnica da API

-   :material-github:{ .lg } [**Contribuindo**](development/contributing.md)
    
    Como contribuir com o projeto

</div>

## ü§ù Comunidade

- **Issues**: [GitHub Issues](https://github.com/T3-Labs/edge-video/issues)
- **Discuss√µes**: [GitHub Discussions](https://github.com/T3-Labs/edge-video/discussions)
- **Changelog**: [Ver mudan√ßas](changelog.md)

## üìù Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja [LICENSE](about/license.md) para mais detalhes.

---

<div align="center">

**Desenvolvido com ‚ù§Ô∏è por [T3 Labs](https://github.com/T3-Labs)**

</div>
</file>

<file path="docs/QUICK_REFERENCE.md">
# üöÄ Quick Reference: Towncrier & Pre-commit

## Instala√ß√£o R√°pida

```bash
pip install pre-commit towncrier commitizen
pre-commit install
pre-commit install --hook-type commit-msg
```

## Comandos Di√°rios

### Criar Changelog Fragment
```bash
./scripts/new-changelog.sh <tipo> "mensagem"
```

**Tipos:** `feature`, `bugfix`, `docs`, `removal`, `security`, `performance`, `refactor`, `misc`

### Commit
```bash
git add .
git commit -m "feat: sua mensagem"  # Hooks executam automaticamente
```

### Listar Fragments
```bash
./scripts/new-changelog.sh --list
```

## Release

### Preview
```bash
./scripts/build-changelog.sh --draft 1.0.0
```

### Gerar
```bash
./scripts/build-changelog.sh 1.0.0
git add CHANGELOG.md changelog.d/
git commit -m "chore: release v1.0.0"
git tag -a v1.0.0 -m "Release v1.0.0"
git push origin main --tags
```

## Atalhos

### Executar Hooks Manualmente
```bash
pre-commit run --all-files
```

### Bypass Hooks (emerg√™ncia)
```bash
git commit --no-verify -m "mensagem"
```

## Formato de Commit

Use [Conventional Commits](https://www.conventionalcommits.org/):

- `feat:` - nova funcionalidade
- `fix:` - corre√ß√£o de bug
- `docs:` - documenta√ß√£o
- `refactor:` - refatora√ß√£o
- `test:` - testes
- `chore:` - manuten√ß√£o
- `perf:` - performance
- `style:` - formata√ß√£o

## Documenta√ß√£o Completa

- üìñ [Pre-commit & Towncrier Guide](PRECOMMIT_TOWNCRIER_GUIDE.md)
- üìñ [Towncrier Setup Guide](TOWNCRIER_SETUP.md)
- üìñ [Development Guide](development/precommit-towncrier.md)
</file>

<file path="docs/TOWNCRIER_SETUP.md">
# üìã Resumo: Towncrier + Pre-commit Implementado

## ‚úÖ Arquivos Criados

### Configura√ß√µes:
1. **`.pre-commit-config.yaml`** - Configura√ß√£o dos pre-commit hooks
2. **`pyproject.toml`** - Configura√ß√£o do Towncrier
3. **`.secrets.baseline`** - Baseline para detec√ß√£o de segredos
4. **`CHANGELOG.md`** - Arquivo principal de changelog

### Diret√≥rio changelog.d/:
5. **`changelog.d/template.md.j2`** - Template Jinja2 para gera√ß√£o
6. **`changelog.d/README.md`** - Guia de uso dos fragments
7. **`changelog.d/1.feature.md`** - Exemplo: convers√£o YAML‚ÜíTOML
8. **`changelog.d/2.security.md`** - Exemplo: autentica√ß√£o Redis
9. **`changelog.d/3.feature.md`** - Exemplo: CI/CD GitHub Actions
10. **`changelog.d/4.feature.md`** - Exemplo: visualiza√ß√£o OpenCV

### Scripts:
11. **`scripts/new-changelog.sh`** - Helper para criar fragments
12. **`scripts/build-changelog.sh`** - Helper para gerar changelog

### Documenta√ß√£o:
13. **`docs/PRECOMMIT_TOWNCRIER_GUIDE.md`** - Guia completo de uso
14. **`README.md`** - Atualizado com se√ß√£o de contribui√ß√£o

---

## üöÄ Como Usar

### 1. Instala√ß√£o (Uma vez):

```bash
# Instalar pre-commit e towncrier
python3 -m venv .venv-tools
source .venv-tools/bin/activate
pip install pre-commit towncrier commitizen detect-secrets

# Instalar hooks
pre-commit install
pre-commit install --hook-type commit-msg
```

### 2. Workflow Di√°rio:

```bash
# 1. Criar feature branch
git checkout -b feature/nova-funcionalidade

# 2. Fazer suas mudan√ßas no c√≥digo
# ... editar arquivos ...

# 3. Criar changelog fragment
./scripts/new-changelog.sh feature "Adiciona suporte a PostgreSQL"

# 4. Commit (os hooks executam automaticamente)
git add .
git commit -m "feat: adiciona suporte a PostgreSQL"

# 5. Push
git push origin feature/nova-funcionalidade
```

### 3. Criar Release:

```bash
# 1. Merge para main
git checkout main
git merge develop

# 2. Gerar changelog
source .venv-tools/bin/activate
./scripts/build-changelog.sh 1.0.0

# 3. Commit e tag
git add CHANGELOG.md changelog.d/
git commit -m "chore: release v1.0.0"
git tag -a v1.0.0 -m "Release v1.0.0"
git push origin main --tags
```

---

## üéØ O que os Pre-commit Hooks Fazem

Quando voc√™ executa `git commit`, automaticamente:

### ‚úÖ Checks de Qualidade:
- **trailing-whitespace**: Remove espa√ßos em branco no final
- **end-of-file-fixer**: Garante nova linha no final
- **check-yaml/toml/json**: Valida sintaxe

### ‚úÖ Go Hooks:
- **go-fmt**: Formata c√≥digo Go
- **go-vet**: Executa an√°lise est√°tica
- **go-imports**: Organiza imports
- **go-build**: Verifica compila√ß√£o
- **go-mod-tidy**: Limpa depend√™ncias

### ‚úÖ Python Hooks:
- **ruff**: Lint e formata√ß√£o Python

### ‚úÖ Changelog:
- **towncrier-check**: Verifica se h√° fragment criado

### ‚úÖ Commits:
- **commitizen**: Valida formato de commit sem√¢ntico

### ‚úÖ Seguran√ßa:
- **detect-secrets**: Detecta poss√≠veis segredos no c√≥digo

---

## üìù Tipos de Changelog Fragments

| Tipo | Emoji | Descri√ß√£o |
|------|-------|-----------|
| `feature` | ‚ú® | Nova funcionalidade |
| `bugfix` | üêõ | Corre√ß√£o de bug |
| `docs` | üìö | Documenta√ß√£o |
| `removal` | üóëÔ∏è | Remo√ß√µes/deprecia√ß√µes |
| `security` | üîí | Seguran√ßa |
| `performance` | ‚ö° | Performance |
| `refactor` | ‚ôªÔ∏è | Refatora√ß√£o |
| `misc` | üîß | Outros |

---

## üõ†Ô∏è Comandos √öteis

### Scripts Helpers:

```bash
# Criar fragment
./scripts/new-changelog.sh feature "Sua mensagem"
./scripts/new-changelog.sh bugfix "Corrige problema X" 123

# Listar fragments
./scripts/new-changelog.sh --list

# Preview do changelog
./scripts/build-changelog.sh --draft 1.0.0

# Gerar changelog
./scripts/build-changelog.sh 1.0.0

# Gerar e manter fragments
./scripts/build-changelog.sh --keep 1.0.0
```

### Pre-commit:

```bash
# Executar todos os hooks
pre-commit run --all-files

# Executar hook espec√≠fico
pre-commit run go-fmt --all-files
pre-commit run towncrier-check --all-files

# Atualizar hooks
pre-commit autoupdate

# Bypass hooks (n√£o recomendado)
git commit --no-verify -m "mensagem"
```

### Towncrier:

```bash
# Verificar fragments
ls -la changelog.d/*.md

# Build com op√ß√µes
towncrier build --version 1.0.0 --draft   # Preview
towncrier build --version 1.0.0 --keep    # Manter fragments
towncrier build --version 1.0.0 --yes     # Sem confirma√ß√£o
```

---

## üé® Exemplo de CHANGELOG Gerado

```markdown
## [1.0.0] - 2025-11-06

### ‚ú® Features

- Convers√£o do formato de configura√ß√£o de YAML para TOML ([#1](link))
- Implementa pipeline CI/CD com GitHub Actions ([#3](link))
- Adiciona visualiza√ß√£o em tempo real de frames com OpenCV ([#4](link))

### üîí Security

- Adiciona autentica√ß√£o por senha para Redis ([#2](link))
```

---

## üìö Documenta√ß√£o Completa

- **[Pre-commit & Towncrier Guide](PRECOMMIT_TOWNCRIER_GUIDE.md)** - Guia completo de uso
- **[Development Guide](development/precommit-towncrier.md)** - Guia de desenvolvimento
- **[Contributing Guide](CONTRIBUTING.md)** - Como contribuir

---

## üîç Troubleshooting

### Hook "towncrier-check" falha?
**Solu√ß√£o:** Crie um fragment ou use `--no-verify` para commits em branches principais.

### Hook "commitizen" falha?
**Solu√ß√£o:** Use formato sem√¢ntico: `tipo: descri√ß√£o` (ex: `feat: nova funcionalidade`)

### Towncrier n√£o encontra fragments?
**Solu√ß√£o:** Verifique se os arquivos est√£o em `changelog.d/` e terminam com `.tipo.md`

---

## üéâ Tudo Pronto!

O sistema de changelog autom√°tico com Towncrier est√° 100% configurado!

**Pr√≥ximos passos:**
1. ‚úÖ Instalar depend√™ncias: `pip install pre-commit towncrier`
2. ‚úÖ Instalar hooks: `pre-commit install`
3. ‚úÖ Testar criando um fragment: `./scripts/new-changelog.sh feature "teste"`
4. ‚úÖ Fazer commit e ver os hooks em a√ß√£o!

---

**Data de implementa√ß√£o:** 2025-11-06  
**Vers√£o:** 1.0.0
</file>

<file path="internal/metadata/publisher.go">
package metadata

import (
	"encoding/json"
	"time"

	"github.com/streadway/amqp"
)

// Publisher handles publishing frame metadata to RabbitMQ.
type Publisher struct {
	channel    *amqp.Channel
	exchange   string
	routingKey string
	enabled    bool
}

// NewPublisher creates a new metadata Publisher.
func NewPublisher(ch *amqp.Channel, exchange, routingKey string, enabled bool) *Publisher {
	// Se estiver habilitado e o canal existir, declara o exchange
	if enabled && ch != nil {
		err := ch.ExchangeDeclare(
			exchange,
			"topic",
			true,  // durable
			false, // auto-deleted
			false, // internal
			false, // no-wait
			nil,   // arguments
		)
		if err != nil {
			// Log o erro mas n√£o falha a cria√ß√£o do publisher
			// Isso permite que a aplica√ß√£o continue mesmo se o exchange j√° existir
			// ou houver problemas tempor√°rios
		}
	}

	return &Publisher{
		channel:    ch,
		exchange:   exchange,
		routingKey: routingKey,
		enabled:    enabled,
	}
}

// Enabled returns true if the metadata publisher is enabled.
func (p *Publisher) Enabled() bool {
	return p.enabled
}

// Metadata represents the structure of the metadata message.
type Metadata struct {
	CameraID  string    `json:"camera_id"`
	Timestamp time.Time `json:"timestamp"`
	RedisKey  string    `json:"redis_key"`
	Width     int       `json:"width"`
	Height    int       `json:"height"`
	Encoding  string    `json:"encoding"`
	SizeBytes int       `json:"size_bytes"`
}

// PublishMetadata sends a JSON message with frame metadata to RabbitMQ.
func (p *Publisher) PublishMetadata(cameraID string, timestamp time.Time, redisKey string, width, height, size int, encoding string) error {
	if !p.enabled {
		return nil
	}

	metadata := Metadata{
		CameraID:  cameraID,
		Timestamp: timestamp,
		RedisKey:  redisKey,
		Width:     width,
		Height:    height,
		Encoding:  encoding,
		SizeBytes: size,
	}

	body, err := json.Marshal(metadata)
	if err != nil {
		return err
	}

	return p.channel.Publish(
		p.exchange,
		p.routingKey,
		false, // mandatory
		false, // immediate
		amqp.Publishing{
			ContentType: "application/json",
			Body:        body,
		},
	)
}
</file>

<file path="pkg/camera/persistent_capture.go">
package camera

import (
	"bufio"
	"bytes"
	"context"
	"fmt"
	"io"
	"os/exec"
	"sync"
	"time"
	
	"github.com/T3-Labs/edge-video/pkg/logger"
)

type PersistentCapture struct {
	cameraID     string
	rtspURL      string
	quality      int
	fps          int
	
	mu           sync.RWMutex
	cmd          *exec.Cmd
	stdout       io.ReadCloser
	stderr       io.ReadCloser
	running      bool
	
	ctx          context.Context
	cancel       context.CancelFunc
	
	frameBuffer  chan []byte
	errorCount   int64
	lastRestart  time.Time
}

func NewPersistentCapture(ctx context.Context, cameraID, rtspURL string, quality int, fps int) *PersistentCapture {
	ctx, cancel := context.WithCancel(ctx)
	
	return &PersistentCapture{
		cameraID:    cameraID,
		rtspURL:     rtspURL,
		quality:     quality,
		fps:         fps,
		ctx:         ctx,
		cancel:      cancel,
		frameBuffer: make(chan []byte, 50),
		lastRestart: time.Now(),
	}
}

func (pc *PersistentCapture) Start() error {
	pc.mu.Lock()
	defer pc.mu.Unlock()
	
	if pc.running {
		return fmt.Errorf("captura j√° est√° rodando")
	}
	
	err := pc.startFFmpeg()
	if err != nil {
		return err
	}
	
	go pc.readFrames()
	go pc.monitorHealth()
	
	pc.running = true
	logger.Log.Infow("Captura persistente iniciada",
		"camera_id", pc.cameraID,
		"quality", pc.quality)
	
	return nil
}

func (pc *PersistentCapture) startFFmpeg() error {
	pc.cmd = exec.CommandContext(
		pc.ctx,
		"ffmpeg",
		"-rtsp_transport", "tcp",
		"-i", pc.rtspURL,
		"-f", "image2pipe",
		"-vcodec", "mjpeg",
		"-q:v", fmt.Sprintf("%d", pc.quality),
		"-r", fmt.Sprintf("%d", pc.fps),
		"-",
	)
	
	var err error
	pc.stdout, err = pc.cmd.StdoutPipe()
	if err != nil {
		return fmt.Errorf("erro ao criar stdout pipe: %w", err)
	}
	
	pc.stderr, err = pc.cmd.StderrPipe()
	if err != nil {
		return fmt.Errorf("erro ao criar stderr pipe: %w", err)
	}
	
	err = pc.cmd.Start()
	if err != nil {
		return fmt.Errorf("erro ao iniciar FFmpeg: %w", err)
	}
	
	go pc.logErrors()
	
	return nil
}

func (pc *PersistentCapture) readFrames() {
	reader := bufio.NewReader(pc.stdout)
	frameBuffer := bytes.NewBuffer(make([]byte, 0, 512*1024))
	
	jpegSOI := []byte{0xFF, 0xD8}
	jpegEOI := []byte{0xFF, 0xD9}
	
	for {
		select {
		case <-pc.ctx.Done():
			return
		default:
		}
		
		b, err := reader.ReadByte()
		if err != nil {
			if err == io.EOF {
				pc.handleError("EOF no stream FFmpeg")
				return
			}
			pc.handleError(fmt.Sprintf("erro ao ler byte: %v", err))
			return
		}
		
		frameBuffer.WriteByte(b)
		
		if frameBuffer.Len() >= 2 {
			tail := frameBuffer.Bytes()[frameBuffer.Len()-2:]
			if bytes.Equal(tail, jpegEOI) {
				frameData := make([]byte, frameBuffer.Len())
				copy(frameData, frameBuffer.Bytes())
				
				if bytes.HasPrefix(frameData, jpegSOI) {
					select {
					case pc.frameBuffer <- frameData:
					default:
						logger.Log.Warnw("Frame buffer cheio, descartando frame",
							"camera_id", pc.cameraID)
					}
				}
				
				frameBuffer.Reset()
			}
		}
	}
}

func (pc *PersistentCapture) logErrors() {
	scanner := bufio.NewScanner(pc.stderr)
	for scanner.Scan() {
		line := scanner.Text()
		logger.Log.Debugw("FFmpeg stderr",
			"camera_id", pc.cameraID,
			"message", line)
	}
}

func (pc *PersistentCapture) monitorHealth() {
	ticker := time.NewTicker(10 * time.Second)
	defer ticker.Stop()
	
	lastFrameTime := time.Now()
	
	for {
		select {
		case <-pc.ctx.Done():
			return
			
		case <-ticker.C:
			select {
			case <-pc.frameBuffer:
				lastFrameTime = time.Now()
			default:
			}
			
			if time.Since(lastFrameTime) > 30*time.Second {
				logger.Log.Warnw("Nenhum frame recebido h√° 30s, reiniciando captura",
					"camera_id", pc.cameraID)
				pc.Restart()
				lastFrameTime = time.Now()
			}
		}
	}
}

func (pc *PersistentCapture) handleError(msg string) {
	logger.Log.Errorw("Erro na captura persistente",
		"camera_id", pc.cameraID,
		"error", msg)
	
	pc.errorCount++
	
	if pc.errorCount > 5 && time.Since(pc.lastRestart) < time.Minute {
		logger.Log.Errorw("Muitos erros em pouco tempo, aguardando antes de reiniciar",
			"camera_id", pc.cameraID,
			"error_count", pc.errorCount)
		time.Sleep(10 * time.Second)
	}
	
	pc.Restart()
}

func (pc *PersistentCapture) Restart() error {
	pc.mu.Lock()
	defer pc.mu.Unlock()
	
	if pc.cmd != nil && pc.cmd.Process != nil {
		_ = pc.cmd.Process.Kill()
		_ = pc.cmd.Wait()
	}
	
	time.Sleep(time.Second)
	
	err := pc.startFFmpeg()
	if err != nil {
		logger.Log.Errorw("Erro ao reiniciar FFmpeg",
			"camera_id", pc.cameraID,
			"error", err)
		return err
	}
	
	pc.lastRestart = time.Now()
	pc.errorCount = 0
	
	go pc.readFrames()
	
	logger.Log.Infow("Captura reiniciada",
		"camera_id", pc.cameraID)
	
	return nil
}

func (pc *PersistentCapture) GetFrame() ([]byte, bool) {
	select {
	case frame := <-pc.frameBuffer:
		return frame, true
	case <-time.After(5 * time.Second):
		return nil, false
	}
}

func (pc *PersistentCapture) GetFrameNonBlocking() ([]byte, bool) {
	select {
	case frame := <-pc.frameBuffer:
		return frame, true
	default:
		return nil, false
	}
}

func (pc *PersistentCapture) GetFrameWithTimeout(timeout time.Duration) ([]byte, bool) {
	ctx, cancel := context.WithTimeout(pc.ctx, timeout)
	defer cancel()
	
	select {
	case frame := <-pc.frameBuffer:
		return frame, true
	case <-ctx.Done():
		return nil, false
	}
}

func (pc *PersistentCapture) Stop() {
	pc.mu.Lock()
	defer pc.mu.Unlock()
	
	if !pc.running {
		return
	}
	
	pc.cancel()
	
	if pc.cmd != nil && pc.cmd.Process != nil {
		_ = pc.cmd.Process.Kill()
		_ = pc.cmd.Wait()
	}
	
	close(pc.frameBuffer)
	pc.running = false
	
	logger.Log.Infow("Captura persistente parada",
		"camera_id", pc.cameraID)
}

func (pc *PersistentCapture) IsRunning() bool {
	pc.mu.RLock()
	defer pc.mu.RUnlock()
	return pc.running
}
</file>

<file path="pkg/config/config_formats_test.go">
package config

import (
	"testing"

	"github.com/stretchr/testify/assert"
)

func TestLoadConfigTOML(t *testing.T) {
	cfg, err := LoadConfig("../../config.toml")
	assert.NoError(t, err, "Deveria carregar config.toml sem erros")
	assert.NotNil(t, cfg, "Configura√ß√£o n√£o deveria ser nil")

	// Validar par√¢metros principais
	assert.Equal(t, float64(30), cfg.TargetFPS, "Target FPS deveria ser 30")
	assert.Equal(t, "amqp", cfg.Protocol, "Protocol deveria ser amqp")

	// Validar AMQP
	assert.Equal(t, "amqp://user:password@rabbitmq:5672/supermercado_vhost", cfg.AMQP.AmqpURL)
	assert.Equal(t, "supermercado_exchange", cfg.AMQP.Exchange)
	assert.Equal(t, "camera.", cfg.AMQP.RoutingKeyPrefix)

	// Validar MQTT
	assert.Equal(t, "tcp://localhost:1883", cfg.MQTT.Broker)
	assert.Equal(t, "camera/", cfg.MQTT.TopicPrefix)

	// Validar Optimization
	assert.Equal(t, 20, cfg.Optimization.MaxWorkers, "Max workers deveria ser 20")
	assert.Equal(t, 200, cfg.Optimization.BufferSize, "Buffer size deveria ser 200")
	assert.Equal(t, 5, cfg.Optimization.FrameQuality)
	assert.Equal(t, "1280x720", cfg.Optimization.FrameResolution)
	assert.True(t, cfg.Optimization.UsePersistent)
	assert.Equal(t, 5, cfg.Optimization.CircuitMaxFailures)
	assert.Equal(t, 60, cfg.Optimization.CircuitResetSec)

	// Validar Redis
	assert.True(t, cfg.Redis.Enabled)
	assert.Equal(t, "redis:6379", cfg.Redis.Address)
	assert.Equal(t, 300, cfg.Redis.TTLSeconds)
	assert.Equal(t, "frames", cfg.Redis.Prefix)

	// Validar Metadata
	assert.True(t, cfg.Metadata.Enabled)
	assert.Equal(t, "camera.metadata", cfg.Metadata.Exchange)
	assert.Equal(t, "camera.metadata.event", cfg.Metadata.RoutingKey)

	// Validar Cameras
	assert.Len(t, cfg.Cameras, 5, "Deveria ter 5 c√¢meras")
	assert.Equal(t, "cam1", cfg.Cameras[0].ID)
	assert.Equal(t, "cam2", cfg.Cameras[1].ID)
	assert.Equal(t, "cam3", cfg.Cameras[2].ID)
	assert.Equal(t, "cam4", cfg.Cameras[3].ID)
	assert.Equal(t, "cam5", cfg.Cameras[4].ID)

	// Validar c√°lculo derivado
	interval := cfg.GetFrameInterval()
	assert.NotZero(t, interval, "Interval n√£o deveria ser zero")
}

func TestConfigParity(t *testing.T) {
	cfgTOML, err := LoadConfig("../../config.toml")
	assert.NoError(t, err)
	assert.NotNil(t, cfgTOML)

	// Verificar valores esperados
	assert.Equal(t, float64(30), cfgTOML.TargetFPS, "Target FPS deveria ser 30")
	assert.Equal(t, "amqp", cfgTOML.Protocol, "Protocol deveria ser amqp")
	
	// Optimization
	assert.Equal(t, 20, cfgTOML.Optimization.MaxWorkers, "Max workers deveria ser 20")
	assert.Equal(t, 200, cfgTOML.Optimization.BufferSize, "Buffer size deveria ser 200")
	assert.Equal(t, 5, cfgTOML.Optimization.FrameQuality, "Frame quality deveria ser 5")
	assert.True(t, cfgTOML.Optimization.UsePersistent, "Use persistent deveria ser true")
	assert.Equal(t, 5, cfgTOML.Optimization.CircuitMaxFailures, "Circuit failures deveria ser 5")
	assert.Equal(t, 60, cfgTOML.Optimization.CircuitResetSec, "Circuit reset deveria ser 60")
	
	// Redis
	assert.Equal(t, 300, cfgTOML.Redis.TTLSeconds, "Redis TTL deveria ser 300")
	assert.Equal(t, "redis:6379", cfgTOML.Redis.Address, "Redis address deveria ser redis:6379")
	
	// Cameras
	assert.Equal(t, 5, len(cfgTOML.Cameras), "N√∫mero de c√¢meras deveria ser 5")
}
</file>

<file path="pkg/config/config_test.go">
package config

import (
	"os"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
)

func TestLoadConfig(t *testing.T) {
	content := `
target_fps: 12.5
protocol: "amqp"
amqp:
  amqp_url: "amqp://guest:guest@localhost:5672/"
  exchange: "test_exchange"
  routing_key_prefix: "test."
cameras:
  - id: "cam1"
    url: "rtsp://test.com/1"
`
	tmpfile, err := os.CreateTemp("", "config-*.yaml")
	assert.NoError(t, err)
	defer os.Remove(tmpfile.Name())

	_, err = tmpfile.WriteString(content)
	assert.NoError(t, err)
	tmpfile.Close()

	cfg, err := LoadConfig(tmpfile.Name())
	assert.NoError(t, err)
	assert.NotNil(t, cfg)

	assert.Equal(t, 12.5, cfg.TargetFPS)
	assert.Equal(t, "amqp", cfg.Protocol)
	assert.Equal(t, "amqp://guest:guest@localhost:5672/", cfg.AMQP.AmqpURL)
	assert.Equal(t, "test_exchange", cfg.AMQP.Exchange)
	assert.Equal(t, "test.", cfg.AMQP.RoutingKeyPrefix)
	assert.Len(t, cfg.Cameras, 1)
	assert.Equal(t, "cam1", cfg.Cameras[0].ID)
	assert.Equal(t, "rtsp://test.com/1", cfg.Cameras[0].URL)
	assert.Equal(t, time.Duration(float64(time.Second)/12.5), cfg.GetFrameInterval())
}

func TestLoadConfig_FileNotFound(t *testing.T) {
	_, err := LoadConfig("non_existent_file.yaml")
	assert.Error(t, err)
}
</file>

<file path="pkg/mq/mqtt.go">
package mq

import (
	"context"
	"fmt"
	"log"

	mqtt "github.com/eclipse/paho.mqtt.golang"
)

type MQTTPublisher struct {
	client      mqtt.Client
	topicPrefix string
}

func NewMQTTPublisher(broker, topicPrefix string) (*MQTTPublisher, error) {
	opts := mqtt.NewClientOptions().AddBroker(broker)
	opts.SetAutoReconnect(true)
	opts.SetConnectRetry(true)

	client := mqtt.NewClient(opts)
	if token := client.Connect(); token.Wait() && token.Error() != nil {
		return nil, fmt.Errorf("mqtt connect: %w", token.Error())
	}
	log.Println("Conectado ao broker MQTT")
	return &MQTTPublisher{client: client, topicPrefix: topicPrefix}, nil
}

func (p *MQTTPublisher) Publish(ctx context.Context, cameraID string, payload []byte) error {
	topic := p.topicPrefix + cameraID
	token := p.client.Publish(topic, 1, false, payload)
	sent := token.Wait()
	if !sent {
		return fmt.Errorf("o cliente MQTT n√£o conseguiu enviar a mensagem")
	}
	if token.Error() != nil {
		return fmt.Errorf("falha ao publicar no MQTT: %w", token.Error())
	}
	return nil
}

func (p *MQTTPublisher) Close() error {
	p.client.Disconnect(250)
	return nil
}
</file>

<file path="pkg/mq/publisher_mock.go">
package mq

import (
	"context"
	"testing"

	"github.com/stretchr/testify/assert"
)

type MockPublisher struct {
	PublishFunc func(ctx context.Context, cameraID string, payload []byte) error
	CloseFunc   func() error
}

func (m *MockPublisher) Publish(ctx context.Context, cameraID string, payload []byte) error {
	if m.PublishFunc != nil {
		return m.PublishFunc(ctx, cameraID, payload)
	}
	return nil
}

func (m *MockPublisher) Close() error {
	if m.CloseFunc != nil {
		return m.CloseFunc()
	}
	return nil
}

func TestMockPublisher(t *testing.T) {
	var published bool
	mock := &MockPublisher{
		PublishFunc: func(ctx context.Context, cameraID string, payload []byte) error {
			published = true
			assert.Equal(t, "cam1", cameraID)
			assert.Equal(t, []byte("test"), payload)
			return nil
		},
	}

	err := mock.Publish(context.Background(), "cam1", []byte("test"))
	assert.NoError(t, err)
	assert.True(t, published)
}
</file>

<file path="pkg/mq/publisher.go">
package mq

import "context"

type Publisher interface {
	Publish(ctx context.Context, cameraID string, payload []byte) error
	Close() error
}
</file>

<file path="pkg/util/compress.go">
package util

import (
	"bytes"
	"fmt"

	zstd "github.com/klauspost/compress/zstd"
)

type Compressor struct {
	encoder *zstd.Encoder
	level   int
}

func NewCompressor(level int) (*Compressor, error) {
	enc, err := zstd.NewWriter(nil, zstd.WithEncoderLevel(zstd.EncoderLevelFromZstd(level)))
	if err != nil {
		return nil, fmt.Errorf("zstd new writer: %w", err)
	}
	return &Compressor{encoder: enc, level: level}, nil
}

func (c *Compressor) Compress(data []byte) ([]byte, error) {
	var b bytes.Buffer
	w, err := zstd.NewWriter(&b)
	if err != nil {
		return nil, err
	}
	if _, err := w.Write(data); err != nil {
		w.Close()
		return nil, err
	}
	w.Close()
	return b.Bytes(), nil
}

func Decompress(data []byte) ([]byte, error) {
	r, err := zstd.NewReader(bytes.NewReader(data))
	if err != nil {
		return nil, err
	}
	defer r.Close()
	var out bytes.Buffer
	_, err = out.ReadFrom(r)
	if err != nil {
		return nil, err
	}
	return out.Bytes(), nil
}
</file>

<file path=".env.example">
# Exemplo de arquivo .env para configura√ß√£o do Edge Video

# Caminho para o arquivo config.yaml
# Pode ser um caminho relativo ou absoluto
# Padr√£o: ./config.yaml (pasta atual)
CONFIG_PATH=./config.yaml

# RabbitMQ Configuration
RABBITMQ_HOST=localhost
RABBITMQ_PORT=5672
RABBITMQ_VHOST=guard_vhost
RABBITMQ_USER=user
RABBITMQ_PASS=password

# Exchange Configuration
EXCHANGE_NAME=carnes_nobres
ROUTING_KEY=camera.#
QUEUE_NAME=test_consumer_queue

# Development Configuration
DEBUG=true
LOG_LEVEL=INFO

# Exemplos de uso:
# CONFIG_PATH=./config.yaml                          # Pasta atual (padr√£o)
# CONFIG_PATH=/etc/edge-video/config.yaml           # Caminho absoluto
# CONFIG_PATH=~/cameras/config.yaml                 # Home do usu√°rio
# CONFIG_PATH=/mnt/storage/configs/config.yaml      # Storage montado
</file>

<file path="config.toml">
# Configura√ß√£o do Edge Video - Formato TOML

# FPS desejado para captura (frames por segundo)
target_fps = 30

# Protocolo de mensageria: "amqp" ou "mqtt"
protocol = "amqp"

# Configura√ß√£o AMQP (RabbitMQ)
[amqp]
amqp_url = "amqp://user:password@rabbitmq:5672/supermercado_vhost"
vhost =  "supermercado_vhost"
exchange = "supermercado_exchange"
routing_key_prefix = "camera."

# Configura√ß√£o MQTT
[mqtt]
broker = "tcp://localhost:1883"
topic_prefix = "camera/"

# Configura√ß√µes de otimiza√ß√£o de performance
[optimization]
max_workers = 20                    # N√∫mero de workers para processar frames
buffer_size = 200                   # Tamanho do buffer de frames
frame_quality = 5                   # Qualidade JPEG (2-31, menor = melhor)
frame_resolution = "1280x720"       # Resolu√ß√£o dos frames
use_persistent = true               # Usar captura persistente FFmpeg
circuit_max_failures = 5            # Falhas antes de abrir circuit breaker
circuit_reset_seconds = 60          # Tempo para tentar reconectar (segundos)

# Configura√ß√£o Redis (armazenamento de frames)
[redis]
enabled = true
address = "redis:6379"
ttl_seconds = 60
prefix = "frames"

# Configura√ß√£o de Metadados (publica√ß√£o de metadados de frames)
[metadata]
enabled = true
exchange = "camera.metadata"
routing_key = "camera.metadata.event"

# C√¢meras RTSP
[[cameras]]
id = "cam1"
url = "rtsp://shopguard:!Sg36786@191.7.178.101:8554/cam/realmonitor?channel=1&subtype=0"

[[cameras]]
id = "cam2"
url = "rtsp://shopguard:!Sg36786@191.7.178.101:8554/cam/realmonitor?channel=2&subtype=0"

[[cameras]]
id = "cam3"
url = "rtsp://shopguard:!Sg36786@191.7.178.101:8554/cam/realmonitor?channel=3&subtype=0"

[[cameras]]
id = "cam4"
url = "rtsp://shopguard:!Sg36786@191.7.178.101:8554/cam/realmonitor?channel=4&subtype=0"

[[cameras]]
id = "cam5"
url = "rtsp://shopguard:!Sg36786@191.7.178.101:8554/cam/realmonitor?channel=5&subtype=0"
</file>

<file path="run-docker.sh">
#!/bin/bash
# Script para executar o Edge Video usando Docker Run
# Uso: ./run-docker.sh /path/para/config.yaml

set -e

# Cores para output
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Par√¢metros
CONFIG_PATH=${1:-"$(pwd)/config.yaml"}
RABBITMQ_USER=${RABBITMQ_USER:-"user"}
RABBITMQ_PASS=${RABBITMQ_PASS:-"password"}
RABBITMQ_VHOST=${RABBITMQ_VHOST:-"guard_vhost"}
NETWORK_NAME="edge-video-net"
RABBITMQ_CONTAINER="rabbitmq"
COLLECTOR_CONTAINER="camera-collector"

echo -e "${GREEN}=== Edge Video - Docker Run Setup ===${NC}"

# Verifica se o config existe
if [ ! -f "$CONFIG_PATH" ]; then
    echo -e "${YELLOW}Erro: Config file n√£o encontrado em: $CONFIG_PATH${NC}"
    echo "Uso: $0 /path/para/config.yaml"
    exit 1
fi

echo -e "${GREEN}[1/5] Usando config: $CONFIG_PATH${NC}"

# Cria a rede se n√£o existir
if ! docker network inspect $NETWORK_NAME >/dev/null 2>&1; then
    echo -e "${GREEN}[2/5] Criando rede Docker: $NETWORK_NAME${NC}"
    docker network create $NETWORK_NAME
else
    echo -e "${GREEN}[2/5] Rede $NETWORK_NAME j√° existe${NC}"
fi

# Remove containers antigos se existirem
echo -e "${GREEN}[3/5] Limpando containers antigos...${NC}"
docker rm -f $RABBITMQ_CONTAINER 2>/dev/null || true
docker rm -f $COLLECTOR_CONTAINER 2>/dev/null || true

# Inicia RabbitMQ
echo -e "${GREEN}[4/5] Iniciando RabbitMQ...${NC}"
docker run -d \
  --name $RABBITMQ_CONTAINER \
  --network $NETWORK_NAME \
  -p 5672:5672 \
  -p 15672:15672 \
  -e RABBITMQ_DEFAULT_USER=$RABBITMQ_USER \
  -e RABBITMQ_DEFAULT_PASS=$RABBITMQ_PASS \
  -e RABBITMQ_DEFAULT_VHOST=$RABBITMQ_VHOST \
  rabbitmq:3.13-management-alpine

# Aguarda RabbitMQ iniciar
echo -e "${YELLOW}Aguardando RabbitMQ iniciar...${NC}"
sleep 10

# Inicia Camera Collector
echo -e "${GREEN}[5/5] Iniciando Camera Collector...${NC}"
docker run -d \
  --name $COLLECTOR_CONTAINER \
  --network $NETWORK_NAME \
  --restart unless-stopped \
  -v "$CONFIG_PATH:/app/config.yaml:ro" \
  t3labs/edge-video:latest

echo ""
echo -e "${GREEN}=== Setup Completo! ===${NC}"
echo ""
echo "Servi√ßos rodando:"
echo "  - RabbitMQ Management: http://localhost:15672 (user: $RABBITMQ_USER, pass: $RABBITMQ_PASS)"
echo "  - AMQP Port: localhost:5672"
echo ""
echo "Comandos √∫teis:"
echo "  docker logs -f $COLLECTOR_CONTAINER  # Ver logs do collector"
echo "  docker logs -f $RABBITMQ_CONTAINER   # Ver logs do RabbitMQ"
echo "  docker stop $COLLECTOR_CONTAINER $RABBITMQ_CONTAINER  # Parar servi√ßos"
echo "  docker rm $COLLECTOR_CONTAINER $RABBITMQ_CONTAINER    # Remover containers"
echo ""
</file>

<file path="pkg/mq/amqp.go">
package mq

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/streadway/amqp"
)

type AMQPPublisher struct {
	conn             *amqp.Connection
	channel          *amqp.Channel
	exchange         string
	routingKeyPrefix string
	amqpURL          string
}

func NewAMQPPublisher(amqpURL, exchange, routingKeyPrefix string) (*AMQPPublisher, error) {
	publisher := &AMQPPublisher{
		exchange:         exchange,
		routingKeyPrefix: routingKeyPrefix,
		amqpURL:          amqpURL,
	}

	// Tenta conectar com retry
	var err error
	maxRetries := 10
	for i := 0; i < maxRetries; i++ {
		err = publisher.connect()
		if err == nil {
			log.Printf("Conectado ao RabbitMQ com sucesso")
			return publisher, nil
		}
		log.Printf("Tentativa %d/%d de conex√£o ao RabbitMQ falhou: %v. Tentando novamente em 5s...", i+1, maxRetries, err)
		time.Sleep(5 * time.Second)
	}

	return nil, fmt.Errorf("falha ao conectar ao RabbitMQ ap√≥s %d tentativas: %w", maxRetries, err)
}

func (p *AMQPPublisher) connect() error {
	conn, err := amqp.Dial(p.amqpURL)
	if err != nil {
		return fmt.Errorf("failed to connect to RabbitMQ: %w", err)
	}

	ch, err := conn.Channel()
	if err != nil {
		conn.Close()
		return fmt.Errorf("failed to open a channel: %w", err)
	}

	err = ch.ExchangeDeclare(
		p.exchange,
		"topic",
		true,
		false,
		false,
		false,
		nil,
	)
	if err != nil {
		ch.Close()
		conn.Close()
		return fmt.Errorf("failed to declare an exchange: %w", err)
	}

	p.conn = conn
	p.channel = ch
	return nil
}

func (p *AMQPPublisher) Publish(ctx context.Context, cameraID string, payload []byte) error {
	routingKey := p.routingKeyPrefix + cameraID
	err := p.channel.Publish(
		p.exchange,
		routingKey,
		false,
		false,
		amqp.Publishing{
			ContentType: "application/octet-stream",
			Body:        payload,
			Timestamp:   time.Now(),
		})
	if err != nil {
		return fmt.Errorf("failed to publish a message: %w", err)
	}
	return nil
}

func (p *AMQPPublisher) Close() error {
	if p.channel != nil {
		p.channel.Close()
	}
	if p.conn != nil {
		return p.conn.Close()
	}
	return nil
}

// GetChannel returns the underlying AMQP channel.
func (p *AMQPPublisher) GetChannel() *amqp.Channel {
	return p.channel
}
</file>

<file path=".python-version">
3.11
</file>

<file path="CHANGELOG.md">
# Changelog

Todas as mudan√ßas not√°veis neste projeto ser√£o documentadas neste arquivo.

O formato √© baseado em [Keep a Changelog](https://keepachangelog.com/pt-BR/1.0.0/),
e este projeto adere ao [Semantic Versioning](https://semver.org/lang/pt-BR/).

<!-- towncrier release notes start -->

## [2.0.0] - 2025-11-07

### üöÄ Major Performance Improvements

#### Novos Componentes

- **Worker Pool** (`pkg/worker/pool.go`) - Pool de goroutines com tamanho configur√°vel para controle de concorr√™ncia
  - Fila de jobs com buffer para evitar cria√ß√£o ilimitada de goroutines
  - Stats tracking: jobs processados, erros, tamanho da fila
  - Graceful shutdown com timeout de 5 segundos
  - 9 testes unit√°rios incluindo benchmarks
  - **Ganho esperado**: 2x capacidade

- **Frame Buffer** (`pkg/buffer/frame_buffer.go`) - Buffer circular para gerenciamento de frames
  - Tracking autom√°tico de frames descartados e drop rate
  - Opera√ß√µes push/pop bloqueantes e n√£o-bloqueantes
  - 8 testes unit√°rios com testes de concorr√™ncia
  - **Ganho esperado**: 50% redu√ß√£o em frame drops

- **Circuit Breaker** (`pkg/circuit/breaker.go`) - Padr√£o Circuit Breaker para resili√™ncia
  - Estados: Closed (normal), Open (falhas), HalfOpen (recupera√ß√£o)
  - Recovery autom√°tico com timeout configur√°vel
  - 9 testes unit√°rios cobrindo todas transi√ß√µes de estado
  - **Ganho esperado**: Prote√ß√£o contra cascade failures

- **Persistent FFmpeg Capture** (`pkg/camera/persistent_capture.go`) - Captura persistente com processo FFmpeg
  - Elimina overhead de recria√ß√£o de processos
  - Parser de stream MJPEG com detec√ß√£o SOI/EOI
  - Auto-restart com exponential backoff
  - Health monitoring com timeout de 30 segundos
  - **Ganho esperado**: 3-5x capacidade (maior ganho individual)

- **Structured Logging** (`pkg/logger/logger.go`) - Migra√ß√£o para Zap logger
  - Sampling configur√°vel para reduzir overhead
  - N√≠veis: Debug, Info, Warn, Error
  - Logging baseado em fields
  - **Ganho esperado**: 10-15% redu√ß√£o de CPU

- **Prometheus Metrics** (`pkg/metrics/collector.go`) - 10 m√©tricas de observabilidade
  - Frames processados/descartados por c√¢mera
  - Lat√™ncia de captura e publica√ß√£o (histograms)
  - Worker pool queue size e processing
  - Circuit breaker state e camera connection
  - Endpoint HTTP em `:9090/metrics`

#### Configura√ß√µes

- Adicionadas 7 novas op√ß√µes de otimiza√ß√£o (`pkg/config/config.go`):
  - `optimization.max_workers` - Workers do pool (padr√£o: 10)
  - `optimization.buffer_size` - Buffer de frames (padr√£o: 100)
  - `optimization.frame_quality` - Qualidade JPEG 2-31 (padr√£o: 5)
  - `optimization.frame_resolution` - Resolu√ß√£o (padr√£o: "1280x720")
  - `optimization.use_persistent` - Captura persistente (padr√£o: true)
  - `optimization.circuit_max_failures` - Threshold de falhas (padr√£o: 5)
  - `optimization.circuit_reset_seconds` - Timeout de recovery (padr√£o: 60)

#### Documenta√ß√£o

- `docs/guides/performance-analysis.md` - An√°lise detalhada de 8 bottlenecks
- `docs/guides/performance-summary.md` - Resumo executivo e quick wins
- `docs/guides/worker-pool-implementation.md` - Guia de implementa√ß√£o
- `docs/guides/implementation-summary.md` - Resumo completo com guia de deployment

### Changed

- **Refatora√ß√£o completa da captura** (`pkg/camera/camera.go`)
  - Integra√ß√£o com Worker Pool, Frame Buffer e Circuit Breaker
  - Suporte para captura persistente e cl√°ssica
  - Migra√ß√£o para structured logging
  - Instrumenta√ß√£o com Prometheus metrics
  - Novo pattern: `FrameProcessJob` para processamento ass√≠ncrono

- **Refatora√ß√£o da aplica√ß√£o principal** (`cmd/edge-video/main.go`)
  - Inicializa√ß√£o de Worker Pool global
  - Frame Buffer e Circuit Breaker por c√¢mera
  - Servidor de m√©tricas em `:9090/metrics`
  - System monitoring a cada 30 segundos
  - Shutdown gracioso com timeout

### Dependencies

- Adicionado `go.uber.org/zap` v1.27.0 - Structured logging
- Adicionado `github.com/prometheus/client_golang` v1.23.2 - Metrics
- Atualizado `github.com/cespare/xxhash/v2` v2.1.2 ‚Üí v2.3.0

### Performance

**Capacidade Antes**: 15-20 c√¢meras (limite cr√≠tico)  
**Capacidade Depois**: 50-100 c√¢meras (ganho de 5-10x)

| M√©trica | Antes | Depois | Melhoria |
|---------|-------|--------|----------|
| CPU Usage | 80-100% | 30-50% | -50% |
| Memory Usage | 3-4 GB | 1.5-2 GB | -40% |
| Frame Drop Rate | 20-30% | <5% | -80% |
| Capture Latency P99 | 5-10s | 0.5-1s | -85% |
| Throughput (FPS) | 10 FPS/cam | 20-30 FPS/cam | +150% |

### Testing

- **26 testes unit√°rios** adicionados (todos passando ‚úÖ)
  - `pkg/worker/pool_test.go` - 9 testes + benchmarks
  - `pkg/circuit/breaker_test.go` - 9 testes + benchmarks
  - `pkg/buffer/frame_buffer_test.go` - 8 testes + benchmarks

### Migration Guide

#### Compatibilidade

‚úÖ **Totalmente compat√≠vel com vers√µes anteriores**
- Configura√ß√£o `optimization.use_persistent: false` mant√©m comportamento cl√°ssico
- Todas configura√ß√µes antigas continuam funcionando

#### Deployment Recomendado

1. **Fase 1** (1-2 dias): Validar com 5-10 c√¢meras em modo cl√°ssico
2. **Fase 2** (2-3 dias): Habilitar `use_persistent: true` em 2-3 c√¢meras
3. **Fase 3** (1 semana): Expandir para 20-30 c√¢meras
4. **Fase 4**: Produ√ß√£o com 50-100 c√¢meras

#### Monitoramento

**M√©tricas Cr√≠ticas**:
- Frame drop rate: `< 5%`
- Worker pool saturation: `< 80%`
- Capture latency P99: `< 2s`
- Circuit breaker state: monitorar transi√ß√µes para OPEN

**Alertas Recomendados** (Prometheus):
```promql
# Frame drop rate > 10% por 5 minutos
rate(edge_video_frames_dropped_total[5m]) / rate(edge_video_frames_processed_total[5m]) > 0.1

# Worker pool saturado > 90% por 5 minutos
edge_video_worker_pool_queue_size / edge_video_worker_pool_capacity > 0.9
```

### Breaking Changes

Nenhuma breaking change. Vers√£o 2.0.0 devido √†s melhorias substanciais de arquitetura e performance.

## [1.1.0] - 2025-11-06

### ‚ú® Features

- Convers√£o do formato de configura√ß√£o de YAML para TOML para melhor legibilidade e suporte nativo ([#[#1](https://github.com/T3-Labs/edge-video/issues/1)](https://github.com/T3-Labs/edge-video/issues/[#1](https://github.com/T3-Labs/edge-video/issues/1)))
- Implementa pipeline CI/CD com GitHub Actions para testes automatizados em qualquer branch ([#[#3](https://github.com/T3-Labs/edge-video/issues/3)](https://github.com/T3-Labs/edge-video/issues/[#3](https://github.com/T3-Labs/edge-video/issues/3)))
- Adiciona visualiza√ß√£o em tempo real de frames com OpenCV no script de teste Python ([#[#4](https://github.com/T3-Labs/edge-video/issues/4)](https://github.com/T3-Labs/edge-video/issues/[#4](https://github.com/T3-Labs/edge-video/issues/4)))

### üîí Security

- Adiciona autentica√ß√£o por senha para Redis com configura√ß√£o via config.toml ([#[#2](https://github.com/T3-Labs/edge-video/issues/2)](https://github.com/T3-Labs/edge-video/issues/[#2](https://github.com/T3-Labs/edge-video/issues/2)))
</file>

<file path="pkg/config/config.go">
package config

import (
	"net/url"
	"strings"
	"time"

	"github.com/spf13/viper"
)

type CameraConfig struct {
	ID   string `mapstructure:"id"`
	Name string `mapstructure:"name"`
	URL  string `mapstructure:"url"`
}

type AMQPConfig struct {
	AmqpURL          string `mapstructure:"amqp_url"`
	Exchange         string `mapstructure:"exchange"`
	RoutingKeyPrefix string `mapstructure:"routing_key_prefix"`
}

type MQTTConfig struct {
	Broker      string `mapstructure:"broker"`
	TopicPrefix string `mapstructure:"topic_prefix"`
}

type Compression struct {
	Enabled bool `mapstructure:"enabled"`
	Level   int  `mapstructure:"level"`
}

type Optimization struct {
	MaxWorkers         int    `mapstructure:"max_workers"`
	BufferSize         int    `mapstructure:"buffer_size"`
	FrameQuality       int    `mapstructure:"frame_quality"`
	FrameResolution    string `mapstructure:"frame_resolution"`
	UsePersistent      bool   `mapstructure:"use_persistent"`
	CircuitMaxFailures int    `mapstructure:"circuit_max_failures"`
	CircuitResetSec    int    `mapstructure:"circuit_reset_seconds"`
}

type RedisConfig struct {
	Enabled    bool   `mapstructure:"enabled"`
	Address    string `mapstructure:"address"`
	TTLSeconds int    `mapstructure:"ttl_seconds"`
	Prefix     string `mapstructure:"prefix"`
}

type MetadataConfig struct {
	Enabled    bool   `mapstructure:"enabled"`
	Exchange   string `mapstructure:"exchange"`
	RoutingKey string `mapstructure:"routing_key"`
}

type Config struct {
	TargetFPS           float64        `mapstructure:"target_fps"`
	Protocol            string         `mapstructure:"protocol"`
	UseOptimizedCapture bool           `mapstructure:"use_optimized_capture"`
	AMQP                AMQPConfig     `mapstructure:"amqp"`
	MQTT                MQTTConfig     `mapstructure:"mqtt"`
	Redis               RedisConfig    `mapstructure:"redis"`
	Metadata            MetadataConfig `mapstructure:"metadata"`
	Compression         Compression    `mapstructure:"compression"`
	Optimization        Optimization   `mapstructure:"optimization"`
	Cameras             []CameraConfig `mapstructure:"cameras"`
}

// GetFrameInterval calcula o intervalo de tempo entre os frames com base no TargetFPS.
// Retorna um intervalo padr√£o de 2 FPS se o valor for inv√°lido.
func (c *Config) GetFrameInterval() time.Duration {
	if c.TargetFPS <= 0 {
		return time.Second / 2 // Padr√£o: 2 FPS
	}
	return time.Duration(float64(time.Second) / c.TargetFPS)
}

func LoadConfig(path string) (*Config, error) {
	viper.SetConfigFile(path)
	if err := viper.ReadInConfig(); err != nil {
		return nil, err
	}
	var cfg Config
	if err := viper.Unmarshal(&cfg); err != nil {
		return nil, err
	}
	return &cfg, nil
}
</file>

<file path="pkg/camera/camera.go">
package camera

import (
	"bytes"
	"context"
	"errors"
	"os/exec"
	"time"

	"github.com/T3-Labs/edge-video/internal/metadata"
	"github.com/T3-Labs/edge-video/internal/storage"
	"github.com/T3-Labs/edge-video/pkg/buffer"
	"github.com/T3-Labs/edge-video/pkg/circuit"
	"github.com/T3-Labs/edge-video/pkg/logger"
	"github.com/T3-Labs/edge-video/pkg/metrics"
	"github.com/T3-Labs/edge-video/pkg/mq"
	"github.com/T3-Labs/edge-video/pkg/util"
	"github.com/T3-Labs/edge-video/pkg/worker"
	"github.com/go-redis/redis/v8"
	"github.com/streadway/amqp"
)

type Config struct {
	ID  string
	URL string
}

type Capture struct {
	ctx              context.Context
	config           Config
	interval         time.Duration
	compressor       *util.Compressor
	publisher        mq.Publisher
	redisStore       *storage.RedisStore
	metaPublisher    *metadata.Publisher
	workerPool       *worker.Pool
	frameBuffer      *buffer.FrameBuffer
	circuitBreaker   *circuit.Breaker
	persistentCapture *PersistentCapture
	usePersistent    bool
}

func NewCapture(
	ctx context.Context,
	config Config,
	interval time.Duration,
	compressor *util.Compressor,
	publisher mq.Publisher,
	redisStore *storage.RedisStore,
	metaPublisher *metadata.Publisher,
	workerPool *worker.Pool,
	frameBuffer *buffer.FrameBuffer,
	circuitBreaker *circuit.Breaker,
	usePersistent bool,
) *Capture {
	capture := &Capture{
		ctx:            ctx,
		config:         config,
		interval:       interval,
		compressor:     compressor,
		publisher:      publisher,
		redisStore:     redisStore,
		metaPublisher:  metaPublisher,
		workerPool:     workerPool,
		frameBuffer:    frameBuffer,
		circuitBreaker: circuitBreaker,
		usePersistent:  usePersistent,
	}
	
	if usePersistent {
		fps := int(time.Second / interval)
		if fps == 0 {
			fps = 30
		}
		capture.persistentCapture = NewPersistentCapture(ctx, config.ID, config.URL, 5, fps)
	}
	
	return capture
}

func (c *Capture) Start() {
	if c.usePersistent && c.persistentCapture != nil {
		err := c.persistentCapture.Start()
		if err != nil {
			logger.Log.Errorw("Erro ao iniciar captura persistente, usando modo cl√°ssico",
				"camera_id", c.config.ID,
				"error", err)
			c.usePersistent = false
		} else {
			go c.persistentCaptureLoop()
			metrics.CameraConnected.WithLabelValues(c.config.ID).Set(1)
			return
		}
	}
	
	go c.classicCaptureLoop()
	metrics.CameraConnected.WithLabelValues(c.config.ID).Set(1)
}

func (c *Capture) persistentCaptureLoop() {
	logger.Log.Infow("Iniciando loop de captura persistente",
		"camera_id", c.config.ID)
	
	ticker := time.NewTicker(c.interval)
	defer ticker.Stop()
	
	for {
		select {
		case <-c.ctx.Done():
			logger.Log.Infow("Parando captura persistente",
				"camera_id", c.config.ID)
			c.persistentCapture.Stop()
			metrics.CameraConnected.WithLabelValues(c.config.ID).Set(0)
			return
			
		case <-ticker.C:
			frame, ok := c.persistentCapture.GetFrameWithTimeout(c.interval / 2)
			if !ok {
				metrics.FramesDropped.WithLabelValues(c.config.ID, "no_frame_available").Inc()
				continue
			}
			
			job := &FrameProcessJob{
				cameraID:      c.config.ID,
				frameData:     frame,
				timestamp:     time.Now(),
				publisher:     c.publisher,
				redisStore:    c.redisStore,
				metaPublisher: c.metaPublisher,
			}
			
			err := c.workerPool.Submit(job)
			if err != nil {
				metrics.FramesDropped.WithLabelValues(c.config.ID, "worker_pool_full").Inc()
				logger.Log.Warnw("Worker pool cheio, frame descartado",
					"camera_id", c.config.ID)
			}
		}
	}
}

func (c *Capture) classicCaptureLoop() {
	logger.Log.Infow("Iniciando loop de captura cl√°ssica",
		"camera_id", c.config.ID)

	for {
		select {
		case <-c.ctx.Done():
			logger.Log.Infow("Parando captura cl√°ssica",
				"camera_id", c.config.ID)
			metrics.CameraConnected.WithLabelValues(c.config.ID).Set(0)
			return
			
		default:
		}
		
		start := time.Now()
		c.captureAndPublish()
		
		elapsed := time.Since(start)
		sleepTime := c.interval - elapsed
		if sleepTime > 0 {
			time.Sleep(sleepTime)
		}
	}
}

func (c *Capture) captureAndPublish() {
	start := time.Now()
	
	err := c.circuitBreaker.Call(func() error {
		return c.doCapture()
	})
	
	if err != nil {
		logger.Log.Errorw("Erro na captura com circuit breaker",
			"camera_id", c.config.ID,
			"error", err)
		metrics.FramesDropped.WithLabelValues(c.config.ID, "circuit_breaker_open").Inc()
		return
	}
	
	metrics.CaptureLatency.WithLabelValues(c.config.ID).Observe(time.Since(start).Seconds())
}

func (c *Capture) doCapture() error {
	cmd := exec.CommandContext(
		c.ctx,
		"ffmpeg",
		"-rtsp_transport", "tcp",
		"-i", c.config.URL,
		"-frames:v", "1",
		"-f", "image2pipe",
		"-vcodec", "mjpeg",
		"-q:v", "5",
		"-",
	)

	var stdout, stderr bytes.Buffer
	cmd.Stdout = &stdout
	cmd.Stderr = &stderr

	err := cmd.Run()
	if err != nil {
		logger.Log.Errorw("Erro ao capturar frame",
			"camera_id", c.config.ID,
			"error", err,
			"stderr", stderr.String())
		return err
	}

	frameData := stdout.Bytes()
	if len(frameData) == 0 {
		logger.Log.Warnw("Frame vazio capturado",
			"camera_id", c.config.ID)
		return errors.New("frame vazio")
	}

	metrics.FrameSizeBytes.WithLabelValues(c.config.ID).Observe(float64(len(frameData)))
	
	logger.Log.Debugw("Frame capturado",
		"camera_id", c.config.ID,
		"size_bytes", len(frameData))
	
	job := &FrameProcessJob{
		cameraID:      c.config.ID,
		frameData:     frameData,
		timestamp:     time.Now(),
		publisher:     c.publisher,
		redisStore:    c.redisStore,
		metaPublisher: c.metaPublisher,
	}
	
	err = c.workerPool.Submit(job)
	if err != nil {
		metrics.FramesDropped.WithLabelValues(c.config.ID, "worker_pool_full").Inc()
		logger.Log.Warnw("Worker pool cheio, processando sincronamente",
			"camera_id", c.config.ID)
		return job.Process(c.ctx)
	}
	
	return nil
}

type FrameProcessJob struct {
	cameraID      string
	frameData     []byte
	timestamp     time.Time
	publisher     mq.Publisher
	redisStore    *storage.RedisStore
	metaPublisher *metadata.Publisher
}

func (j *FrameProcessJob) GetID() string {
	return j.cameraID + "_" + j.timestamp.Format("20060102150405.000")
}

func (j *FrameProcessJob) Process(ctx context.Context) error {
	start := time.Now()
	
	err := j.publisher.Publish(ctx, j.cameraID, j.frameData)
	if err != nil {
		logger.Log.Errorw("Erro ao publicar frame",
			"camera_id", j.cameraID,
			"error", err)
		return err
	}
	
	metrics.PublishLatency.WithLabelValues("amqp").Observe(time.Since(start).Seconds())
	metrics.FramesProcessed.WithLabelValues(j.cameraID).Inc()
	
	if j.redisStore.Enabled() {
		width, height := 1280, 720
		
		key, err := j.redisStore.SaveFrame(ctx, j.cameraID, j.timestamp, j.frameData)
		if err != nil {
			if errors.Is(err, redis.ErrClosed) {
				logger.Log.Errorw("Redis store error (connection closed)",
					"camera_id", j.cameraID,
					"error", err)
			} else {
				logger.Log.Errorw("Redis store error",
					"camera_id", j.cameraID,
					"error", err)
			}
			metrics.StorageOperations.WithLabelValues("save_frame", "error").Inc()
			return err
		}
		
		metrics.StorageOperations.WithLabelValues("save_frame", "success").Inc()
		
		if j.metaPublisher.Enabled() {
			err = j.metaPublisher.PublishMetadata(j.cameraID, j.timestamp, key, width, height, len(j.frameData), "jpeg")
			if err != nil {
				if amqpErr, ok := err.(*amqp.Error); ok && amqpErr.Code == amqp.ChannelError {
					logger.Log.Errorw("Metadata publish error (channel closed)",
						"camera_id", j.cameraID,
						"error", err)
				} else {
					logger.Log.Errorw("Metadata publish error",
						"camera_id", j.cameraID,
						"error", err)
				}
				return err
			}
		}
	}
	
	return nil
}
</file>

<file path=".gitignore">
# Created by https://www.toptal.com/developers/gitignore/api/go,vs,visualstudio,pycharm,pycharm+iml,pycharm+all,goland,goland+all,goland+iml
# Edit at https://www.toptal.com/developers/gitignore?templates=go,vs,visualstudio,pycharm,pycharm+iml,pycharm+all,goland,goland+all,goland+iml

### Go ###
# If you prefer the allow list template instead of the deny list, see community template:
# https://github.com/github/gitignore/blob/main/community/Golang/Go.AllowList.gitignore
#
# Binaries for programs and plugins
*.exe
*.exe~
*.dll
*.so
*.dylib

test_consumer.py

# Test binary, built with `go test -c`
*.test

# Output of the go coverage tool, specifically when used with LiteIDE
*.out

# Coverage reports
coverage.out
coverage.html
coverage.txt

# Dependency directories (remove the comment below to include it)
# vendor/

# Python virtual environments
.venv/
.venv-tools/
.venv-docs/
venv-test/
__pycache__/

# MkDocs
site/
.cache/

# Go workspace file
go.work
go.work.sum

### GoLand ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff
.idea/**/workspace.xml
.idea/**/tasks.xml
.idea/**/usage.statistics.xml
.idea/**/dictionaries
.idea/**/shelf

# AWS User-specific
.idea/**/aws.xml

# Generated files
.idea/**/contentModel.xml

# Sensitive or high-churn files
.idea/**/dataSources/
.idea/**/dataSources.ids
.idea/**/dataSources.local.xml
.idea/**/sqlDataSources.xml
.idea/**/dynamic.xml
.idea/**/uiDesigner.xml
.idea/**/dbnavigator.xml

# Gradle
.idea/**/gradle.xml
.idea/**/libraries

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake
cmake-build-*/

# Mongo Explorer plugin
.idea/**/mongoSettings.xml

# File-based project format
*.iws

# IntelliJ
out/

# mpeltonen/sbt-idea plugin
.idea_modules/

# JIRA plugin
atlassian-ide-plugin.xml

# Cursive Clojure plugin
.idea/replstate.xml

# SonarLint plugin
.idea/sonarlint/

# Crashlytics plugin (for Android Studio and IntelliJ)
com_crashlytics_export_strings.xml
crashlytics.properties
crashlytics-build.properties
fabric.properties

# Editor-based Rest Client
.idea/httpRequests

# Android studio 3.1+ serialized cache file
.idea/caches/build_file_checksums.ser

### GoLand Patch ###
# Comment Reason: https://github.com/joeblau/gitignore.io/issues/186#issuecomment-215987721

# *.iml
# modules.xml
# .idea/misc.xml
# *.ipr

# Sonarlint plugin
# https://plugins.jetbrains.com/plugin/7973-sonarlint
.idea/**/sonarlint/

# SonarQube Plugin
# https://plugins.jetbrains.com/plugin/7238-sonarqube-community-plugin
.idea/**/sonarIssues.xml

# Markdown Navigator plugin
# https://plugins.jetbrains.com/plugin/7896-markdown-navigator-enhanced
.idea/**/markdown-navigator.xml
.idea/**/markdown-navigator-enh.xml
.idea/**/markdown-navigator/

# Cache file creation bug
# See https://youtrack.jetbrains.com/issue/JBR-2257
.idea/$CACHE_FILE$

# CodeStream plugin
# https://plugins.jetbrains.com/plugin/12206-codestream
.idea/codestream.xml

# Azure Toolkit for IntelliJ plugin
# https://plugins.jetbrains.com/plugin/8053-azure-toolkit-for-intellij
.idea/**/azureSettings.xml

### GoLand+all ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff

# AWS User-specific

# Generated files

# Sensitive or high-churn files

# Gradle

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake

# Mongo Explorer plugin

# File-based project format

# IntelliJ

# mpeltonen/sbt-idea plugin

# JIRA plugin

# Cursive Clojure plugin

# SonarLint plugin

# Crashlytics plugin (for Android Studio and IntelliJ)

# Editor-based Rest Client

# Android studio 3.1+ serialized cache file

### GoLand+all Patch ###
# Ignore everything but code style settings and run configurations
# that are supposed to be shared within teams.

.idea/*

!.idea/codeStyles
!.idea/runConfigurations

### GoLand+iml ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff

# AWS User-specific

# Generated files

# Sensitive or high-churn files

# Gradle

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake

# Mongo Explorer plugin

# File-based project format

# IntelliJ

# mpeltonen/sbt-idea plugin

# JIRA plugin

# Cursive Clojure plugin

# SonarLint plugin

# Crashlytics plugin (for Android Studio and IntelliJ)

# Editor-based Rest Client

# Android studio 3.1+ serialized cache file

### GoLand+iml Patch ###
# Reason: https://github.com/joeblau/gitignore.io/issues/186#issuecomment-249601023

*.iml
modules.xml
.idea/misc.xml
*.ipr

### PyCharm ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff

# AWS User-specific

# Generated files

# Sensitive or high-churn files

# Gradle

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake

# Mongo Explorer plugin

# File-based project format

# IntelliJ

# mpeltonen/sbt-idea plugin

# JIRA plugin

# Cursive Clojure plugin

# SonarLint plugin

# Crashlytics plugin (for Android Studio and IntelliJ)

# Editor-based Rest Client

# Android studio 3.1+ serialized cache file

### PyCharm Patch ###
# Comment Reason: https://github.com/joeblau/gitignore.io/issues/186#issuecomment-215987721

# *.iml
# modules.xml
# .idea/misc.xml
# *.ipr

# Sonarlint plugin
# https://plugins.jetbrains.com/plugin/7973-sonarlint

# SonarQube Plugin
# https://plugins.jetbrains.com/plugin/7238-sonarqube-community-plugin

# Markdown Navigator plugin
# https://plugins.jetbrains.com/plugin/7896-markdown-navigator-enhanced

# Cache file creation bug
# See https://youtrack.jetbrains.com/issue/JBR-2257

# CodeStream plugin
# https://plugins.jetbrains.com/plugin/12206-codestream

# Azure Toolkit for IntelliJ plugin
# https://plugins.jetbrains.com/plugin/8053-azure-toolkit-for-intellij

### PyCharm+all ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff

# AWS User-specific

# Generated files

# Sensitive or high-churn files

# Gradle

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake

# Mongo Explorer plugin

# File-based project format

# IntelliJ

# mpeltonen/sbt-idea plugin

# JIRA plugin

# Cursive Clojure plugin

# SonarLint plugin

# Crashlytics plugin (for Android Studio and IntelliJ)

# Editor-based Rest Client

# Android studio 3.1+ serialized cache file

### PyCharm+all Patch ###
# Ignore everything but code style settings and run configurations
# that are supposed to be shared within teams.



### PyCharm+iml ###
# Covers JetBrains IDEs: IntelliJ, RubyMine, PhpStorm, AppCode, PyCharm, CLion, Android Studio, WebStorm and Rider
# Reference: https://intellij-support.jetbrains.com/hc/en-us/articles/206544839

# User-specific stuff

# AWS User-specific

# Generated files

# Sensitive or high-churn files

# Gradle

# Gradle and Maven with auto-import
# When using Gradle or Maven with auto-import, you should exclude module files,
# since they will be recreated, and may cause churn.  Uncomment if using
# auto-import.
# .idea/artifacts
# .idea/compiler.xml
# .idea/jarRepositories.xml
# .idea/modules.xml
# .idea/*.iml
# .idea/modules
# *.iml
# *.ipr

# CMake

# Mongo Explorer plugin

# File-based project format

# IntelliJ

# mpeltonen/sbt-idea plugin

# JIRA plugin

# Cursive Clojure plugin

# SonarLint plugin

# Crashlytics plugin (for Android Studio and IntelliJ)

# Editor-based Rest Client

# Android studio 3.1+ serialized cache file

### PyCharm+iml Patch ###
# Reason: https://github.com/joeblau/gitignore.io/issues/186#issuecomment-249601023


### vs ###
## Ignore Visual Studio temporary files, build results, and
## files generated by popular Visual Studio add-ons.
##
## Get latest from https://github.com/github/gitignore/blob/master/VisualStudio.gitignore

# User-specific files
*.rsuser
*.suo
*.user
*.userosscache
*.sln.docstates

# User-specific files (MonoDevelop/Xamarin Studio)
*.userprefs

# Mono auto generated files
mono_crash.*

# Build results
[Dd]ebug/
[Dd]ebugPublic/
[Rr]elease/
[Rr]eleases/
x64/
x86/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
bld/
[Bb]in/
[Oo]bj/
[Ll]og/
[Ll]ogs/

# Visual Studio 2015/2017 cache/options directory
.vs/
# Uncomment if you have tasks that create the project's static files in wwwroot
#wwwroot/

# Visual Studio 2017 auto generated files
Generated\ Files/

# MSTest test Results
[Tt]est[Rr]esult*/
[Bb]uild[Ll]og.*

# NUnit
*.VisualState.xml
TestResult.xml
nunit-*.xml

# Build Results of an ATL Project
[Dd]ebugPS/
[Rr]eleasePS/
dlldata.c

# Benchmark Results
BenchmarkDotNet.Artifacts/

# .NET Core
project.lock.json
project.fragment.lock.json
artifacts/

# StyleCop
StyleCopReport.xml

# Files built by Visual Studio
*_i.c
*_p.c
*_h.h
*.ilk
*.meta
*.obj
*.iobj
*.pch
*.pdb
*.ipdb
*.pgc
*.pgd
*.rsp
*.sbr
*.tlb
*.tli
*.tlh
*.tmp
*.tmp_proj
*_wpftmp.csproj
*.log
*.vspscc
*.vssscc
.builds
*.pidb
*.svclog
*.scc

# Chutzpah Test files
_Chutzpah*

# Visual C++ cache files
ipch/
*.aps
*.ncb
*.opendb
*.opensdf
*.sdf
*.cachefile
*.VC.db
*.VC.VC.opendb

# Visual Studio profiler
*.psess
*.vsp
*.vspx
*.sap

# Visual Studio Trace Files
*.e2e

# TFS 2012 Local Workspace
$tf/

# Guidance Automation Toolkit
*.gpState

# ReSharper is a .NET coding add-in
_ReSharper*/
*.[Rr]e[Ss]harper
*.DotSettings.user

# TeamCity is a build add-in
_TeamCity*

# DotCover is a Code Coverage Tool
*.dotCover

# AxoCover is a Code Coverage Tool
.axoCover/*
!.axoCover/settings.json

# Coverlet is a free, cross platform Code Coverage Tool
coverage*[.json, .xml, .info]

# Visual Studio code coverage results
*.coverage
*.coveragexml

# NCrunch
_NCrunch_*
.*crunch*.local.xml
nCrunchTemp_*

# MightyMoose
*.mm.*
AutoTest.Net/

# Web workbench (sass)
.sass-cache/

# Installshield output folder
[Ee]xpress/

# DocProject is a documentation generator add-in
DocProject/buildhelp/
DocProject/Help/*.HxT
DocProject/Help/*.HxC
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/Html2
DocProject/Help/html

# Click-Once directory
publish/

# Publish Web Output
*.[Pp]ublish.xml
*.azurePubxml
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted
*.pubxml
*.publishproj

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted
PublishScripts/

# NuGet Packages
*.nupkg
# NuGet Symbol Packages
*.snupkg
# The packages folder can be ignored because of Package Restore
**/[Pp]ackages/*
# except build/, which is used as an MSBuild target.
!**/[Pp]ackages/build/
# Uncomment if necessary however generally it will be regenerated when needed
#!**/[Pp]ackages/repositories.config
# NuGet v3's project.json files produces more ignorable files
*.nuget.props
*.nuget.targets

# Microsoft Azure Build Output
csx/
*.build.csdef

# Microsoft Azure Emulator
ecf/
rcf/

# Windows Store app package directories and files
AppPackages/
BundleArtifacts/
Package.StoreAssociation.xml
_pkginfo.txt
*.appx
*.appxbundle
*.appxupload

# Visual Studio cache files
# files ending in .cache can be ignored
*.[Cc]ache
# but keep track of directories ending in .cache
!?*.[Cc]ache/

# Others
ClientBin/
~$*
*~
*.dbmdl
*.dbproj.schemaview
*.jfm
*.pfx
*.publishsettings
orleans.codegen.cs

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)
#*.snk

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)
#bower_components/

# RIA/Silverlight projects
Generated_Code/

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)
_UpgradeReport_Files/
Backup*/
UpgradeLog*.XML
UpgradeLog*.htm
ServiceFabricBackup/
*.rptproj.bak

# SQL Server files
*.mdf
*.ldf
*.ndf

# Business Intelligence projects
*.rdl.data
*.bim.layout
*.bim_*.settings
*.rptproj.rsuser
*- [Bb]ackup.rdl
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl

# Microsoft Fakes
FakesAssemblies/

# GhostDoc plugin setting file
*.GhostDoc.xml

# Node.js Tools for Visual Studio
.ntvs_analysis.dat
node_modules/

# Visual Studio 6 build log
*.plg

# Visual Studio 6 workspace options file
*.opt

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)
*.vbw

# Visual Studio LightSwitch build output
**/*.HTMLClient/GeneratedArtifacts
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
_Pvt_Extensions

# Paket dependency manager
.paket/paket.exe
paket-files/

# FAKE - F# Make
.fake/

# CodeRush personal settings
.cr/personal

# Python Tools for Visual Studio (PTVS)
__pycache__/
*.pyc

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio
*.tss

# Telerik's JustMock configuration file
*.jmconfig

# BizTalk build output
*.btp.cs
*.btm.cs
*.odx.cs
*.xsd.cs

# OpenCover UI analysis results
OpenCover/

# Azure Stream Analytics local run output
ASALocalRun/

# MSBuild Binary and Structured Log
*.binlog

# NVidia Nsight GPU debugger configuration file
*.nvuser

# MFractors (Xamarin productivity tool) working folder
.mfractor/

# Local History for Visual Studio
.localhistory/

# BeatPulse healthcheck temp database
healthchecksdb

# Backup folder for Package Reference Convert tool in Visual Studio 2017
MigrationBackup/

# Ionide (cross platform F# VS Code tools) working folder
.ionide/

### VisualStudio ###
## Get latest from https://github.com/github/gitignore/blob/main/VisualStudio.gitignore

# User-specific files

# User-specific files (MonoDevelop/Xamarin Studio)

# Mono auto generated files

# Build results
[Ww][Ii][Nn]32/

# Visual Studio 2015/2017 cache/options directory
# Uncomment if you have tasks that create the project's static files in wwwroot

# Visual Studio 2017 auto generated files

# MSTest test Results

# NUnit

# Build Results of an ATL Project

# Benchmark Results

# .NET Core

# ASP.NET Scaffolding
ScaffoldingReadMe.txt

# StyleCop

# Files built by Visual Studio
*.tlog

# Chutzpah Test files

# Visual C++ cache files

# Visual Studio profiler

# Visual Studio Trace Files

# TFS 2012 Local Workspace

# Guidance Automation Toolkit

# ReSharper is a .NET coding add-in

# TeamCity is a build add-in

# DotCover is a Code Coverage Tool

# AxoCover is a Code Coverage Tool

# Coverlet is a free, cross platform Code Coverage Tool
coverage*.json
coverage*.xml
coverage*.info

# Visual Studio code coverage results

# NCrunch

# MightyMoose

# Web workbench (sass)

# Installshield output folder

# DocProject is a documentation generator add-in

# Click-Once directory

# Publish Web Output
# Note: Comment the next line if you want to checkin your web deploy settings,
# but database connection strings (with potential passwords) will be unencrypted

# Microsoft Azure Web App publish settings. Comment the next line if you want to
# checkin your Azure Web App publish settings, but sensitive information contained
# in these scripts will be unencrypted

# NuGet Packages
# NuGet Symbol Packages
# The packages folder can be ignored because of Package Restore
# except build/, which is used as an MSBuild target.
# Uncomment if necessary however generally it will be regenerated when needed
# NuGet v3's project.json files produces more ignorable files

# Microsoft Azure Build Output

# Microsoft Azure Emulator

# Windows Store app package directories and files

# Visual Studio cache files
# files ending in .cache can be ignored
# but keep track of directories ending in .cache

# Others

# Including strong name files can present a security risk
# (https://github.com/github/gitignore/pull/2483#issue-259490424)

# Since there are multiple workflows, uncomment next line to ignore bower_components
# (https://github.com/github/gitignore/pull/1529#issuecomment-104372622)

# RIA/Silverlight projects

# Backup & report files from converting an old project file
# to a newer Visual Studio version. Backup files are not needed,
# because we have git ;-)

# SQL Server files

# Business Intelligence projects

# Microsoft Fakes

# GhostDoc plugin setting file

# Node.js Tools for Visual Studio

# Visual Studio 6 build log

# Visual Studio 6 workspace options file

# Visual Studio 6 auto-generated workspace file (contains which files were open etc.)

# Visual Studio 6 auto-generated project file (contains which files were open etc.)
*.vbp

# Visual Studio 6 workspace and project file (working project files containing files to include in project)
*.dsw
*.dsp

# Visual Studio 6 technical files

# Visual Studio LightSwitch build output

# Paket dependency manager

# FAKE - F# Make

# CodeRush personal settings

# Python Tools for Visual Studio (PTVS)

# Cake - Uncomment if you are using it
# tools/**
# !tools/packages.config

# Tabs Studio

# Telerik's JustMock configuration file

# BizTalk build output

# OpenCover UI analysis results

# Azure Stream Analytics local run output

# MSBuild Binary and Structured Log

# NVidia Nsight GPU debugger configuration file

# MFractors (Xamarin productivity tool) working folder

# Local History for Visual Studio

# Visual Studio History (VSHistory) files
.vshistory/

# BeatPulse healthcheck temp database

# Backup folder for Package Reference Convert tool in Visual Studio 2017

# Ionide (cross platform F# VS Code tools) working folder

# Fody - auto-generated XML schema
FodyWeavers.xsd

# VS Code files for those working on multiple tools
.vscode/*
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
*.code-workspace

# Local History for Visual Studio Code
.history/

# Windows Installer files from build outputs
*.cab
*.msi
*.msix
*.msm
*.msp

# JetBrains Rider
*.sln.iml

### VisualStudio Patch ###
# Additional files built by Visual Studio

# End of https://www.toptal.com/developers/gitignore/api/go,vs,visualstudio,pycharm,pycharm+iml,pycharm+all,goland,goland+all,goland+iml
</file>

<file path="pyproject.toml">
[tool.towncrier]
# Configura√ß√£o do Towncrier para gera√ß√£o autom√°tica de CHANGELOG
# Documenta√ß√£o: https://towncrier.readthedocs.io/

# Caminho para o arquivo de changelog
filename = "CHANGELOG.md"

# Diret√≥rio onde os fragments de changelog ser√£o armazenados
directory = "changelog.d"

# Template para o t√≠tulo das vers√µes
title_format = "## [{version}] - {project_date}"

# Template para o corpo do changelog
template = "changelog.d/template.md.j2"

# Formato de data (ISO 8601)
issue_format = "[#{issue}](https://github.com/T3-Labs/edge-video/issues/{issue})"

# Branch principal para compara√ß√£o
# compare_with = "origin/main"

# Iniciar vers√£o do zero se n√£o existir CHANGELOG
start_string = "<!-- towncrier release notes start -->\n"

# Underlines para t√≠tulos (markdown usa ##)
underlines = ["", "", ""]

# Wrap do texto (0 = sem wrap)
wrap = false

# All bullets points (n√£o adicionar bullets extras)
all_bullets = true

# Tipos de mudan√ßas permitidos
[[tool.towncrier.type]]
directory = "feature"
name = "‚ú® Features"
showcontent = true

[[tool.towncrier.type]]
directory = "bugfix"
name = "üêõ Bug Fixes"
showcontent = true

[[tool.towncrier.type]]
directory = "docs"
name = "üìö Documentation"
showcontent = true

[[tool.towncrier.type]]
directory = "removal"
name = "üóëÔ∏è Removals and Deprecations"
showcontent = true

[[tool.towncrier.type]]
directory = "misc"
name = "üîß Miscellaneous"
showcontent = true

[[tool.towncrier.type]]
directory = "security"
name = "üîí Security"
showcontent = true

[[tool.towncrier.type]]
directory = "performance"
name = "‚ö° Performance"
showcontent = true

[[tool.towncrier.type]]
directory = "refactor"
name = "‚ôªÔ∏è Refactoring"
showcontent = true
</file>

<file path="cmd/edge-video/main.go">
package main

import (
	"context"
	"flag"
	"log"
	"net/http"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/T3-Labs/edge-video/internal/metadata"
	"github.com/T3-Labs/edge-video/internal/storage"
	"github.com/T3-Labs/edge-video/pkg/buffer"
	"github.com/T3-Labs/edge-video/pkg/camera"
	"github.com/T3-Labs/edge-video/pkg/circuit"
	"github.com/T3-Labs/edge-video/pkg/config"
	"github.com/T3-Labs/edge-video/pkg/logger"
	"github.com/T3-Labs/edge-video/pkg/metrics"
	"github.com/T3-Labs/edge-video/pkg/mq"
	"github.com/T3-Labs/edge-video/pkg/util"
	"github.com/T3-Labs/edge-video/pkg/worker"
	"github.com/prometheus/client_golang/prometheus/promhttp"
)

func main() {
	// Parse command line flags
	configFile := flag.String("config", "config.toml", "Caminho para o arquivo de configura√ß√£o")
	flag.Parse()

	err := logger.InitLogger(false)
	if err != nil {
		log.Fatalf("erro ao inicializar logger: %v", err)
	}
	defer logger.Sync()
	
	cfg, err := config.LoadConfig(*configFile)
	if err != nil {
		logger.Log.Fatalw("Erro ao carregar config", "error", err, "config_file", *configFile)
	}

	interval := cfg.GetFrameInterval()
	logger.Log.Infow("Configura√ß√£o carregada",
		"config_file", *configFile,
		"target_fps", cfg.TargetFPS,
		"interval", interval,
		"cameras", len(cfg.Cameras),
		"max_workers", cfg.Optimization.MaxWorkers,
		"buffer_size", cfg.Optimization.BufferSize)

	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	workerPool := worker.NewPool(ctx, cfg.Optimization.MaxWorkers, cfg.Optimization.BufferSize)
	defer workerPool.Close()

	var publisher mq.Publisher
	var amqpPublisher *mq.AMQPPublisher
	if cfg.Protocol == "mqtt" {
		p, err := mq.NewMQTTPublisher(cfg.MQTT.Broker, cfg.MQTT.TopicPrefix)
		if err != nil {
			logger.Log.Fatalw("Erro ao criar mqtt publisher", "error", err)
		}
		publisher = p
	} else {
		p, err := mq.NewAMQPPublisher(cfg.AMQP.AmqpURL, cfg.AMQP.Exchange, cfg.AMQP.RoutingKeyPrefix)
		if err != nil {
			logger.Log.Fatalw("Erro ao criar amqp publisher", "error", err)
		}
		publisher = p
		amqpPublisher = p
	}
	defer publisher.Close()

	redisStore := storage.NewRedisStore(cfg.Redis.Address, cfg.Redis.TTLSeconds, cfg.Redis.Prefix, cfg.Redis.Enabled)

	var metaPublisher *metadata.Publisher
	if amqpPublisher != nil {
		metaPublisher = metadata.NewPublisher(amqpPublisher.GetChannel(), cfg.Metadata.Exchange, cfg.Metadata.RoutingKey, cfg.Metadata.Enabled)
	} else {
		metaPublisher = metadata.NewPublisher(nil, "", "", false)
	}

	var compressor *util.Compressor
	if cfg.Compression.Enabled {
		comp, err := util.NewCompressor(cfg.Compression.Level)
		if err != nil {
			logger.Log.Fatalw("Erro ao criar compressor", "error", err)
		}
		compressor = comp
	}

	go startMetricsServer(":9090")

	go monitorSystem(workerPool)

	for _, camCfg := range cfg.Cameras {
		frameBuffer := buffer.NewFrameBuffer(cfg.Optimization.BufferSize)
		
		resetTimeout := time.Duration(cfg.Optimization.CircuitResetSec) * time.Second
		if resetTimeout == 0 {
			resetTimeout = 60 * time.Second
		}
		
		maxFailures := int64(cfg.Optimization.CircuitMaxFailures)
		if maxFailures == 0 {
			maxFailures = 5
		}
		
		circuitBreaker := circuit.NewBreaker(camCfg.ID, maxFailures, resetTimeout)
		
		capture := camera.NewCapture(
			ctx,
			camera.Config{ID: camCfg.ID, URL: camCfg.URL},
			interval,
			compressor,
			publisher,
			redisStore,
			metaPublisher,
			workerPool,
			frameBuffer,
			circuitBreaker,
			cfg.Optimization.UsePersistent,
		)

		capture.Start()
		
		logger.Log.Infow("C√¢mera iniciada",
			"camera_id", camCfg.ID,
			"camera_name", camCfg.Name,
			"use_persistent", cfg.Optimization.UsePersistent)
	}

	sig := make(chan os.Signal, 1)
	signal.Notify(sig, syscall.SIGINT, syscall.SIGTERM)
	<-sig
	
	logger.Log.Info("Recebido sinal de finaliza√ß√£o, encerrando...")
	cancel()
	
	time.Sleep(2 * time.Second)
	
	logger.Log.Info("Aplica√ß√£o finalizada")
}

func startMetricsServer(addr string) {
	http.Handle("/metrics", promhttp.Handler())
	
	logger.Log.Infow("Servidor de m√©tricas iniciado", "address", addr)
	
	if err := http.ListenAndServe(addr, nil); err != nil {
		logger.Log.Errorw("Erro no servidor de m√©tricas", "error", err)
	}
}

func monitorSystem(pool *worker.Pool) {
	ticker := time.NewTicker(30 * time.Second)
	defer ticker.Stop()
	
	for range ticker.C {
		stats := pool.Stats()
		
		metrics.WorkerPoolQueueSize.WithLabelValues("main").Set(float64(stats.QueueSize))
		metrics.WorkerPoolProcessing.WithLabelValues("main").Set(float64(stats.Processing))
		
		logger.Log.Infow("System stats",
			"pool_stats", stats.String())
	}
}
</file>

<file path="docker-compose.yml">
version: '3.8'

services:
  camera-collector:
    build: .
    container_name: camera-collector
    restart: unless-stopped
    volumes:
      # Monta o config.toml (pode ser customizado via vari√°vel de ambiente)
      - ${CONFIG_PATH:-./config.toml}:/app/config.toml
    # Para usar um arquivo de configura√ß√£o diferente, descomente e ajuste:
    # command: ["./camera-collector", "--config", "/app/config.toml"]
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_started
    # Opcional: descomente se precisar que a rede do host seja usada
    # network_mode: "host"

  redis:
    image: redis:7-alpine
    container_name: redis
    restart: always
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  redisinsight:
    image: redis/redisinsight:latest
    container_name: redisinsight
    restart: always
    ports:
      - "5540:5540"
    volumes:
      - redisinsight_data:/data
    depends_on:
      redis:
        condition: service_healthy

  rabbitmq:
    image: "rabbitmq:3.13-management-alpine"
    container_name: rabbitmq
    ports:
      # Porta para o protocolo AMQP
      - "5672:5672"
      # Porta para a interface de gerenciamento web
      - "15672:15672"
    volumes:
      # Persiste os dados do RabbitMQ
      - rabbitmq_data:/var/lib/rabbitmq/
    environment:
      - RABBITMQ_DEFAULT_USER=user
      - RABBITMQ_DEFAULT_PASS=password
      - RABBITMQ_DEFAULT_VHOST=guard_vhost
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

volumes:
  rabbitmq_data:
  redisinsight_data:
</file>

<file path="go.mod">
module github.com/T3-Labs/edge-video

go 1.24.0

toolchain go1.24.9

require (
	github.com/eclipse/paho.mqtt.golang v1.5.1
	github.com/go-redis/redis/v8 v8.11.5
	github.com/klauspost/compress v1.18.1
	github.com/prometheus/client_golang v1.23.2
	github.com/spf13/viper v1.21.0
	github.com/streadway/amqp v1.1.0
	github.com/stretchr/testify v1.11.1
	go.uber.org/zap v1.27.0
)

require (
	github.com/beorn7/perks v1.0.1 // indirect
	github.com/cespare/xxhash/v2 v2.3.0 // indirect
	github.com/davecgh/go-spew v1.1.1 // indirect
	github.com/dgryski/go-rendezvous v0.0.0-20200823014737-9f7001d12a5f // indirect
	github.com/fsnotify/fsnotify v1.9.0 // indirect
	github.com/go-viper/mapstructure/v2 v2.4.0 // indirect
	github.com/gorilla/websocket v1.5.3 // indirect
	github.com/munnerz/goautoneg v0.0.0-20191010083416-a7dc8b61c822 // indirect
	github.com/pelletier/go-toml/v2 v2.2.4 // indirect
	github.com/pmezard/go-difflib v1.0.0 // indirect
	github.com/prometheus/client_model v0.6.2 // indirect
	github.com/prometheus/common v0.66.1 // indirect
	github.com/prometheus/procfs v0.16.1 // indirect
	github.com/sagikazarmark/locafero v0.11.0 // indirect
	github.com/sourcegraph/conc v0.3.1-0.20240121214520-5f936abd7ae8 // indirect
	github.com/spf13/afero v1.15.0 // indirect
	github.com/spf13/cast v1.10.0 // indirect
	github.com/spf13/pflag v1.0.10 // indirect
	github.com/subosito/gotenv v1.6.0 // indirect
	go.uber.org/multierr v1.10.0 // indirect
	go.yaml.in/yaml/v2 v2.4.2 // indirect
	go.yaml.in/yaml/v3 v3.0.4 // indirect
	golang.org/x/net v0.44.0 // indirect
	golang.org/x/sync v0.17.0 // indirect
	golang.org/x/sys v0.36.0 // indirect
	golang.org/x/text v0.29.0 // indirect
	google.golang.org/protobuf v1.36.8 // indirect
	gopkg.in/yaml.v3 v3.0.1 // indirect
)
</file>

<file path="Dockerfile">
# Stage 1: Build
FROM golang:1.24-alpine AS builder

WORKDIR /app

# Copiar go.mod e go.sum
COPY go.mod go.sum ./

# Copiar o c√≥digo fonte para resolver depend√™ncias locais
COPY . .

# Baixar e sincronizar depend√™ncias
RUN go mod download
RUN go mod tidy

# Construir a aplica√ß√£o sem CGO
RUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o /camera-collector ./cmd/edge-video

# Stage 2: Final image
FROM alpine:latest

# Instala FFmpeg para captura de streams RTSP
RUN apk add --no-cache ffmpeg

WORKDIR /app

# Copiar o bin√°rio constru√≠do
COPY --from=builder /camera-collector .

# Nota: config.toml ser√° montado via volume no docker-compose.yml
# Voc√™ pode especificar um arquivo diferente usando: --config /path/to/file.toml

# Comando para iniciar a aplica√ß√£o
# Por padr√£o usa config.toml, mas pode ser sobrescrito no docker-compose.yml
CMD ["./camera-collector"]
</file>

</files>
